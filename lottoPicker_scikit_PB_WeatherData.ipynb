{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timhapp/ai_lotto_picker/blob/main/lottoPicker_scikit_PB_WeatherData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvFmCKGi4Az"
      },
      "source": [
        "# Import a bunch of libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFYlpFqkD-4q",
        "outputId": "9943fdec-1120-4149-d951-b5790a4417b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scikit-learn version is 1.0.2.\n"
          ]
        }
      ],
      "source": [
        "#Importing Libraries\n",
        "!pip install -q sodapy\n",
        "from sodapy import Socrata\n",
        "\n",
        "import requests\n",
        "import json\n",
        "#import math\n",
        "\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "#from sklearn.externals import joblib ## depreciated\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4i3Jy80cgrr8",
        "outputId": "6d786ca7-1ed0-4121-d81c-c3eb9b15aef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: awsebcli in /usr/local/lib/python3.7/dist-packages (3.20.3)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (1.26.12)\n",
            "Requirement already satisfied: docker-compose<1.26.0,>=1.25.2 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (1.25.5)\n",
            "Requirement already satisfied: wcwidth<0.2.0,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (0.1.9)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (1.1.0)\n",
            "Requirement already satisfied: cement==2.8.2 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (2.8.2)\n",
            "Requirement already satisfied: pathspec==0.9.0 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (0.9.0)\n",
            "Requirement already satisfied: future<0.17.0,>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (0.16.0)\n",
            "Requirement already satisfied: blessed>=1.9.5 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (1.19.1)\n",
            "Requirement already satisfied: PyYAML<5.5,>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (5.4.1)\n",
            "Collecting botocore<1.24.0,>1.23.41\n",
            "  Using cached botocore-1.23.54-py3-none-any.whl (8.5 MB)\n",
            "Collecting colorama<0.4.4,>=0.2.5\n",
            "  Using cached colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests<=2.26,>=2.20.1 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (2.26.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (2.8.2)\n",
            "Requirement already satisfied: setuptools>=20.0 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (57.4.0)\n",
            "Collecting six<1.15.0,>=1.11.0\n",
            "  Using cached six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: semantic-version==2.8.5 in /usr/local/lib/python3.7/dist-packages (from awsebcli) (2.8.5)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema<4,>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (3.2.0)\n",
            "Requirement already satisfied: cached-property<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (1.5.2)\n",
            "Requirement already satisfied: docopt<1,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (0.6.2)\n",
            "Requirement already satisfied: websocket-client<1,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (0.59.0)\n",
            "Requirement already satisfied: docker[ssh]<5,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (4.4.4)\n",
            "Requirement already satisfied: texttable<2,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (1.6.4)\n",
            "Requirement already satisfied: dockerpty<1,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (0.4.1)\n",
            "Requirement already satisfied: paramiko>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (2.11.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=2.5.1->docker-compose<1.26.0,>=1.25.2->awsebcli) (4.12.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=2.5.1->docker-compose<1.26.0,>=1.25.2->awsebcli) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=2.5.1->docker-compose<1.26.0,>=1.25.2->awsebcli) (22.1.0)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4.2->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (1.5.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4.2->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (3.2.2)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4.2->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (37.0.4)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (2.21)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<=2.26,>=2.20.1->awsebcli) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<=2.26,>=2.20.1->awsebcli) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<=2.26,>=2.20.1->awsebcli) (2022.6.15)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<4,>=2.5.1->docker-compose<1.26.0,>=1.25.2->awsebcli) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<4,>=2.5.1->docker-compose<1.26.0,>=1.25.2->awsebcli) (4.1.1)\n",
            "Installing collected packages: six, jmespath, colorama, botocore\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: jmespath\n",
            "    Found existing installation: jmespath 1.0.1\n",
            "    Uninstalling jmespath-1.0.1:\n",
            "      Successfully uninstalled jmespath-1.0.1\n",
            "  Attempting uninstall: colorama\n",
            "    Found existing installation: colorama 0.4.4\n",
            "    Uninstalling colorama-0.4.4:\n",
            "      Successfully uninstalled colorama-0.4.4\n",
            "  Attempting uninstall: botocore\n",
            "    Found existing installation: botocore 1.27.57\n",
            "    Uninstalling botocore-1.27.57:\n",
            "      Successfully uninstalled botocore-1.27.57\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "boto3 1.24.57 requires botocore<1.28.0,>=1.27.57, but you have botocore 1.23.54 which is incompatible.\n",
            "awscli 1.25.58 requires botocore==1.27.57, but you have botocore 1.23.54 which is incompatible.\n",
            "awscli 1.25.58 requires docutils<0.17,>=0.10, but you have docutils 0.17.1 which is incompatible.\n",
            "awscli 1.25.58 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\u001b[0m\n",
            "Successfully installed botocore-1.23.54 colorama-0.4.3 jmespath-0.10.0 six-1.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "colorama",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting awscli\n",
            "  Using cached awscli-1.25.58-py3-none-any.whl (3.9 MB)\n",
            "Collecting six\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting PyYAML<5.5,>=3.10\n",
            "  Using cached PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Collecting botocore==1.27.57\n",
            "  Using cached botocore-1.27.57-py3-none-any.whl (9.1 MB)\n",
            "Collecting rsa<4.8,>=3.1.2\n",
            "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting docutils<0.17,>=0.10\n",
            "  Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "Collecting colorama<0.4.5,>=0.2.5\n",
            "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.1\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting pyasn1>=0.1.3\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Installing collected packages: six, urllib3, python-dateutil, jmespath, pyasn1, botocore, s3transfer, rsa, PyYAML, docutils, colorama, awscli\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "awsebcli 3.20.3 requires botocore<1.24.0,>1.23.41, but you have botocore 1.27.57 which is incompatible.\n",
            "awsebcli 3.20.3 requires colorama<0.4.4,>=0.2.5, but you have colorama 0.4.4 which is incompatible.\n",
            "awsebcli 3.20.3 requires six<1.15.0,>=1.11.0, but you have six 1.16.0 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-5.4.1 awscli-1.25.58 botocore-1.27.57 colorama-0.4.4 docutils-0.17.1 jmespath-1.0.1 pyasn1-0.4.8 python-dateutil-2.8.2 rsa-4.9 s3transfer-0.6.0 six-1.16.0 urllib3-1.26.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "colorama",
                  "dateutil",
                  "six",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement botocore==1.29 (from versions: 0.4.1, 0.4.2, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.6.0, 0.7.0, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.9.0, 0.9.1, 0.9.2, 0.10.0, 0.11.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.15.0, 0.15.1, 0.16.0, 0.17.0, 0.18.0, 0.19.0, 0.20.0, 0.21.0, 0.22.0, 0.23.0, 0.24.0, 0.25.0, 0.26.0, 0.27.0, 0.28.0, 0.29.0, 0.30.0, 0.31.0, 0.32.0, 0.33.0, 0.34.0, 0.35.0, 0.36.0, 0.37.0, 0.38.0, 0.39.0, 0.40.0, 0.41.0, 0.42.0, 0.43.0, 0.44.0, 0.45.0, 0.46.0, 0.47.0, 0.48.0, 0.49.0, 0.50.0, 0.51.0, 0.52.0, 0.53.0, 0.54.0, 0.55.0, 0.56.0, 0.57.0, 0.58.0, 0.59.0, 0.60.0, 0.61.0, 0.62.0, 0.63.0, 0.64.0, 0.65.0, 0.66.0, 0.67.0, 0.68.0, 0.69.0, 0.70.0, 0.71.0, 0.72.0, 0.73.0, 0.74.0, 0.75.0, 0.76.0, 0.77.0, 0.78.0, 0.79.0, 0.80.0, 0.81.0, 0.82.0, 0.83.0, 0.84.0, 0.85.0, 0.86.0, 0.87.0, 0.88.0, 0.89.0, 0.90.0, 0.91.0, 0.92.0, 0.93.0, 0.94.0, 0.95.0, 0.96.0, 0.97.0, 0.98.0, 0.99.0, 0.100.0, 0.101.0, 0.102.0, 0.103.0, 0.104.0, 0.105.0, 0.106.0, 0.107.0, 0.108.0, 0.109.0, 1.0.0a1, 1.0.0a2, 1.0.0a3, 1.0.0b1, 1.0.0b2, 1.0.0b3, 1.0.0rc1, 1.0.0, 1.0.1, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.1.6, 1.1.7, 1.1.8, 1.1.9, 1.1.10, 1.1.11, 1.1.12, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.2.5, 1.2.6, 1.2.7, 1.2.8, 1.2.9, 1.2.10, 1.2.11, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.3.6, 1.3.7, 1.3.8, 1.3.9, 1.3.10, 1.3.11, 1.3.12, 1.3.13, 1.3.14, 1.3.15, 1.3.16, 1.3.17, 1.3.18, 1.3.19, 1.3.20, 1.3.21, 1.3.22, 1.3.23, 1.3.24, 1.3.25, 1.3.26, 1.3.27, 1.3.28, 1.3.29, 1.3.30, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.4.4, 1.4.5, 1.4.6, 1.4.7, 1.4.8, 1.4.9, 1.4.10, 1.4.11, 1.4.12, 1.4.13, 1.4.14, 1.4.15, 1.4.16, 1.4.17, 1.4.18, 1.4.19, 1.4.20, 1.4.21, 1.4.22, 1.4.23, 1.4.24, 1.4.25, 1.4.26, 1.4.27, 1.4.28, 1.4.29, 1.4.30, 1.4.31, 1.4.32, 1.4.33, 1.4.34, 1.4.35, 1.4.36, 1.4.37, 1.4.38, 1.4.39, 1.4.40, 1.4.41, 1.4.42, 1.4.43, 1.4.44, 1.4.46, 1.4.47, 1.4.48, 1.4.49, 1.4.50, 1.4.51, 1.4.52, 1.4.53, 1.4.54, 1.4.55, 1.4.56, 1.4.57, 1.4.58, 1.4.59, 1.4.60, 1.4.61, 1.4.62, 1.4.63, 1.4.64, 1.4.65, 1.4.66, 1.4.67, 1.4.68, 1.4.69, 1.4.70, 1.4.71, 1.4.72, 1.4.73, 1.4.74, 1.4.75, 1.4.76, 1.4.77, 1.4.78, 1.4.79, 1.4.80, 1.4.81, 1.4.82, 1.4.83, 1.4.84, 1.4.85, 1.4.86, 1.4.87, 1.4.88, 1.4.89, 1.4.90, 1.4.91, 1.4.92, 1.4.93, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.5.5, 1.5.6, 1.5.7, 1.5.8, 1.5.9, 1.5.10, 1.5.11, 1.5.12, 1.5.13, 1.5.14, 1.5.15, 1.5.16, 1.5.17, 1.5.18, 1.5.19, 1.5.20, 1.5.21, 1.5.22, 1.5.23, 1.5.24, 1.5.25, 1.5.26, 1.5.27, 1.5.28, 1.5.29, 1.5.30, 1.5.31, 1.5.32, 1.5.33, 1.5.34, 1.5.35, 1.5.36, 1.5.37, 1.5.38, 1.5.39, 1.5.40, 1.5.41, 1.5.42, 1.5.43, 1.5.44, 1.5.45, 1.5.46, 1.5.47, 1.5.48, 1.5.49, 1.5.50, 1.5.51, 1.5.52, 1.5.53, 1.5.54, 1.5.55, 1.5.56, 1.5.57, 1.5.58, 1.5.59, 1.5.60, 1.5.61, 1.5.62, 1.5.63, 1.5.64, 1.5.65, 1.5.66, 1.5.67, 1.5.68, 1.5.69, 1.5.70, 1.5.71, 1.5.72, 1.5.73, 1.5.74, 1.5.75, 1.5.76, 1.5.77, 1.5.78, 1.5.79, 1.5.80, 1.5.81, 1.5.82, 1.5.83, 1.5.84, 1.5.85, 1.5.86, 1.5.87, 1.5.88, 1.5.89, 1.5.90, 1.5.91, 1.5.92, 1.5.93, 1.5.94, 1.5.95, 1.6.0, 1.6.1, 1.6.2, 1.6.3, 1.6.4, 1.6.5, 1.6.6, 1.6.7, 1.6.8, 1.7.0, 1.7.1, 1.7.2, 1.7.3, 1.7.4, 1.7.5, 1.7.6, 1.7.7, 1.7.8, 1.7.9, 1.7.10, 1.7.11, 1.7.12, 1.7.13, 1.7.14, 1.7.15, 1.7.16, 1.7.17, 1.7.18, 1.7.19, 1.7.20, 1.7.21, 1.7.22, 1.7.23, 1.7.24, 1.7.25, 1.7.26, 1.7.27, 1.7.28, 1.7.29, 1.7.30, 1.7.31, 1.7.32, 1.7.33, 1.7.34, 1.7.35, 1.7.36, 1.7.37, 1.7.38, 1.7.39, 1.7.40, 1.7.41, 1.7.42, 1.7.43, 1.7.44, 1.7.45, 1.7.46, 1.7.47, 1.7.48, 1.8.0, 1.8.1, 1.8.2, 1.8.3, 1.8.4, 1.8.5, 1.8.6, 1.8.7, 1.8.8, 1.8.9, 1.8.10, 1.8.11, 1.8.12, 1.8.13, 1.8.14, 1.8.15, 1.8.16, 1.8.17, 1.8.18, 1.8.19, 1.8.20, 1.8.21, 1.8.22, 1.8.23, 1.8.24, 1.8.25, 1.8.26, 1.8.27, 1.8.28, 1.8.29, 1.8.30, 1.8.31, 1.8.32, 1.8.33, 1.8.34, 1.8.35, 1.8.36, 1.8.37, 1.8.38, 1.8.39, 1.8.40, 1.8.41, 1.8.42, 1.8.43, 1.8.44, 1.8.45, 1.8.46, 1.8.47, 1.8.48, 1.8.49, 1.8.50, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.9.4, 1.9.5, 1.9.6, 1.9.7, 1.9.8, 1.9.9, 1.9.10, 1.9.11, 1.9.12, 1.9.13, 1.9.14, 1.9.15, 1.9.16, 1.9.17, 1.9.18, 1.9.19, 1.9.20, 1.9.21, 1.9.22, 1.9.23, 1.10.0, 1.10.1, 1.10.2, 1.10.3, 1.10.4, 1.10.5, 1.10.6, 1.10.7, 1.10.8, 1.10.9, 1.10.10, 1.10.11, 1.10.12, 1.10.13, 1.10.14, 1.10.15, 1.10.16, 1.10.17, 1.10.18, 1.10.19, 1.10.20, 1.10.21, 1.10.22, 1.10.23, 1.10.24, 1.10.25, 1.10.26, 1.10.27, 1.10.28, 1.10.29, 1.10.30, 1.10.31, 1.10.32, 1.10.33, 1.10.34, 1.10.35, 1.10.36, 1.10.37, 1.10.38, 1.10.39, 1.10.40, 1.10.41, 1.10.42, 1.10.43, 1.10.44, 1.10.45, 1.10.46, 1.10.47, 1.10.48, 1.10.49, 1.10.50, 1.10.51, 1.10.52, 1.10.53, 1.10.54, 1.10.55, 1.10.56, 1.10.57, 1.10.58, 1.10.59, 1.10.60, 1.10.61, 1.10.62, 1.10.63, 1.10.64, 1.10.65, 1.10.66, 1.10.67, 1.10.68, 1.10.69, 1.10.70, 1.10.71, 1.10.72, 1.10.73, 1.10.74, 1.10.75, 1.10.76, 1.10.77, 1.10.78, 1.10.79, 1.10.80, 1.10.81, 1.10.82, 1.10.83, 1.10.84, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.11.5, 1.11.6, 1.11.7, 1.11.8, 1.11.9, 1.12.0, 1.12.1, 1.12.2, 1.12.3, 1.12.4, 1.12.5, 1.12.6, 1.12.7, 1.12.8, 1.12.9, 1.12.10, 1.12.11, 1.12.12, 1.12.13, 1.12.14, 1.12.15, 1.12.16, 1.12.17, 1.12.18, 1.12.19, 1.12.20, 1.12.21, 1.12.22, 1.12.23, 1.12.24, 1.12.25, 1.12.26, 1.12.27, 1.12.28, 1.12.29, 1.12.30, 1.12.31, 1.12.32, 1.12.33, 1.12.34, 1.12.35, 1.12.36, 1.12.37, 1.12.38, 1.12.39, 1.12.40, 1.12.41, 1.12.42, 1.12.43, 1.12.44, 1.12.45, 1.12.46, 1.12.47, 1.12.48, 1.12.49, 1.12.50, 1.12.51, 1.12.52, 1.12.53, 1.12.54, 1.12.55, 1.12.56, 1.12.57, 1.12.58, 1.12.59, 1.12.60, 1.12.61, 1.12.62, 1.12.63, 1.12.64, 1.12.65, 1.12.66, 1.12.67, 1.12.68, 1.12.69, 1.12.70, 1.12.71, 1.12.72, 1.12.73, 1.12.74, 1.12.75, 1.12.76, 1.12.77, 1.12.78, 1.12.79, 1.12.80, 1.12.81, 1.12.82, 1.12.83, 1.12.84, 1.12.85, 1.12.86, 1.12.87, 1.12.88, 1.12.89, 1.12.90, 1.12.91, 1.12.92, 1.12.93, 1.12.94, 1.12.95, 1.12.96, 1.12.97, 1.12.98, 1.12.99, 1.12.100, 1.12.101, 1.12.102, 1.12.103, 1.12.104, 1.12.105, 1.12.106, 1.12.107, 1.12.108, 1.12.109, 1.12.110, 1.12.111, 1.12.112, 1.12.113, 1.12.114, 1.12.115, 1.12.116, 1.12.117, 1.12.118, 1.12.119, 1.12.120, 1.12.121, 1.12.122, 1.12.123, 1.12.124, 1.12.125, 1.12.126, 1.12.127, 1.12.128, 1.12.129, 1.12.130, 1.12.131, 1.12.132, 1.12.133, 1.12.134, 1.12.135, 1.12.136, 1.12.137, 1.12.138, 1.12.139, 1.12.140, 1.12.141, 1.12.142, 1.12.143, 1.12.144, 1.12.145, 1.12.146, 1.12.147, 1.12.148, 1.12.149, 1.12.150, 1.12.151, 1.12.152, 1.12.153, 1.12.154, 1.12.155, 1.12.156, 1.12.157, 1.12.158, 1.12.159, 1.12.160, 1.12.161, 1.12.162, 1.12.163, 1.12.164, 1.12.165, 1.12.166, 1.12.167, 1.12.168, 1.12.169, 1.12.170, 1.12.171, 1.12.172, 1.12.173, 1.12.174, 1.12.175, 1.12.176, 1.12.177, 1.12.178, 1.12.179, 1.12.180, 1.12.181, 1.12.182, 1.12.183, 1.12.184, 1.12.185, 1.12.186, 1.12.187, 1.12.188, 1.12.189, 1.12.190, 1.12.191, 1.12.192, 1.12.193, 1.12.194, 1.12.195, 1.12.196, 1.12.197, 1.12.198, 1.12.199, 1.12.200, 1.12.201, 1.12.202, 1.12.203, 1.12.204, 1.12.205, 1.12.206, 1.12.207, 1.12.208, 1.12.209, 1.12.210, 1.12.211, 1.12.212, 1.12.213, 1.12.214, 1.12.215, 1.12.216, 1.12.217, 1.12.218, 1.12.219, 1.12.220, 1.12.221, 1.12.222, 1.12.223, 1.12.224, 1.12.225, 1.12.226, 1.12.227, 1.12.228, 1.12.229, 1.12.230, 1.12.231, 1.12.232, 1.12.233, 1.12.234, 1.12.235, 1.12.236, 1.12.237, 1.12.238, 1.12.239, 1.12.240, 1.12.241, 1.12.242, 1.12.243, 1.12.244, 1.12.245, 1.12.246, 1.12.247, 1.12.248, 1.12.249, 1.12.250, 1.12.251, 1.12.252, 1.12.253, 1.13.0, 1.13.1, 1.13.2, 1.13.3, 1.13.4, 1.13.5, 1.13.6, 1.13.7, 1.13.8, 1.13.9, 1.13.10, 1.13.11, 1.13.12, 1.13.13, 1.13.14, 1.13.15, 1.13.16, 1.13.17, 1.13.18, 1.13.19, 1.13.20, 1.13.21, 1.13.22, 1.13.23, 1.13.24, 1.13.25, 1.13.26, 1.13.27, 1.13.28, 1.13.29, 1.13.30, 1.13.31, 1.13.32, 1.13.33, 1.13.34, 1.13.35, 1.13.36, 1.13.37, 1.13.38, 1.13.39, 1.13.40, 1.13.41, 1.13.42, 1.13.43, 1.13.44, 1.13.45, 1.13.46, 1.13.47, 1.13.48, 1.13.49, 1.13.50, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.14.7, 1.14.8, 1.14.9, 1.14.10, 1.14.11, 1.14.12, 1.14.13, 1.14.14, 1.14.15, 1.14.16, 1.14.17, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 1.15.6, 1.15.7, 1.15.8, 1.15.9, 1.15.10, 1.15.11, 1.15.12, 1.15.13, 1.15.14, 1.15.15, 1.15.16, 1.15.17, 1.15.18, 1.15.19, 1.15.20, 1.15.21, 1.15.22, 1.15.23, 1.15.24, 1.15.25, 1.15.26, 1.15.27, 1.15.28, 1.15.29, 1.15.30, 1.15.31, 1.15.32, 1.15.33, 1.15.34, 1.15.35, 1.15.36, 1.15.37, 1.15.38, 1.15.39, 1.15.40, 1.15.41, 1.15.42, 1.15.43, 1.15.44, 1.15.45, 1.15.46, 1.15.47, 1.15.48, 1.15.49, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.16.7, 1.16.8, 1.16.9, 1.16.10, 1.16.11, 1.16.12, 1.16.13, 1.16.14, 1.16.15, 1.16.16, 1.16.17, 1.16.18, 1.16.19, 1.16.20, 1.16.21, 1.16.22, 1.16.23, 1.16.24, 1.16.25, 1.16.26, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.17.6, 1.17.7, 1.17.8, 1.17.9, 1.17.10, 1.17.11, 1.17.12, 1.17.13, 1.17.14, 1.17.15, 1.17.16, 1.17.17, 1.17.18, 1.17.19, 1.17.20, 1.17.21, 1.17.22, 1.17.23, 1.17.24, 1.17.25, 1.17.26, 1.17.27, 1.17.28, 1.17.29, 1.17.30, 1.17.31, 1.17.32, 1.17.33, 1.17.34, 1.17.35, 1.17.36, 1.17.37, 1.17.38, 1.17.39, 1.17.40, 1.17.41, 1.17.42, 1.17.43, 1.17.44, 1.17.45, 1.17.46, 1.17.47, 1.17.48, 1.17.49, 1.17.50, 1.17.51, 1.17.52, 1.17.53, 1.17.54, 1.17.55, 1.17.56, 1.17.57, 1.17.58, 1.17.59, 1.17.60, 1.17.61, 1.17.62, 1.17.63, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.18.6, 1.18.7, 1.18.8, 1.18.9, 1.18.10, 1.18.11, 1.18.12, 1.18.13, 1.18.14, 1.18.15, 1.18.16, 1.18.17, 1.18.18, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.19.6, 1.19.7, 1.19.8, 1.19.9, 1.19.10, 1.19.11, 1.19.12, 1.19.13, 1.19.14, 1.19.15, 1.19.16, 1.19.17, 1.19.18, 1.19.19, 1.19.20, 1.19.21, 1.19.22, 1.19.23, 1.19.24, 1.19.25, 1.19.26, 1.19.27, 1.19.28, 1.19.29, 1.19.30, 1.19.31, 1.19.32, 1.19.33, 1.19.34, 1.19.35, 1.19.36, 1.19.37, 1.19.38, 1.19.39, 1.19.40, 1.19.41, 1.19.42, 1.19.43, 1.19.44, 1.19.45, 1.19.46, 1.19.47, 1.19.48, 1.19.49, 1.19.50, 1.19.51, 1.19.52, 1.19.53, 1.19.54, 1.19.55, 1.19.56, 1.19.57, 1.19.58, 1.19.59, 1.19.60, 1.19.61, 1.19.62, 1.19.63, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.20.4, 1.20.5, 1.20.6, 1.20.7, 1.20.8, 1.20.9, 1.20.10, 1.20.11, 1.20.12, 1.20.13, 1.20.14, 1.20.15, 1.20.16, 1.20.17, 1.20.18, 1.20.19, 1.20.20, 1.20.21, 1.20.22, 1.20.23, 1.20.24, 1.20.25, 1.20.26, 1.20.27, 1.20.28, 1.20.29, 1.20.30, 1.20.31, 1.20.32, 1.20.33, 1.20.34, 1.20.35, 1.20.36, 1.20.37, 1.20.38, 1.20.39, 1.20.40, 1.20.41, 1.20.42, 1.20.43, 1.20.44, 1.20.45, 1.20.46, 1.20.47, 1.20.48, 1.20.49, 1.20.50, 1.20.51, 1.20.52, 1.20.53, 1.20.54, 1.20.55, 1.20.56, 1.20.57, 1.20.58, 1.20.59, 1.20.60, 1.20.61, 1.20.62, 1.20.63, 1.20.64, 1.20.65, 1.20.66, 1.20.67, 1.20.68, 1.20.69, 1.20.70, 1.20.71, 1.20.72, 1.20.73, 1.20.74, 1.20.75, 1.20.76, 1.20.77, 1.20.78, 1.20.79, 1.20.80, 1.20.81, 1.20.82, 1.20.83, 1.20.84, 1.20.85, 1.20.86, 1.20.87, 1.20.88, 1.20.89, 1.20.90, 1.20.91, 1.20.92, 1.20.93, 1.20.94, 1.20.95, 1.20.96, 1.20.97, 1.20.98, 1.20.99, 1.20.100, 1.20.101, 1.20.102, 1.20.103, 1.20.104, 1.20.105, 1.20.106, 1.20.107, 1.20.108, 1.20.109, 1.20.110, 1.20.111, 1.20.112, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.21.7, 1.21.8, 1.21.9, 1.21.10, 1.21.11, 1.21.12, 1.21.13, 1.21.14, 1.21.15, 1.21.16, 1.21.17, 1.21.18, 1.21.19, 1.21.20, 1.21.21, 1.21.22, 1.21.23, 1.21.24, 1.21.25, 1.21.26, 1.21.27, 1.21.28, 1.21.29, 1.21.30, 1.21.31, 1.21.32, 1.21.33, 1.21.34, 1.21.35, 1.21.36, 1.21.37, 1.21.38, 1.21.39, 1.21.40, 1.21.41, 1.21.42, 1.21.43, 1.21.44, 1.21.45, 1.21.46, 1.21.47, 1.21.48, 1.21.49, 1.21.50, 1.21.51, 1.21.52, 1.21.53, 1.21.54, 1.21.55, 1.21.56, 1.21.57, 1.21.58, 1.21.59, 1.21.60, 1.21.61, 1.21.62, 1.21.63, 1.21.64, 1.21.65, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.22.5, 1.22.6, 1.22.7, 1.22.8, 1.22.9, 1.22.10, 1.22.11, 1.22.12, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.23.6, 1.23.7, 1.23.8, 1.23.9, 1.23.10, 1.23.11, 1.23.12, 1.23.13, 1.23.14, 1.23.15, 1.23.16, 1.23.17, 1.23.18, 1.23.19, 1.23.20, 1.23.21, 1.23.22, 1.23.23, 1.23.24, 1.23.25, 1.23.26, 1.23.27, 1.23.28, 1.23.29, 1.23.30, 1.23.31, 1.23.32, 1.23.33, 1.23.34, 1.23.35, 1.23.36, 1.23.37, 1.23.38, 1.23.39, 1.23.40, 1.23.41, 1.23.42, 1.23.43, 1.23.44, 1.23.45, 1.23.46, 1.23.47, 1.23.48, 1.23.49, 1.23.50, 1.23.51, 1.23.52, 1.23.53, 1.23.54, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.24.5, 1.24.6, 1.24.7, 1.24.8, 1.24.9, 1.24.10, 1.24.11, 1.24.12, 1.24.13, 1.24.14, 1.24.15, 1.24.16, 1.24.17, 1.24.18, 1.24.19, 1.24.20, 1.24.21, 1.24.22, 1.24.23, 1.24.24, 1.24.25, 1.24.26, 1.24.27, 1.24.28, 1.24.29, 1.24.30, 1.24.31, 1.24.32, 1.24.33, 1.24.34, 1.24.35, 1.24.36, 1.24.37, 1.24.38, 1.24.39, 1.24.40, 1.24.41, 1.24.42, 1.24.43, 1.24.44, 1.24.45, 1.24.46, 1.25.0, 1.25.1, 1.25.2, 1.25.3, 1.25.4, 1.25.5, 1.25.6, 1.25.7, 1.25.8, 1.25.9, 1.25.10, 1.25.11, 1.25.12, 1.25.13, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 1.26.5, 1.26.6, 1.26.7, 1.26.8, 1.26.9, 1.26.10, 1.27.0, 1.27.1, 1.27.2, 1.27.3, 1.27.4, 1.27.5, 1.27.6, 1.27.7, 1.27.8, 1.27.9, 1.27.10, 1.27.11, 1.27.12, 1.27.13, 1.27.14, 1.27.15, 1.27.16, 1.27.17, 1.27.18, 1.27.19, 1.27.20, 1.27.21, 1.27.22, 1.27.23, 1.27.24, 1.27.25, 1.27.26, 1.27.27, 1.27.28, 1.27.29, 1.27.30, 1.27.31, 1.27.32, 1.27.33, 1.27.34, 1.27.35, 1.27.36, 1.27.37, 1.27.38, 1.27.39, 1.27.40, 1.27.41, 1.27.42, 1.27.43, 1.27.44, 1.27.45, 1.27.46, 1.27.47, 1.27.48, 1.27.49, 1.27.50, 1.27.51, 1.27.52, 1.27.53, 1.27.54, 1.27.55, 1.27.56, 1.27.57)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for botocore==1.29\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.24.57)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.57 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.27.57)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.57->boto3) (1.26.12)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.57->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.57->boto3) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install awsebcli\n",
        "!pip install awscli --ignore-installed six\n",
        "!pip install botocore==1.29 --upgrade\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i41MHQuCVHwZ"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "from boto3.dynamodb.conditions import Key, Attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YQxfPBgHXuv"
      },
      "outputs": [],
      "source": [
        "dynamodb = boto3.resource('dynamodb',aws_access_key_id='AKIAJQE6ASOMCWSDQZ4Q', aws_secret_access_key='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', region_name='us-east-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write to Weather - PB"
      ],
      "metadata": {
        "id": "6nzKn2HQMjF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LuckyWeatherNumbers = dynamodb.Table('LuckyWeatherNumbers')\n",
        "print(LuckyWeatherNumbers.creation_date_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaF9m3QRMsQ-",
        "outputId": "e308ab60-f9af-47f2-fb5d-0077e487cb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-11-14 06:15:53.690000+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Powerball lotto (https://data.ny.gov/resource/d6yy-54nr.json)\n",
        "client = Socrata(\"data.ny.gov\", None)\n",
        "results = client.get(\"8vkr-v8vh\", limit=5, order=\"draw_date DESC\", offset=0)\n",
        "# weather\n",
        "url = 'https://api.weatherstem.com/api'\n",
        "values = {\n",
        "    'api_key':'fso3dec6',\n",
        "    'stations':['fsus@leon.weatherstem.com','fsu@leon.weatherstem.com'],\n",
        "    'from': '2018-11-11 22:59:00',\n",
        "    'to': '2018-11-11 23:00:00',\n",
        "    'sensors':[\"Barometer\", \"Dewpoint\", \"Heat Index\", \"Hygrometer\", \"Thermometer\"]\n",
        "}\n",
        "\n",
        "for draw in results:\n",
        "    date_obj = datetime.strptime(draw['draw_date'], '%Y-%m-%dT%H:%M:%S.%f')\n",
        "    values['from'] = str(datetime.date(date_obj)) + \" 22:59:00\"\n",
        "    values['to'] = str(datetime.date(date_obj)) + \" 23:01:00\"\n",
        "    response = requests.post(url, data=json.dumps(values))\n",
        "    dayWeatherData = json.loads(response.text)\n",
        "    number_POS = draw['winning_numbers'].split()\n",
        "    try:\n",
        "        DBentry = LuckyWeatherNumbers.put_item(\n",
        "        Item = {\n",
        "            'draw_date': str(datetime.date(date_obj)),\n",
        "            'night': str(datetime.date(date_obj).weekday()),\n",
        "            'POS1': number_POS[0],\n",
        "            'POS2': number_POS[1],\n",
        "            'POS3': number_POS[2],\n",
        "            'POS4': number_POS[3],\n",
        "            'POS5': number_POS[4],\n",
        "            'PWRB': number_POS[5],\n",
        "            'Station': dayWeatherData[0]['station']['handle'],\n",
        "            'Barometer': dayWeatherData[0][\"records\"][1][1],\n",
        "            'Dewpoint': dayWeatherData[0][\"records\"][1][2],\n",
        "            'Heat_Index': dayWeatherData[0][\"records\"][1][3],\n",
        "            'Hygrometer': dayWeatherData[0][\"records\"][1][4],\n",
        "            'Thermometer': dayWeatherData[0][\"records\"][1][5]\n",
        "            }\n",
        "        )\n",
        "        print(str(datetime.date(date_obj)), draw['winning_numbers'], DBentry['ResponseMetadata']['RequestId'])\n",
        "    except:\n",
        "        print(str(datetime.date(date_obj)), draw['winning_numbers'])\n",
        "        print(dayWeatherData[1][\"records\"])\n",
        "        try:\n",
        "            DBentry = LuckyWeatherNumbers.put_item(\n",
        "            Item = {\n",
        "                'draw_date': str(datetime.date(date_obj)),\n",
        "                'night': str(datetime.date(date_obj).weekday()),\n",
        "                'POS1': number_POS[0],\n",
        "                'POS2': number_POS[1],\n",
        "                'POS3': number_POS[2],\n",
        "                'POS4': number_POS[3],\n",
        "                'POS5': number_POS[4],\n",
        "                'PWRB': number_POS[5],\n",
        "                'Station': dayWeatherData[1]['station']['handle'],\n",
        "                'Barometer': dayWeatherData[1][\"records\"][1][1],\n",
        "                'Dewpoint': dayWeatherData[1][\"records\"][1][2],\n",
        "                'Heat_Index': dayWeatherData[1][\"records\"][1][3],\n",
        "                'Hygrometer': dayWeatherData[1][\"records\"][1][4],\n",
        "                'Thermometer': dayWeatherData[1][\"records\"][1][5]\n",
        "                }\n",
        "            )\n",
        "            print(str(datetime.date(date_obj)), draw['winning_numbers'], DBentry['ResponseMetadata']['RequestId'])\n",
        "        except:\n",
        "            print(str(datetime.date(date_obj)), draw['winning_numbers'])\n",
        "            continue\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E6igNqWMvTx",
        "outputId": "4b1535b5-bb1d-4800-b89a-31d727c9a6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-22 12 27 34 55 67 09 FNU8B7A74V7HR13KT7I80UN7H3VV4KQNSO5AEMVJF66Q9ASUAAJG\n",
            "2022-08-20 05 09 11 16 66 07 GLPB5N14Q2D1FQNLMVS4JE9VURVV4KQNSO5AEMVJF66Q9ASUAAJG\n",
            "2022-08-17 23 28 41 50 55 24 DF09L3TJP9LU3T9P38LR89DSVJVV4KQNSO5AEMVJF66Q9ASUAAJG\n",
            "2022-08-15 20 24 47 50 63 05 4ONESG99VPJV8J43CK4OAHIS1NVV4KQNSO5AEMVJF66Q9ASUAAJG\n",
            "2022-08-13 19 24 35 43 62 02 CHMJHJQVQJ2T0MRC69UOKEKOA7VV4KQNSO5AEMVJF66Q9ASUAAJG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igNwTrxijXGk"
      },
      "source": [
        "# predictionScore\n",
        "Score the results on triangular numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wjGInr3E_tt"
      },
      "outputs": [],
      "source": [
        "def predictionScore(prediction, sample):\n",
        "    sample = list(sample)\n",
        "    c = 0\n",
        "    for p in prediction:\n",
        "        if p in sample:\n",
        "            c += 1\n",
        "            sample.remove(p)\n",
        "    if c > 0:\n",
        "        #Triangular number\n",
        "        return ((c**2)+c)/(2)\n",
        "    else:\n",
        "        return c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wX3dIQTGOd6"
      },
      "source": [
        "# Get data for next draw day\n",
        "* Next draw day for Powerball\n",
        "* Weather for the next draw date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu0XhASKFgpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d39516-e788-404b-fd0c-aa2241141199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-23 15:47:19.754513\n",
            "1661378419 2022-08-24 22:00:19 2\n"
          ]
        }
      ],
      "source": [
        "utc=pytz.utc\n",
        "nextdraw_date = datetime.today()\n",
        "print(nextdraw_date)\n",
        "\n",
        "while nextdraw_date.weekday() != 0:\n",
        "    if nextdraw_date.weekday() == 2:\n",
        "        break\n",
        "    if nextdraw_date.weekday() == 5:\n",
        "        break\n",
        "    else:\n",
        "        nextdraw_date += timedelta(1)\n",
        "\n",
        "# manually set date\n",
        "#nextdraw_date = nextdraw_date.replace(year=2022, month=8, day=8)\n",
        "\n",
        "nextdraw_date = nextdraw_date.replace(hour=22, minute=0)\n",
        "nextdraw_date_utcepoch = int(nextdraw_date.astimezone(utc).timestamp())\n",
        "\n",
        "print(nextdraw_date_utcepoch, nextdraw_date.strftime(\"%Y-%m-%d %H:%M:%S\"), nextdraw_date.weekday())\n",
        "\n",
        "nextDrawResults = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEQAPd-YE6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5677f6-1d96-4b12-a62e-07876875d00c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29.97, 74.8, 86.84, 81, 81.06, 2]\n"
          ]
        }
      ],
      "source": [
        "## Get weather data for next draw date\n",
        "# 250 Marriott Dr | Tallahassee, FL 32301\n",
        "# lat: 30.439489\n",
        "# lon: -84.264712\n",
        "# hPa / 33.863886666667 = inHg (barometer)\n",
        "\n",
        "url = \"https://api.darksky.net/forecast/f6a6de11a8a5f55d5036ab0c6ed8650b/30.439489,-84.264712,\" + str(nextdraw_date_utcepoch) + \"?exclude=hourly,minutely,daily,alerts,flags\"\n",
        "response = requests.get(url)\n",
        "dayWeatherData = json.loads(response.text)\n",
        "#print(dayWeatherData['currently'])\n",
        "\n",
        "nextdraw_barometer = round((dayWeatherData['currently']['pressure'] / 33.863886666667), 3)\n",
        "nextdraw_dewPoint = dayWeatherData['currently']['dewPoint']\n",
        "nextdraw_apparentTemperature = dayWeatherData['currently']['apparentTemperature']\n",
        "nextdraw_humidity = int(dayWeatherData['currently']['humidity']*100)\n",
        "nextdraw_temperature = dayWeatherData['currently']['temperature']\n",
        "\n",
        "#print( nextdraw_barometer, nextdraw_dewPoint, nextdraw_apparentTemperature, nextdraw_humidity, nextdraw_temperature, nextdraw_date.weekday())\n",
        "nextdraw_set = [nextdraw_barometer, nextdraw_dewPoint, nextdraw_apparentTemperature, nextdraw_humidity, nextdraw_temperature, nextdraw_date.weekday()]\n",
        "print(nextdraw_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pgaZNhwmmnK"
      },
      "source": [
        "# Weather predictions\n",
        "What if the weather affected the way the numbers dropped? Well, if i did, this script should find it.\n",
        "*   Grab all the historic data\n",
        "*   Split up the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpPgQMfAHeLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "32c7bb5c-b097-493d-ea4b-52992eb3d5b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   POS1  POS2  POS3  POS4  POS5  PWRB  Barometer  Dewpoint  Heat_Index  \\\n",
              "0     7    42    49    62    69    23     30.072      55.0        57.0   \n",
              "1    40    43    48    59    69    19     30.234      57.0        61.0   \n",
              "2    12    17    30    45    62     5     29.917      67.0        75.0   \n",
              "3    11    13    55    56    69     4     30.144      63.0        77.0   \n",
              "4    10    31    41    63    67     5     29.974      71.0        83.0   \n",
              "\n",
              "   Hygrometer  Thermometer  night  \n",
              "0          95         56.5      2  \n",
              "1          86         61.0      5  \n",
              "2          80         73.6      5  \n",
              "3          66         75.2      2  \n",
              "4          76         79.3      5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-877615d1-0e58-4de1-83b2-4b25c4a9478c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>POS1</th>\n",
              "      <th>POS2</th>\n",
              "      <th>POS3</th>\n",
              "      <th>POS4</th>\n",
              "      <th>POS5</th>\n",
              "      <th>PWRB</th>\n",
              "      <th>Barometer</th>\n",
              "      <th>Dewpoint</th>\n",
              "      <th>Heat_Index</th>\n",
              "      <th>Hygrometer</th>\n",
              "      <th>Thermometer</th>\n",
              "      <th>night</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>42</td>\n",
              "      <td>49</td>\n",
              "      <td>62</td>\n",
              "      <td>69</td>\n",
              "      <td>23</td>\n",
              "      <td>30.072</td>\n",
              "      <td>55.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>95</td>\n",
              "      <td>56.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>43</td>\n",
              "      <td>48</td>\n",
              "      <td>59</td>\n",
              "      <td>69</td>\n",
              "      <td>19</td>\n",
              "      <td>30.234</td>\n",
              "      <td>57.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>86</td>\n",
              "      <td>61.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>30</td>\n",
              "      <td>45</td>\n",
              "      <td>62</td>\n",
              "      <td>5</td>\n",
              "      <td>29.917</td>\n",
              "      <td>67.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>80</td>\n",
              "      <td>73.6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>55</td>\n",
              "      <td>56</td>\n",
              "      <td>69</td>\n",
              "      <td>4</td>\n",
              "      <td>30.144</td>\n",
              "      <td>63.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>66</td>\n",
              "      <td>75.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "      <td>41</td>\n",
              "      <td>63</td>\n",
              "      <td>67</td>\n",
              "      <td>5</td>\n",
              "      <td>29.974</td>\n",
              "      <td>71.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>76</td>\n",
              "      <td>79.3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-877615d1-0e58-4de1-83b2-4b25c4a9478c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-877615d1-0e58-4de1-83b2-4b25c4a9478c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-877615d1-0e58-4de1-83b2-4b25c4a9478c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "table = dynamodb.Table('LuckyWeatherNumbers')\n",
        "#print(table.creation_date_time)\n",
        "\n",
        "# grab all the records...\n",
        "response = table.scan(\n",
        "    FilterExpression=Attr('night').gt('1') & Attr('PWRB').gt('0'),\n",
        "    ProjectionExpression='draw_date, POS1, POS2, POS3, POS4, POS5, PWRB, Barometer, Dewpoint, Heat_Index, Hygrometer, Thermometer, night',\n",
        "    Limit=1040\n",
        ")\n",
        "# put them in a dataframe\n",
        "df_w = pd.DataFrame(response['Items'])\n",
        "\n",
        "# make everything numeric\n",
        "for column in df_w:\n",
        "    # set all to numeric\n",
        "    df_w[column] = pd.to_numeric(df_w[column], errors='coerce')\n",
        "\n",
        "\n",
        "# re-sort the columns\n",
        "df_w = df_w[['POS1', 'POS2', 'POS3', 'POS4', 'POS5', 'PWRB', 'Barometer', 'Dewpoint', 'Heat_Index', 'Hygrometer', 'Thermometer', 'night']]\n",
        "\n",
        "#print('Shape of the dataset: ' + str(df_w.shape))\n",
        "df_w.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsfCgaXiHmJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce52afc3-0888-4270-b802-39ee9ca0d7f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The independent features set: \n",
            "[[30.072 55.    57.    95.    56.5    2.   ]\n",
            " [30.234 57.    61.    86.    61.     5.   ]\n",
            " [29.917 67.    75.    80.    73.6    5.   ]\n",
            " [30.144 63.    77.    66.    75.2    2.   ]\n",
            " [29.974 71.    83.    76.    79.3    5.   ]]\n",
            "The dependent variable: \n",
            "[[ 7 42 49 62 69 23]\n",
            " [40 43 48 59 69 19]\n",
            " [12 17 30 45 62  5]\n",
            " [11 13 55 56 69  4]\n",
            " [10 31 41 63 67  5]]\n"
          ]
        }
      ],
      "source": [
        "# Split the data into independent and dependent variables\n",
        "X = df_w.iloc[:,6:12].values\n",
        "y = df_w.iloc[:,0:6].values\n",
        "print('The independent features set: ')\n",
        "print(X[:5,:])\n",
        "print('The dependent variable: ')\n",
        "print(y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkVEWzD5Hm7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc9aeff-940b-4e32-c91a-c40c5614ff2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[30.048 67.    71.    94.    68.6    5.   ]\n",
            " [29.972 72.    81.    83.    77.9    2.   ]\n",
            " [29.97  61.2   65.7   88.    64.8    5.   ]]\n",
            "[[15 33 43 59 60  8]\n",
            " [ 4 22 24 31 33 10]\n",
            " [ 8 12 18 44 51 18]]\n",
            "Scaled:\n",
            "[[ 0.15178598  0.42627454  0.06710356  1.12776067  0.05010003  0.99646017]\n",
            " [-0.38506972  0.79597336  0.78977699  0.25969278  0.83829647 -1.00355241]\n",
            " [-0.3991975  -0.00257609 -0.31591336  0.65426909 -0.27195873  0.99646017]]\n",
            "X Scaled:\n",
            "[[ 0.30856102 -0.45421854 -0.93565847  1.21450431 -0.96858386 -0.99717114]\n",
            " [ 1.46340052 -0.30580618 -0.64786703  0.50411488 -0.58710603  1.00283689]\n",
            " [-0.79637802  0.4362556   0.359403    0.03052193  0.4810319   1.00283689]]\n"
          ]
        }
      ],
      "source": [
        "# Creating the Training and Test set from data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)#, random_state = 69)\n",
        "print(X_train[:3,:])\n",
        "#y_train = y_train.reshape(-1,1)\n",
        "print(y_train[:3])\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_fit_train = scaler.fit_transform(X_train)\n",
        "X_fit_test = scaler.transform(X_test)\n",
        "print('Scaled:')\n",
        "#X_fit_train = X_fit_train.reshape(-1,1)\n",
        "print(X_fit_train[:3,:])\n",
        "\n",
        "X_fit = scaler.fit_transform(X)\n",
        "print('X Scaled:')\n",
        "#X_fit = X_fit.reshape(-1,1)\n",
        "print(X_fit[:3,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS6KZT1BqR_t"
      },
      "source": [
        "# Random Forest - entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnYvXfXIHqjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba02ac41-73f7-48f1-c39b-bfa52988f789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1 ------\n",
            "[ 4  9 17 27 38 18] [ 4 26 32 55 64 18] [4] [18] 7\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 4 17 26 32 49 10] [ 8 25 34 38 41 10] [] [10] 6\n",
            "[17 19 26 61 62 15] [ 1 15 17 46 66 15] [17] [15] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "-----> Accuracy: 4.6667 | Match Score: 33 <------\n",
            "----- 2 ------\n",
            "[ 4 17 55 58 64 12] [20 33 36 47 52 12] [] [12] 6\n",
            "[ 3 20 32 37 58 12] [19 37 48 61 63 12] [37] [12] 7\n",
            "[ 4  7 15 41 44  4] [ 7 15 20 29 41 22] [41, 15, 7] [] 6\n",
            "[ 5 25 26 36 65  4] [ 8 31 39 40 43  4] [] [4] 6\n",
            "[ 1 19 31 43 52  6] [ 4 33 39 46 60  6] [] [6] 6\n",
            "[ 5  9 11 33 59 21] [11 33 44 59 67  8] [33, 11, 59] [] 6\n",
            "-----> Accuracy: 4.5 | Match Score: 37 <------\n",
            "----- 3 ------\n",
            "[ 1  3 44 19 57 11] [ 9 21 56 57 66 11] [57] [11] 7\n",
            "[ 3 15 29 54 57 10] [19 43 47 60 68 10] [] [10] 6\n",
            "[ 9 26 37 39 58 12] [ 8 12 42 46 56 12] [] [12] 6\n",
            "[ 3 12 20 21 33  1] [ 4 18 21 26 38  1] [21] [1] 7\n",
            "[ 4 14 23 27 56  4] [ 6  7 16 23 26  4] [23] [4] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 46 <------\n",
            "----- 4 ------\n",
            "[13 27 47 64 65  9] [17 18 49 59 66  9] [] [9] 6\n",
            "[ 1  3 13 15 44  2] [27 49 50 51 52  2] [] [2] 6\n",
            "[ 4  8 61 44 65  1] [ 9 23 56 58 68  1] [] [1] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 8 12 24 41 62  5] [ 2 12 32 50 65  5] [12] [5] 7\n",
            "-----> Accuracy: 3.3333 | Match Score: 38 <------\n",
            "----- 5 ------\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 1 14 21 53 63  1] [ 7 10 16 46 56  1] [] [1] 6\n",
            "[ 7 12 15 19 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 3.3333 | Match Score: 20 <------\n",
            "----- 6 ------\n",
            "[ 5 25 39 54 57 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10  2 39 43 58 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "[ 3  2 24 35 43  1] [ 3  6 19 26 44  1] [3] [1] 7\n",
            "-----> Accuracy: 5.0 | Match Score: 33 <------\n",
            "----- 7 ------\n",
            "[13 27 47 64 65  9] [17 18 49 59 66  9] [] [9] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[24 25 38 62 63  6] [28 30 32 36 58  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[ 1 12 13 36 62 15] [ 1 15 17 46 66 15] [1] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 4 33  7 61 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 65 <------\n",
            "----- 8 ------\n",
            "[ 5 16 26 50 68  9] [17 18 49 59 66  9] [] [9] 6\n",
            "[17 12 21 22 50  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 38 42 57 11] [ 4 39 48 50 51 11] [] [11] 6\n",
            "[ 8 27 31 36 67 11] [11 21 28 33 45 11] [] [11] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 43 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 3.8333 | Match Score: 45 <------\n",
            "----- 9 ------\n",
            "[24 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[ 5 55 59 64 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 38 <------\n",
            "----- 10 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 4 17 26 32 49 10] [ 8 25 34 38 41 10] [] [10] 6\n",
            "[23 25 39 54 64 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 8 37 52 53 58  5] [20 40 47 55 63  5] [] [5] 6\n",
            "[23 35 39 47 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 1 15 21 25 46  1] [ 7 10 16 46 56  1] [46] [1] 7\n",
            "[ 8 10 25 41 64  5] [ 2 12 32 50 65  5] [] [5] 6\n",
            "-----> Accuracy: 4.1667 | Match Score: 45 <------\n",
            "----- 11 ------\n",
            "[10  8 26 32 39 20] [10 30 51 57 63 20] [10] [20] 7\n",
            "[ 1 19 21 22 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 8  9 18 48 52 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[ 3 12 18 57 69 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 3.8333 | Match Score: 46 <------\n",
            "----- 12 ------\n",
            "[13 18 27 29 61  9] [17 18 49 59 66  9] [18] [9] 7\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[ 1 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1  3 13 15 44  2] [27 49 50 51 52  2] [] [2] 6\n",
            "[12 14 26 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1 28 43 67 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[ 5 25 26 44 62  4] [ 8 31 39 40 43  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 43 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 8 31 25 41 64  5] [ 2 12 32 50 65  5] [] [5] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 78 <------\n",
            "----- 13 ------\n",
            "[ 6 20 41 46 66  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[19 28 43 62 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[17 28 18 32 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 54 <------\n",
            "----- 14 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 43 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 8  9 18 48 52 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27 35 38 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 33 <------\n",
            "----- 15 ------\n",
            "[17 12 39 48 50  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 41 52 69  7] [19 28 41 42 51  7] [41, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[40 15 23 31 69 19] [ 2 23 40 59 69 13] [40, 69, 23] [] 6\n",
            "-----> Accuracy: 4.5 | Match Score: 49 <------\n",
            "----- 16 ------\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[ 8  8 35 52 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 3.8333 | Match Score: 46 <------\n",
            "----- 17 ------\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[ 1 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[14 15 21 32 64  1] [ 7 10 16 46 56  1] [] [1] 6\n",
            "[ 5  9 38 49 68 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27 35 38 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 39 <------\n",
            "----- 18 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 12 41 48 50  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 8 18 52 29 69  5] [20 40 47 55 63  5] [] [5] 6\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 5 43 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 8  9 18 48 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.8333 | Match Score: 52 <------\n",
            "----- 19 ------\n",
            "[ 5  9 33 46 68  9] [17 18 49 59 66  9] [] [9] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 2 23 31 44 68  6] [28 30 32 36 58  6] [] [6] 6\n",
            "[ 7 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 43 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 57 58 60 65  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 58 <------\n",
            "----- 20 ------\n",
            "[ 7 31 31 32 48 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[ 1 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 8  8 18 48 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 1  2  3 37 61 25] [ 7 17 27 29 40 25] [] [25] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 31 <------\n",
            "----- 21 ------\n",
            "[ 8  9 27 29 42  9] [17 18 49 59 66  9] [] [9] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "-----> Accuracy: 4.5 | Match Score: 32 <------\n",
            "----- 22 ------\n",
            "[ 2 57 58 60 65  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 2 15 23 31 59  3] [ 2 23 40 59 69 13] [2, 59, 23] [] 6\n",
            "-----> Accuracy: 3.6667 | Match Score: 12 <------\n",
            "----- 23 ------\n",
            "[ 8 17 49 52 59  1] [17 18 49 59 66  9] [17, 59, 49] [] 6\n",
            "[ 4  9 17 27 38 18] [ 4 26 32 55 64 18] [4] [18] 7\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 68 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 65 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.1667 | Match Score: 67 <------\n",
            "----- 24 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[ 1 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1  8 16 40 63  6] [ 6 14 38 39 65  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 52 <------\n",
            "----- 25 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 29 50 47 66 14] [16 25 36 44 55 14] [] [14] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 8 37 52 53 58  5] [20 40 47 55 63  5] [] [5] 6\n",
            "[ 5 55 59 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 5  8 41 27 68 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 1 11 18 37 61 25] [ 7 17 27 29 40 25] [] [25] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 58 <------\n",
            "----- 26 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[ 6 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 47 43 65 68  4] [19 43 47 60 68 10] [43, 68, 47] [] 6\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 5 43 48 56 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 3 35 18 57 69 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 50 <------\n",
            "----- 27 ------\n",
            "[ 8 12 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[ 5 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "-----> Accuracy: 4.1667 | Match Score: 33 <------\n",
            "----- 28 ------\n",
            "[ 8 17 49 52 59  1] [17 18 49 59 66  9] [17, 59, 49] [] 6\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 23 42 52 68  6] [ 6 14 38 39 65  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 43 45 61 65 14] [19 25 43 46 48 14] [43] [14] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 4.0 | Match Score: 52 <------\n",
            "----- 29 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 51 59 61 63 10] [19 43 47 60 68 10] [] [10] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 8  9 18 57 69 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 51 <------\n",
            "----- 30 ------\n",
            "[ 8 16 38 50 61  9] [17 18 49 59 66  9] [] [9] 6\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 68 <------\n",
            "----- 31 ------\n",
            "[ 8 17 47 64 65  9] [17 18 49 59 66  9] [17] [9] 7\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1 12 28 48 67 25] [18 42 53 62 66 25] [] [25] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 4.3333 | Match Score: 58 <------\n",
            "----- 32 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 2 14 26 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 5 36 48 57 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 12 34 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  9 17 27 38 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 5.1667 | Match Score: 58 <------\n",
            "----- 33 ------\n",
            "[ 1 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 38 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 4.3333 | Match Score: 53 <------\n",
            "----- 34 ------\n",
            "[ 8 17 27 46 69  9] [17 18 49 59 66  9] [17] [9] 7\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 65 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[ 5 13 48 38 63 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[23 55 48 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[ 1  6 22 42 61 25] [ 7 17 27 29 40 25] [] [25] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 65 <------\n",
            "----- 35 ------\n",
            "[ 4  9 17 27 38 18] [ 4 26 32 55 64 18] [4] [18] 7\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 47 50 65 68 10] [19 43 47 60 68 10] [68, 47] [10] 9\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 5 13 48 57 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 5 55 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 80 <------\n",
            "----- 36 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 15 43 54 69 10] [19 43 47 60 68 10] [43] [10] 7\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[40 43 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 3.6667 | Match Score: 46 <------\n",
            "----- 37 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 1  2 37  7 61 25] [ 7 17 27 29 40 25] [7] [25] 7\n",
            "-----> Accuracy: 4.6667 | Match Score: 40 <------\n",
            "----- 38 ------\n",
            "[ 7 15 18 32 68 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.0 | Match Score: 39 <------\n",
            "----- 39 ------\n",
            "[ 3  9 17 27 38 18] [ 4 26 32 55 64 18] [] [18] 6\n",
            "[ 1 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 13 48 57 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 31 34 36  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  8 38 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 65 <------\n",
            "----- 40 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 65 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[22 12 24 45 62  5] [ 2 12 32 50 65  5] [12] [5] 7\n",
            "[ 1  4 22 29 61 25] [ 7 17 27 29 40 25] [29] [25] 7\n",
            "[10 19 40 45 58 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "[ 5  2 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 68 <------\n",
            "----- 41 ------\n",
            "[ 4  9 17 27 38 18] [ 4 26 32 55 64 18] [4] [18] 7\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[ 8 15 31 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 13 48 57 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 68 <------\n",
            "----- 42 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 24 33 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 29 54 57 10] [19 43 47 60 68 10] [] [10] 6\n",
            "[ 3 33 45 53 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 57 <------\n",
            "----- 43 ------\n",
            "[ 1 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 39 62 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 65 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[40 43 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 58 <------\n",
            "----- 44 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[ 1 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 15 26 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 36 48 57 58 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[ 4 33  7 53 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[17  9 18 27 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.5 | Match Score: 61 <------\n",
            "----- 45 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 1 19 37 37 61 25] [ 7 17 27 29 40 25] [] [25] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 45 <------\n",
            "----- 46 ------\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 43 45 61 65 14] [19 25 43 46 48 14] [43] [14] 7\n",
            "[ 5 36 48 57 58 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[23 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 52 <------\n",
            "----- 47 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 29 54 57 10] [19 43 47 60 68 10] [] [10] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 54 <------\n",
            "----- 48 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 9 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  9 18 48 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[ 1 11 37 42 61 25] [ 7 17 27 29 40 25] [] [25] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 38 <------\n",
            "----- 49 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 14 33 36 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 57 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[14 28 43 65 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[ 3 33 45 59 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[10  9 18 43 68 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.8333 | Match Score: 52 <------\n",
            "----- 50 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 23 38 59 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 43 45 61 65 14] [19 25 43 46 48 14] [43] [14] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 43 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 67 <------\n",
            "----- 51 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 5 13 28 38 63 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  9 17 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.1667 | Match Score: 46 <------\n",
            "----- 52 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 2 11 25 66 67 26] [ 6  7 11 66 67 19] [11, 66, 67] [] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 38 57 69 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 51 <------\n",
            "----- 53 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 1 11 37 29 61 25] [ 7 17 27 29 40 25] [29] [25] 7\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 4.5 | Match Score: 53 <------\n",
            "----- 54 ------\n",
            "[ 8 17 49 52 59  1] [17 18 49 59 66  9] [17, 59, 49] [] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 38 57 69 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 47 <------\n",
            "----- 55 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 33 48 59 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 38 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[ 1  4 37 29 61 25] [ 7 17 27 29 40 25] [29] [25] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 75 <------\n",
            "----- 56 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[21  9 18 48 68 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.6667 | Match Score: 40 <------\n",
            "----- 57 ------\n",
            "[ 6 23 18 32 68 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 54 <------\n",
            "----- 58 ------\n",
            "[13 16 33 50 69  9] [17 18 49 59 66  9] [] [9] 6\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 67 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 68  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 52 <------\n",
            "----- 59 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 4.5 | Match Score: 53 <------\n",
            "----- 60 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 67 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 41 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27  9 18 57 69 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 66 <------\n",
            "----- 61 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 15 43 67 69 10] [19 43 47 60 68 10] [43] [10] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 31 34 36  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 2  9 18 27 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 6.1667 | Match Score: 56 <------\n",
            "----- 62 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[ 1 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 67 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[10 11 32 16 58 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 72 <------\n",
            "----- 63 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 5 55 28 64 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[ 4 33  7 53 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 4  9 38 27 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 58 <------\n",
            "----- 64 ------\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 41 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 53 <------\n",
            "----- 65 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 13 28 38 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[ 3  9 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 47 <------\n",
            "----- 66 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 46 <------\n",
            "----- 67 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 4 33 37 53 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5 17 18 43 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 47 <------\n",
            "----- 68 ------\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[10 12 31 36 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 1  2  7 52 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 66 <------\n",
            "----- 69 ------\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 13 48 56 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 48 <------\n",
            "----- 70 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.5 | Match Score: 32 <------\n",
            "----- 71 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 41 <------\n",
            "----- 72 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.3333 | Match Score: 46 <------\n",
            "----- 73 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 5 36 48 57 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 68  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 52 <------\n",
            "----- 74 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 46 <------\n",
            "----- 75 ------\n",
            "[13 17 33 50 62  9] [17 18 49 59 66  9] [17] [9] 7\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 2 21 23 31 59  3] [ 2 23 40 59 69 13] [2, 59, 23] [] 6\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 59 <------\n",
            "----- 76 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 53 <------\n",
            "----- 77 ------\n",
            "[ 7 12 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 67 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[ 4 33  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27 35 38 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 59 <------\n",
            "----- 78 ------\n",
            "[17 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 65 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 13 28 38 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[10 61 63 64 64 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 62 <------\n",
            "----- 79 ------\n",
            "[ 7 31 18 32 48 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 38 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 6.5 | Match Score: 68 <------\n",
            "----- 80 ------\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 56 <------\n",
            "----- 81 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 65 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 55 <------\n",
            "----- 82 ------\n",
            "[ 7 31 18 32 48 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 32 64 69 18] [ 5 21 36 61 62 18] [] [18] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 45 <------\n",
            "----- 83 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 65 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 53 <------\n",
            "----- 84 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 1  6 22 42 61 25] [ 7 17 27 29 40 25] [] [25] 6\n",
            "-----> Accuracy: 6.1667 | Match Score: 62 <------\n",
            "----- 85 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 32 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 12 34 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 5 13 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 67 <------\n",
            "----- 86 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 65 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 59 <------\n",
            "----- 87 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 48 <------\n",
            "----- 88 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[ 8 12 26 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 5.0 | Match Score: 53 <------\n",
            "----- 89 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 65 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 13 28 38 63 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 9 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[27 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 67 <------\n",
            "----- 90 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 15 31 61 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 43 65 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[ 5 13 48 38 69 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[ 4  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 18 27 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[23 33 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 79 <------\n",
            "----- 91 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 32 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 5 33 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 61 <------\n",
            "----- 92 ------\n",
            "[11 16 38 50 69  9] [17 18 49 59 66  9] [] [9] 6\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 33 45 61 59 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 31 34 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[23 33 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 63 <------\n",
            "----- 93 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.1667 | Match Score: 46 <------\n",
            "----- 94 ------\n",
            "[ 7 21 26 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 23 39 59 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[ 8 19 26 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 41 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[23 33 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 66 <------\n",
            "----- 95 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 8  9 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 51 <------\n",
            "----- 96 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 42 <------\n",
            "----- 97 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 8 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[ 5  2 28 38 63 21] [16 29 53 58 69 21] [] [21] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 60 <------\n",
            "----- 98 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 33 45 53 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 8  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27 35 38 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 60 <------\n",
            "----- 99 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 41 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[27 35 38 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[10 25 32 36 63 25] [ 3 27 36 56 69 25] [36] [25] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 69 <------\n",
            "----- 100 ------\n",
            "[ 7 23 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 43 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 41 27 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.6667 | Match Score: 56 <------\n",
            "----- 101 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[14 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 8 35 18 57 66 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 52 <------\n",
            "----- 102 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  9 18 27 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "[ 8 35 18 57 69 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 52 <------\n",
            "----- 103 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 61 <------\n",
            "----- 104 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[30 12 54 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 4 33  7 52 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.8333 | Match Score: 59 <------\n"
          ]
        }
      ],
      "source": [
        "winningScore = 0\n",
        "winningState = 0\n",
        "RFcriterion = \"entropy\"\n",
        "\n",
        "irandom_state = 1\n",
        "while irandom_state <= 104:\n",
        "    # Fitting Random Forest Classification to the Training set\n",
        "    RFclassifier = RandomForestClassifier(n_estimators=irandom_state, criterion=RFcriterion, random_state=irandom_state)\n",
        "    RFclassifier.fit(X_fit_train, y_train)\n",
        "    #print (RFclassifier)\n",
        "\n",
        "    # Compare the Test set results for Random Forest Classification\n",
        "    y_pred = RFclassifier.predict(X_fit_test)\n",
        "    \n",
        "    print('----- ' + str(irandom_state) + ' ------')\n",
        "    accuracyScore = 0\n",
        "    totalMatchScore = 0\n",
        "    for index, pred in enumerate(y_pred):\n",
        "        accuracy = accuracy_score(y_test[index], pred)\n",
        "        accuracyScore += accuracy\n",
        "        comparePOS = list(set(pred[:5]) & set(y_test[index][:5]))\n",
        "        comparePWB = list(set(pred[5:]) & set(y_test[index][5:]))\n",
        "        matchScore = predictionScore(pred[:5], y_test[index][:5]) + (predictionScore(pred[5:], y_test[index][5:])*6)\n",
        "        if matchScore >= 6:\n",
        "            totalMatchScore += matchScore\n",
        "            print(pred, y_test[index], comparePOS, comparePWB, str(int(matchScore)))\n",
        "        # Find the winner!\n",
        "        if totalMatchScore >= winningScore:\n",
        "            winningScore = totalMatchScore\n",
        "            winningState = irandom_state\n",
        "    print('-----> Accuracy: ' + str(round(accuracyScore,4)) + ' | Match Score: ' + str(int(totalMatchScore)) + ' <------')\n",
        "\n",
        "    irandom_state += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YILC2I7RHwl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6db7786-efce-41a8-e578-8a9e019c104d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----> Winner is 35 with 80 <------\n",
            "[ 3 17 49 58 68  8] [29.97, 74.8, 86.84, 81, 81.06, 2]\n"
          ]
        }
      ],
      "source": [
        "print('-----> Winner is ' + str(int(winningState)) + ' with ' + str(int(winningScore)) + ' <------')\n",
        "# Fitting Random Forest Classification to the Training set\n",
        "RFclassifier = RandomForestClassifier(n_estimators=int(winningState), criterion=RFcriterion, random_state=int(winningState))\n",
        "RFclassifier.fit(X_fit, y)\n",
        "\n",
        "# Predicting the next draw set results\n",
        "nextdraw_pred = RFclassifier.predict([nextdraw_set])\n",
        "print(nextdraw_pred[0], nextdraw_set)\n",
        "\n",
        "nextDrawResults.append([{\"numbers\":list(map(int, nextdraw_pred[0]))},{\"score\":int(winningScore)},{\"class\":\"weather - RandomForestClassifier - E\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTEDI9qR--M5"
      },
      "source": [
        "# Random Forest - gini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCFjaj0X--M5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53bc174-61fa-4033-9ee9-368323fc3401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1 ------\n",
            "[ 8 17 49 52 59  1] [17 18 49 59 66  9] [17, 59, 49] [] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.8333 | Match Score: 35 <------\n",
            "----- 2 ------\n",
            "[ 4  9 17 27 38 18] [ 4 26 32 55 64 18] [4] [18] 7\n",
            "[17 28 41 46 56  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[11 22 28 45 50  4] [ 8 31 39 40 43  4] [] [4] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 8 12 20 21 32 10] [ 5  6 15 29 42 10] [] [10] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 32 <------\n",
            "----- 3 ------\n",
            "[ 8 20 22 43 64  3] [22 39 43 62 64  7] [64, 43, 22] [] 6\n",
            "[ 3  7 15 41 44 10] [ 7 15 20 29 41 22] [41, 15, 7] [] 6\n",
            "[14 20 21 42 48  4] [11 13 55 56 69  4] [] [4] 6\n",
            "[ 8 12 18 44 51 12] [ 8 12 42 46 56 12] [8, 12] [12] 9\n",
            "[10 13 30 51 53  1] [ 4 18 21 26 38  1] [] [1] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 33 <------\n",
            "----- 4 ------\n",
            "[17 11 21 22 51  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 2 25 31 39 52  6] [28 30 32 36 58  6] [] [6] 6\n",
            "[ 3 28 37 40 53  1] [ 4 18 21 26 38  1] [] [1] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[22 23 21 23 25  5] [ 2 12 32 50 65  5] [] [5] 6\n",
            "-----> Accuracy: 4.0 | Match Score: 31 <------\n",
            "----- 5 ------\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[21 28 30 40 59 26] [ 2 17 33 51 63 26] [] [26] 6\n",
            "[24 61 63 64 64 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 2.8333 | Match Score: 34 <------\n",
            "----- 6 ------\n",
            "[ 8 17 49 52 59  1] [17 18 49 59 66  9] [17, 59, 49] [] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 29 54 57 10] [19 43 47 60 68 10] [] [10] 6\n",
            "[ 1 41 42 49 67 11] [11 21 28 33 45 11] [] [11] 6\n",
            "[23 55 59 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 1 15 21 32 69  1] [ 7 10 16 46 56  1] [] [1] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 6 28 48 63 64 24] [ 5 22 43 57 63 24] [63] [24] 7\n",
            "[40 43 45 50 61 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 58 <------\n",
            "----- 7 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[32 36 49 55 61 13] [ 6 15 50 59 60 13] [] [13] 6\n",
            "[ 1 57 18 60 66 26] [14 16 41 63 68 26] [] [26] 6\n",
            "[ 1  3 20 21 62 18] [14 16 37 48 58 18] [] [18] 6\n",
            "[ 4 11 24 31 33  5] [ 2 12 32 50 65  5] [] [5] 6\n",
            "-----> Accuracy: 4.0 | Match Score: 30 <------\n",
            "----- 8 ------\n",
            "[ 1  8 18 32 39 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 22 50 65 66 14] [16 25 36 44 55 14] [] [14] 6\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 5 12 20 21 30  1] [ 4 18 21 26 38  1] [21] [1] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 3.0 | Match Score: 39 <------\n",
            "----- 9 ------\n",
            "[ 8 27 47 59 60  9] [17 18 49 59 66  9] [59] [9] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "-----> Accuracy: 4.1667 | Match Score: 14 <------\n",
            "----- 10 ------\n",
            "[ 7 12 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[22 41 42 49 67 11] [11 21 28 33 45 11] [] [11] 6\n",
            "[10 28 43 67 68  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[ 4 17 32 29 68  9] [12 30 36 47 62  9] [] [9] 6\n",
            "[ 4  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 41 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 4  2 33 37 68 24] [ 2  6 40 42 55 24] [2] [24] 7\n",
            "-----> Accuracy: 4.8333 | Match Score: 71 <------\n",
            "----- 11 ------\n",
            "[ 2 15 31 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 33 45 42 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 1  2  7 36 47  4] [11 14 31 47 48  4] [47] [4] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  8 18 65 66 20] [ 3  7  9 31 33 20] [] [20] 6\n",
            "[ 5 13 23 40 50 18] [ 6 42 45 47 64 18] [] [18] 6\n",
            "-----> Accuracy: 4.1667 | Match Score: 52 <------\n",
            "----- 12 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[32 36 49 55 61 13] [ 6 15 50 59 60 13] [] [13] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[35 36 20 55 61 17] [ 2 12 17 20 65 17] [20] [17] 7\n",
            "[ 4  7 15 33 44 24] [ 5 22 43 57 63 24] [] [24] 6\n",
            "[ 4 19 40 45 58 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 54 <------\n",
            "----- 13 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[32 36 51 55 61 13] [ 6 15 50 59 60 13] [] [13] 6\n",
            "[23 24 35 54 67 11] [ 4 39 48 50 51 11] [] [11] 6\n",
            "[ 1 33  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[ 3 12 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.0 | Match Score: 37 <------\n",
            "----- 14 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 20 22 43 64 17] [22 39 43 62 64  7] [64, 43, 22] [] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 29 50 65 66 14] [16 25 36 44 55 14] [] [14] 6\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 1  2  7 52 62  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 2  9 20 38 39 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 5.1667 | Match Score: 51 <------\n",
            "----- 15 ------\n",
            "[ 7 15 32 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 19 41 22 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[17 19 26 61 62 15] [ 1 15 17 46 66 15] [17] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 25 45 51 56  2] [ 4 29 49 50 67  2] [] [2] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 12 19 32 64  1] [ 7 10 16 46 56  1] [] [1] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 54 <------\n",
            "----- 16 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 37 54 64 11] [ 4 39 48 50 51 11] [] [11] 6\n",
            "[ 3 15 29 54 57 10] [19 43 47 60 68 10] [] [10] 6\n",
            "[10 43 19 50 61 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 4.0 | Match Score: 24 <------\n",
            "----- 17 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 64 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 8 12 24 45 64  5] [ 2 12 32 50 65  5] [12] [5] 7\n",
            "[ 1 32 21 37 61 25] [ 7 17 27 29 40 25] [] [25] 6\n",
            "[ 4 43 45 50 61 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 6.0 | Match Score: 54 <------\n",
            "----- 18 ------\n",
            "[ 1 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 2 12 31 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 5 13 48 38 58 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[ 8 17 49 52 58  5] [20 40 47 55 63  5] [] [5] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 5.0 | Match Score: 38 <------\n",
            "----- 19 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 25 39 62 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[27 20 41 47 56 14] [16 25 36 44 55 14] [] [14] 6\n",
            "[19 28 43 65 68  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 6.1667 | Match Score: 49 <------\n",
            "----- 20 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 4.3333 | Match Score: 20 <------\n",
            "----- 21 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 28 <------\n",
            "----- 22 ------\n",
            "[17 20 41 49 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 65 68  4] [19 43 47 60 68 10] [19, 43, 68] [] 6\n",
            "[10 28 43 65 69  7] [19 28 41 42 51  7] [28] [7] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 6 28 48 63 64 24] [ 5 22 43 57 63 24] [63] [24] 7\n",
            "-----> Accuracy: 4.3333 | Match Score: 40 <------\n",
            "----- 23 ------\n",
            "[ 4  9 18 27 38 18] [ 4 26 32 55 64 18] [4] [18] 7\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 3 12 48 52 43 18] [ 4  6 16 30 56 18] [] [18] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[ 5 25 39 54 57 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 68  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 6.3333 | Match Score: 47 <------\n",
            "----- 24 ------\n",
            "[ 1 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[23 55 59 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 48 <------\n",
            "----- 25 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[ 8 19 26 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 7 20 38 65 66 14] [16 25 36 44 55 14] [] [14] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1 33 45 61 54 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 5 13 28 38 63 13] [ 8 23 37 52 63 13] [63] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 25 39 43 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 74 <------\n",
            "----- 26 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 7 36 48 57 58 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[ 8 17 49 52 59  5] [20 40 47 55 63  5] [] [5] 6\n",
            "[ 4  2  7 52 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 5.0 | Match Score: 38 <------\n",
            "----- 27 ------\n",
            "[ 1 20 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[27 35 18 57 52 10] [14 32 34 46 61 10] [] [10] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 19 <------\n",
            "----- 28 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[11 12 50 36 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[10 43 39 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 48 <------\n",
            "----- 29 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 19 43 58 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 6.0 | Match Score: 48 <------\n",
            "----- 30 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 21 38 59 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 39 <------\n",
            "----- 31 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 5  9 18 27 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 50 <------\n",
            "----- 32 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 25 38 59 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 32 64 64 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 6.0 | Match Score: 63 <------\n",
            "----- 33 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 19 26 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 45 <------\n",
            "----- 34 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[ 8 30 26 36 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 43 54 57 10] [19 43 47 60 68 10] [43] [10] 7\n",
            "[ 1  2  7 52 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[ 5 13 48 38 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 45 <------\n",
            "----- 35 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 3 33 45 53 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.5 | Match Score: 35 <------\n",
            "----- 36 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 28 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 4 43 45 50 58 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 61 <------\n",
            "----- 37 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 15 43 67 69 10] [19 43 47 60 68 10] [19, 43] [10] 9\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 37 <------\n",
            "----- 38 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[16 12 15 42 54 25] [18 42 53 62 66 25] [42] [25] 7\n",
            "[23 55 59 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 39 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 40 <------\n",
            "----- 39 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[11 12 30 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 43 54 57 10] [19 43 47 60 68 10] [43] [10] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 4.5 | Match Score: 40 <------\n",
            "----- 40 ------\n",
            "[ 4  9 17 27 38 18] [ 4 26 32 55 64 18] [4] [18] 7\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[20 23 39 40 60  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 4 28 15 41 64 24] [ 5 22 43 57 63 24] [] [24] 6\n",
            "[10 19 39 50 58 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 59 <------\n",
            "----- 41 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[ 8  9 18 48 52 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.3333 | Match Score: 35 <------\n",
            "----- 42 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 23 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 29 54 57 10] [19 43 47 60 68 10] [] [10] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[23 43 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 42 <------\n",
            "----- 43 ------\n",
            "[ 7 33 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 3 32 34 53 61  7] [22 39 43 62 64  7] [] [7] 6\n",
            "[14 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[21  9 18 27 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 4.5 | Match Score: 48 <------\n",
            "----- 44 ------\n",
            "[ 1 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 23 39 59 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.0 | Match Score: 43 <------\n",
            "----- 45 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[10 12 26 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 43 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 41 39 55 68  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 45 <------\n",
            "----- 46 ------\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 43 54 57 10] [19 43 47 60 68 10] [43] [10] 7\n",
            "[ 3 33 45 61 65 14] [19 25 43 46 48 14] [] [14] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "-----> Accuracy: 4.8333 | Match Score: 27 <------\n",
            "----- 47 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 43 54 69 10] [19 43 47 60 68 10] [43] [10] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 41 53 55 68  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[22 28 37 41 64 24] [ 5 22 43 57 63 24] [22] [24] 7\n",
            "-----> Accuracy: 5.0 | Match Score: 49 <------\n",
            "----- 48 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[10 28 37 63 64 24] [ 5 22 43 57 63 24] [63] [24] 7\n",
            "[40 43 45 50 61 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 32 <------\n",
            "----- 49 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 1  4 37 29 61 25] [ 7 17 27 29 40 25] [29] [25] 7\n",
            "-----> Accuracy: 4.3333 | Match Score: 40 <------\n",
            "----- 50 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "-----> Accuracy: 5.5 | Match Score: 26 <------\n",
            "----- 51 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 68 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 68  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 4.6667 | Match Score: 41 <------\n",
            "----- 52 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 10 12 17 68  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 42 <------\n",
            "----- 53 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 23 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 5  9 18 65 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 5.1667 | Match Score: 40 <------\n",
            "----- 54 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 4.6667 | Match Score: 49 <------\n",
            "----- 55 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[11 10 41 66 67 15] [ 6  7 11 66 67 19] [11, 66, 67] [] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 1 19 21 37 61 25] [ 7 17 27 29 40 25] [] [25] 6\n",
            "[10 43 39 50 61 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 4.5 | Match Score: 47 <------\n",
            "----- 56 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 15 31 61 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[10 43 39 50 68 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 49 <------\n",
            "----- 57 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[10 43 39 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 41 <------\n",
            "----- 58 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 31 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 6 43 19 50 56 25] [ 3 27 36 56 69 25] [56] [25] 7\n",
            "-----> Accuracy: 5.5 | Match Score: 42 <------\n",
            "----- 59 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[40 43 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 25 32 55 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 62 <------\n",
            "----- 60 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 4  2  7 52 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.1667 | Match Score: 35 <------\n",
            "----- 61 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 68  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.5 | Match Score: 36 <------\n",
            "----- 62 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[11 10 22 66 67 17] [ 6  7 11 66 67 19] [11, 66, 67] [] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1 33  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 31 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 47 <------\n",
            "----- 63 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[30 49 54 66 62 15] [ 1 15 17 46 66 15] [66] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 68  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 8 35 18 57 52 10] [14 32 34 46 61 10] [] [10] 6\n",
            "[10 43 19 50 68 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 6.1667 | Match Score: 53 <------\n",
            "----- 64 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 15 31 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 1 33  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 4.5 | Match Score: 33 <------\n",
            "----- 65 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[15 12 15 48 54 25] [18 42 53 62 66 25] [] [25] 6\n",
            "[ 1 33  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "-----> Accuracy: 4.1667 | Match Score: 48 <------\n",
            "----- 66 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 62 48 68 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 5.0 | Match Score: 33 <------\n",
            "----- 67 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 4.5 | Match Score: 34 <------\n",
            "----- 68 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 25 39 62 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 6.0 | Match Score: 56 <------\n",
            "----- 69 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 9 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[10 43 19 50 58 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 41 <------\n",
            "----- 70 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 32 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[10 43 39 50 66 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 41 <------\n",
            "----- 71 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 5 43 56 50 63 25] [ 3 27 36 56 69 25] [56] [25] 7\n",
            "-----> Accuracy: 4.5 | Match Score: 35 <------\n",
            "----- 72 ------\n",
            "[ 7 31 18 32 48 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 43 54 69 10] [19 43 47 60 68 10] [43] [10] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 43 45 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 48 <------\n",
            "----- 73 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 15 31 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 9 15 43 60 68  4] [19 43 47 60 68 10] [43, 68, 60] [] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 4 33  7 53 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 54 <------\n",
            "----- 74 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 36 <------\n",
            "----- 75 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 15 31 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 6.5 | Match Score: 56 <------\n",
            "----- 76 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 25 39 62 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[ 8 15 26 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 4 33 43 53 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[40 43 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 45 50 61 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 6.8333 | Match Score: 68 <------\n",
            "----- 77 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 5  9 18 48 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 5.3333 | Match Score: 36 <------\n",
            "----- 78 ------\n",
            "[ 7 23 32 32 68 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[13 20 39 47 65 14] [16 25 36 44 55 14] [] [14] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 9 41 53 17 68  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[10 43 45 50 67 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 44 <------\n",
            "----- 79 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[17 19 26 61 62 15] [ 1 15 17 46 66 15] [17] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 68  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 39 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 4.8333 | Match Score: 49 <------\n",
            "----- 80 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 4 33 43 53 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 12 34 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[10 43 39 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 54 <------\n",
            "----- 81 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 12 31 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 4 33  7 53 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 28 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[10 43 45 50 68 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 45 <------\n",
            "----- 82 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 35 <------\n",
            "----- 83 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[40 43 45 50 61 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.1667 | Match Score: 49 <------\n",
            "----- 84 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 1  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[ 8  9 18 48 66 20] [ 3  7  9 31 33 20] [9] [20] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 42 <------\n",
            "----- 85 ------\n",
            "[ 7 15 32 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 9 15 43 60 68  4] [19 43 47 60 68 10] [43, 68, 60] [] 6\n",
            "[19 15 43 67 69  7] [19 28 41 42 51  7] [19] [7] 7\n",
            "[ 5 13 28 57 63 24] [ 8 17 20 27 52 24] [] [24] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[40 43 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 2 21 23 31 59 19] [ 2 23 40 59 69 13] [2, 59, 23] [] 6\n",
            "-----> Accuracy: 5.8333 | Match Score: 57 <------\n",
            "----- 86 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 39 43 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 55 <------\n",
            "----- 87 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[16 29 27 55 67 25] [18 42 53 62 66 25] [] [25] 6\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.3333 | Match Score: 33 <------\n",
            "----- 88 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 15 31 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 59 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 6.0 | Match Score: 56 <------\n",
            "----- 89 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[24 25 39 62 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 4  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[ 2 15 23 31 59  3] [ 2 23 40 59 69 13] [2, 59, 23] [] 6\n",
            "[10 43 45 50 66 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 57 <------\n",
            "----- 90 ------\n",
            "[ 8  9 18 48 38 18] [ 4 26 32 55 64 18] [] [18] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[20 23 39 59 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[ 8 15 26 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 4  2  7 52 61  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[ 5 55 48 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 39 43 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 6.6667 | Match Score: 67 <------\n",
            "----- 91 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 25 39 40 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[10 19 40 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 42 <------\n",
            "----- 92 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[ 3 15 29 54 57 10] [19 43 47 60 68 10] [] [10] 6\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[ 4 33 43 53 65  4] [11 14 31 47 48  4] [] [4] 6\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 45 50 68 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.6667 | Match Score: 60 <------\n",
            "----- 93 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 25 39 62 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 49 <------\n",
            "----- 94 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[ 8 15 31 36 62 15] [ 1 15 17 46 66 15] [15] [15] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 15 43 67 69 10] [19 43 47 60 68 10] [19, 43] [10] 9\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 64 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 6 28 48 63 64 24] [ 5 22 43 57 63 24] [63] [24] 7\n",
            "-----> Accuracy: 5.8333 | Match Score: 66 <------\n",
            "----- 95 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 2 12 33 61 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 39 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 4.1667 | Match Score: 39 <------\n",
            "----- 96 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[40 43 45 50 61 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.3333 | Match Score: 28 <------\n",
            "----- 97 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[23 55 48 59 69 13] [ 8 23 37 52 63 13] [23] [13] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.3333 | Match Score: 50 <------\n",
            "----- 98 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 7 23 39 62 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[ 7 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 15 43 67 69  7] [19 28 41 42 51  7] [19] [7] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "[10 43 39 43 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 59 <------\n",
            "----- 99 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "-----> Accuracy: 4.6667 | Match Score: 20 <------\n",
            "----- 100 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 8 12 26 36 62 15] [ 1 15 17 46 66 15] [] [15] 6\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[10 43 45 50 63 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.0 | Match Score: 41 <------\n",
            "----- 101 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[24 61 32 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 10 12 17 23  8] [15 27 44 59 63  8] [] [8] 6\n",
            "-----> Accuracy: 4.6667 | Match Score: 33 <------\n",
            "----- 102 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[18 25 47 48 50 24] [31 32 37 38 48 24] [48] [24] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 56 50 68 25] [ 3 27 36 56 69 25] [56] [25] 7\n",
            "-----> Accuracy: 6.0 | Match Score: 50 <------\n",
            "----- 103 ------\n",
            "[ 4  9 18 27 67 18] [ 4 26 32 55 64 18] [4] [18] 7\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 38 62 63  6] [ 6 14 38 39 65  6] [38] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "[10 43 39 50 68 25] [ 3 27 36 56 69 25] [] [25] 6\n",
            "-----> Accuracy: 5.5 | Match Score: 56 <------\n",
            "----- 104 ------\n",
            "[17 40 41 46 69  6] [ 9 10 32 42 55  6] [] [6] 6\n",
            "[ 1 25 39 62 63  6] [ 6 14 38 39 65  6] [39] [6] 7\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9\n",
            "[10 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7\n",
            "[ 5 13 28 59 69 13] [ 8 23 37 52 63 13] [] [13] 6\n",
            "[ 7 15 31 34 36  8] [15 27 44 59 63  8] [15] [8] 7\n",
            "-----> Accuracy: 5.6667 | Match Score: 49 <------\n"
          ]
        }
      ],
      "source": [
        "winningScore = 0\n",
        "winningState = 0\n",
        "RFcriterion = \"gini\"\n",
        "\n",
        "irandom_state = 1\n",
        "while irandom_state <= 104:\n",
        "    # Fitting Random Forest Classification to the Training set\n",
        "    RFclassifier = RandomForestClassifier(n_estimators=irandom_state, criterion=RFcriterion, random_state=irandom_state)\n",
        "    RFclassifier.fit(X_fit_train, y_train)\n",
        "    #print (RFclassifier)\n",
        "\n",
        "    # Compare the Test set results for Random Forest Classification\n",
        "    y_pred = RFclassifier.predict(X_fit_test)\n",
        "    \n",
        "    print('----- ' + str(irandom_state) + ' ------')\n",
        "    accuracyScore = 0\n",
        "    totalMatchScore = 0\n",
        "    for index, pred in enumerate(y_pred):\n",
        "        accuracy = accuracy_score(y_test[index], pred)\n",
        "        accuracyScore += accuracy\n",
        "        comparePOS = list(set(pred[:5]) & set(y_test[index][:5]))\n",
        "        comparePWB = list(set(pred[5:]) & set(y_test[index][5:]))\n",
        "        matchScore = predictionScore(pred[:5], y_test[index][:5]) + (predictionScore(pred[5:], y_test[index][5:])*6)\n",
        "        if matchScore >= 6:\n",
        "            totalMatchScore += matchScore\n",
        "            print(pred, y_test[index], comparePOS, comparePWB, str(int(matchScore)))\n",
        "        # Find the winner!\n",
        "        if totalMatchScore >= winningScore:\n",
        "            winningScore = totalMatchScore\n",
        "            winningState = irandom_state\n",
        "    print('-----> Accuracy: ' + str(round(accuracyScore,4)) + ' | Match Score: ' + str(int(totalMatchScore)) + ' <------')\n",
        "\n",
        "    irandom_state += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tJYkLY2--M6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2ace39-7484-4b61-d162-391253bd8c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----> Winner is 25 with 74 <------\n",
            "[ 3 25 35 58 68 10] [29.97, 74.8, 86.84, 81, 81.06, 2]\n"
          ]
        }
      ],
      "source": [
        "print('-----> Winner is ' + str(int(winningState)) + ' with ' + str(int(winningScore)) + ' <------')\n",
        "# Fitting Random Forest Classification to the Training set\n",
        "RFclassifier = RandomForestClassifier(n_estimators=int(winningState), criterion=RFcriterion, random_state=int(winningState))\n",
        "RFclassifier.fit(X_fit, y)\n",
        "\n",
        "# Predicting the next draw set results\n",
        "nextdraw_pred = RFclassifier.predict([nextdraw_set])\n",
        "print(nextdraw_pred[0], nextdraw_set)\n",
        "\n",
        "nextDrawResults.append([{\"numbers\":list(map(int, nextdraw_pred[0]))},{\"score\":int(winningScore)},{\"class\":\"weather - RandomForestClassifier - G\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6cC01o6I7fR"
      },
      "source": [
        "# KNN Classifier - uniform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNJ7s4E0Iqxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020f0886-beeb-49c8-d3e4-a7ba671f7b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9.0\n",
            "[ 3 43 45 61 65 14] [19 25 43 46 48 14] [43] [14] 7.0\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7.0\n",
            "[ 1 15 21 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[17 54 56 63 69 20] [ 3  7  9 31 33 20] [] [20] 6.0\n",
            "-----> Accuracy: 3.8333 | Match Score: 49.0 <------\n",
            "----- 2 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 2 25 31 44 52  6] [28 30 32 36 58  6] [] [6] 6.0\n",
            "[ 3 13 28 38 63 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[ 1 15 21 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[ 8 12 25 41 64  5] [ 2 12 32 50 65  5] [12] [5] 7.0\n",
            "-----> Accuracy: 4.3333 | Match Score: 32.0 <------\n",
            "----- 3 ------\n",
            "[ 3 24 30 42 56  7] [22 39 43 62 64  7] [] [7] 6.0\n",
            "[11 12 15 16 54 18] [ 4  6 16 30 56 18] [16] [18] 7.0\n",
            "[ 1  2 24 38 57 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[ 1 12 21 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[ 8 12 24 41 62  5] [ 2 12 32 50 65  5] [12] [5] 7.0\n",
            "-----> Accuracy: 3.6667 | Match Score: 33.0 <------\n",
            "----- 4 ------\n",
            "[ 3 23 28 34 38  7] [22 39 43 62 64  7] [] [7] 6.0\n",
            "[ 1 12 49 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[ 6 12 24 41 59  5] [ 2 12 32 50 65  5] [12] [5] 7.0\n",
            "-----> Accuracy: 3.5 | Match Score: 20.0 <------\n",
            "----- 5 ------\n",
            "[ 1 12 49 32 64  1] [ 7 10 16 46 56  1] [] [1] 6.0\n",
            "[ 6 12 25 41 59  5] [ 2 12 32 50 65  5] [12] [5] 7.0\n",
            "-----> Accuracy: 3.0 | Match Score: 13.0 <------\n",
            "----- 6 ------\n",
            "[ 1 17 20 48 39 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 49 32 64  1] [ 7 10 16 46 56  1] [] [1] 6.0\n",
            "[ 6 12 25 36 67  5] [ 2 12 32 50 65  5] [12] [5] 7.0\n",
            "-----> Accuracy: 2.8333 | Match Score: 19.0 <------\n",
            "----- 7 ------\n",
            "[ 6 17 20 48 39 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 7 24 58 38 47  4] [16 23 30 44 58  4] [58] [4] 7.0\n",
            "[ 3 12 49 32 64  1] [ 7 10 16 46 56  1] [] [1] 6.0\n",
            "[ 6 12 25 36 67  5] [ 2 12 32 50 65  5] [12] [5] 7.0\n",
            "-----> Accuracy: 3.0 | Match Score: 26.0 <------\n",
            "----- 8 ------\n",
            "[ 6 17 20 48 39 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 7 24 58 49 47  4] [16 23 30 44 58  4] [58] [4] 7.0\n",
            "[ 3 12 49 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[22 12 25 36 67  5] [ 2 12 32 50 65  5] [12] [5] 7.0\n",
            "-----> Accuracy: 2.6667 | Match Score: 27.0 <------\n",
            "----- 9 ------\n",
            "[ 6 17 20 48 39 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 7 10 58 49 23  4] [16 23 30 44 58  4] [58, 23] [4] 9.0\n",
            "[ 3 53 49 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[22 10 25 55 67  5] [ 2 12 32 50 65  5] [] [5] 6.0\n",
            "-----> Accuracy: 2.8333 | Match Score: 28.0 <------\n",
            "----- 10 ------\n",
            "[ 7 10 58 49 23  4] [16 23 30 44 58  4] [58, 23] [4] 9.0\n",
            "[11 23 37 56 69 15] [11 13 55 56 69  4] [56, 11, 69] [] 6.0\n",
            "[22 10 25 55 67  5] [ 2 12 32 50 65  5] [] [5] 6.0\n",
            "-----> Accuracy: 3.3333 | Match Score: 21.0 <------\n",
            "----- 11 ------\n",
            "[ 7 10 35 40 47  4] [16 23 30 44 58  4] [] [4] 6.0\n",
            "[11 23 37 56 69 15] [11 13 55 56 69  4] [56, 11, 69] [] 6.0\n",
            "[22 10 25 55 67  5] [ 2 12 32 50 65  5] [] [5] 6.0\n",
            "-----> Accuracy: 2.6667 | Match Score: 18.0 <------\n",
            "----- 12 ------\n",
            "[ 7 10 35 40 47  4] [16 23 30 44 58  4] [] [4] 6.0\n",
            "[11 23 37 56 69  8] [11 13 55 56 69  4] [56, 11, 69] [] 6.0\n",
            "-----> Accuracy: 3.1667 | Match Score: 12.0 <------\n",
            "----- 13 ------\n",
            "[ 1 21 44 59 60  6] [ 6 14 38 39 65  6] [] [6] 6.0\n",
            "[ 3 32 34 53 56 25] [37 43 44 45 53 25] [53] [25] 7.0\n",
            "[11 23 37 56 69  8] [11 13 55 56 69  4] [56, 11, 69] [] 6.0\n",
            "-----> Accuracy: 3.3333 | Match Score: 19.0 <------\n",
            "----- 14 ------\n",
            "[ 1 21 39 59 60  6] [ 6 14 38 39 65  6] [39] [6] 7.0\n",
            "[11 23 37 56 69  8] [11 13 55 56 69  4] [56, 11, 69] [] 6.0\n",
            "-----> Accuracy: 3.5 | Match Score: 13.0 <------\n",
            "----- 15 ------\n",
            "[ 1 21 39 59 60  6] [ 6 14 38 39 65  6] [39] [6] 7.0\n",
            "[ 1  9 18 44 52  6] [28 30 32 36 58  6] [] [6] 6.0\n",
            "[11 23 37 56 69  8] [11 13 55 56 69  4] [56, 11, 69] [] 6.0\n",
            "-----> Accuracy: 4.3333 | Match Score: 19.0 <------\n",
            "----- 16 ------\n",
            "[ 1 21 39 59 59  6] [ 6 14 38 39 65  6] [39] [6] 7.0\n",
            "[ 1  9 18 44 52  6] [28 30 32 36 58  6] [] [6] 6.0\n",
            "-----> Accuracy: 4.6667 | Match Score: 13.0 <------\n",
            "----- 17 ------\n",
            "[ 1 21 39 59 59  6] [ 6 14 38 39 65  6] [39] [6] 7.0\n",
            "[ 1  9 18 44 52  6] [28 30 32 36 58  6] [] [6] 6.0\n",
            "[ 1  3 13 43 60 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[12 17 37 45 62 18] [14 16 37 48 58 18] [37] [18] 7.0\n",
            "-----> Accuracy: 5.0 | Match Score: 26.0 <------\n",
            "----- 18 ------\n",
            "[ 1 21 39 44 59  6] [ 6 14 38 39 65  6] [39] [6] 7.0\n",
            "[ 1  3 13 17 60 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 9 23 42 59 69 11] [ 2 23 40 59 69 13] [59, 69, 23] [] 6.0\n",
            "[12 17 37 45 62 18] [14 16 37 48 58 18] [37] [18] 7.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 26.0 <------\n",
            "----- 19 ------\n",
            "[ 1 28 35 36 69 13] [ 1 10 27 28 36 12] [1, 36, 28] [] 6.0\n",
            "[ 1  3 13 17 60 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 4 17 37 45 62 18] [14 16 37 48 58 18] [37] [18] 7.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 19.0 <------\n",
            "----- 20 ------\n",
            "[ 1  3 13 17 60 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 3 17 37 45 62 18] [14 16 37 48 58 18] [37] [18] 7.0\n",
            "[ 4 17 32 35 68 10] [13 23 32 35 68 21] [32, 35, 68] [] 6.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 19.0 <------\n",
            "----- 21 ------\n",
            "[ 1  3 13 17 50 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 2 23 42 59 52  3] [ 2 23 40 59 69 13] [2, 59, 23] [] 6.0\n",
            "[ 4 17 32 35 68 10] [13 23 32 35 68 21] [32, 35, 68] [] 6.0\n",
            "-----> Accuracy: 5.5 | Match Score: 18.0 <------\n",
            "----- 22 ------\n",
            "[ 1 28 26 36 64 13] [ 1 10 27 28 36 12] [1, 36, 28] [] 6.0\n",
            "[ 1  3 13 17 50 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 2 23 42 59 62  3] [ 2 23 40 59 69 13] [2, 59, 23] [] 6.0\n",
            "[ 4 17 32 35 68  9] [13 23 32 35 68 21] [32, 35, 68] [] 6.0\n",
            "-----> Accuracy: 5.1667 | Match Score: 24.0 <------\n",
            "----- 23 ------\n",
            "[ 1 28 26 36 64 13] [ 1 10 27 28 36 12] [1, 36, 28] [] 6.0\n",
            "[ 1  3 13 17 50 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 2 23 42 59 62 11] [ 2 23 40 59 69 13] [2, 59, 23] [] 6.0\n",
            "-----> Accuracy: 4.6667 | Match Score: 18.0 <------\n",
            "----- 24 ------\n",
            "[ 1  3 13 17 50 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 3.8333 | Match Score: 6.0 <------\n",
            "----- 25 ------\n",
            "[ 1  3 13 17 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 4.3333 | Match Score: 6.0 <------\n",
            "----- 26 ------\n",
            "[ 1  3 13 17 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 4.6667 | Match Score: 6.0 <------\n",
            "----- 27 ------\n",
            "[ 1  3 13 17 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 2 23 42 59 62 11] [ 2 23 40 59 69 13] [2, 59, 23] [] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 12.0 <------\n",
            "----- 28 ------\n",
            "[ 1  3 13 52 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 6.0 <------\n",
            "----- 29 ------\n",
            "[ 1  3 13 52 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 6.0 <------\n",
            "----- 30 ------\n",
            "[ 1  3 13 52 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 4.1667 | Match Score: 6.0 <------\n",
            "----- 31 ------\n",
            "[ 1  3 13 52 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 4.3333 | Match Score: 6.0 <------\n",
            "----- 32 ------\n",
            "[ 1  3 13 52 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 4.0 | Match Score: 6.0 <------\n",
            "----- 33 ------\n",
            "-----> Accuracy: 4.6667 | Match Score: 0 <------\n",
            "----- 34 ------\n",
            "[ 1 21 38 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "-----> Accuracy: 4.3333 | Match Score: 6.0 <------\n",
            "----- 35 ------\n",
            "[ 5 33 28 42 63 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "-----> Accuracy: 4.5 | Match Score: 7.0 <------\n",
            "----- 36 ------\n",
            "[ 5 33 28 42 63 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "-----> Accuracy: 5.1667 | Match Score: 7.0 <------\n",
            "----- 37 ------\n",
            "[ 1 33 28 42 63 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 6.0 <------\n",
            "----- 38 ------\n",
            "[ 1 33 28 42 63 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 38 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.1667 | Match Score: 12.0 <------\n",
            "----- 39 ------\n",
            "[ 1 33 28 42 63 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 38 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 18 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.0 | Match Score: 18.0 <------\n",
            "----- 40 ------\n",
            "[ 1 33 28 42 63 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 38 44 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 3 12 18 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 25.0 <------\n",
            "----- 41 ------\n",
            "[ 1 33 28 42 63 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 3 12 18 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 25.0 <------\n",
            "----- 42 ------\n",
            "[ 1 33 28 42 63 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 3 12 18 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 25.0 <------\n",
            "----- 43 ------\n",
            "[ 1 33 28 42 63 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 12 18 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 25.0 <------\n",
            "----- 44 ------\n",
            "[ 1 33 28 42 63 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 12 18 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 45 ------\n",
            "[ 1 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 12 16 36 53 11] [ 3 10 15 33 42 11] [] [11] 6.0\n",
            "[ 1 12 18 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 46 ------\n",
            "[ 1 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 19.0 <------\n",
            "----- 47 ------\n",
            "[ 1 21 41 48 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 19.0 <------\n",
            "----- 48 ------\n",
            "[ 1 21 41 48 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 19.0 <------\n",
            "----- 49 ------\n",
            "[ 1 21 41 48 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 19.0 <------\n",
            "----- 50 ------\n",
            "[ 1 21 41 48 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 3 33 28 40 69 16] [ 3  7 33 50 69 24] [33, 3, 69] [] 6.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 51 ------\n",
            "[ 1 21 41 48 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 19.0 <------\n",
            "----- 52 ------\n",
            "[ 1 21 41 48 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "[11 10 32 43 62  5] [ 2 12 32 50 65  5] [32] [5] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 19.0 <------\n",
            "----- 53 ------\n",
            "[ 1 21 41 48 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.5 | Match Score: 12.0 <------\n",
            "----- 54 ------\n",
            "[ 1 21 41 48 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 12.0 <------\n",
            "----- 55 ------\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 28 53 42 68 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 18.0 <------\n",
            "----- 56 ------\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 53 42 68 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 25.0 <------\n",
            "----- 57 ------\n",
            "[ 1 21 41 32 66 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 53 42 68 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 25.0 <------\n",
            "----- 58 ------\n",
            "[ 1 21 41 32 66 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 20 42 68 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 26.0 <------\n",
            "----- 59 ------\n",
            "[ 1 21 41 32 66 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1  7 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 20 42 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 32.0 <------\n",
            "----- 60 ------\n",
            "[ 1 21 41 32 66 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 52 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 25 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 20 42 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 32.0 <------\n",
            "----- 61 ------\n",
            "[ 1 21 41 32 66 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 25 33 40 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 32.0 <------\n",
            "----- 62 ------\n",
            "[ 1 19 32 36 62  4] [ 6 14 36 51 54  4] [36] [4] 7.0\n",
            "[ 1 21 41 32 66 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "[ 1 21 41 32 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 32.0 <------\n",
            "----- 63 ------\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 66 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "[ 1 21 41 62 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 31.0 <------\n",
            "----- 64 ------\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "[ 1 21 41 62 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 31.0 <------\n",
            "----- 65 ------\n",
            "[ 1 19 34 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "[ 1 21 41 59 62 18] [14 16 37 48 58 18] [] [18] 6.0\n",
            "-----> Accuracy: 6.8333 | Match Score: 31.0 <------\n",
            "----- 66 ------\n",
            "[ 1 19 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 25.0 <------\n",
            "----- 67 ------\n",
            "[ 1 19 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 25.0 <------\n",
            "----- 68 ------\n",
            "[ 1 33 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 17 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "-----> Accuracy: 6.5 | Match Score: 31.0 <------\n",
            "----- 69 ------\n",
            "[ 1 33 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 17 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "-----> Accuracy: 6.5 | Match Score: 31.0 <------\n",
            "----- 70 ------\n",
            "[ 1 33 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 12 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 60 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 20 54 69 17] [ 2 12 17 20 65 17] [20] [17] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 31.0 <------\n",
            "----- 71 ------\n",
            "[ 1 33 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 12 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 53 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 30.0 <------\n",
            "----- 72 ------\n",
            "[ 1 33 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 12 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 53 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 30.0 <------\n",
            "----- 73 ------\n",
            "[ 1 33 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 12 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 25 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 53 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 7.3333 | Match Score: 37.0 <------\n",
            "----- 74 ------\n",
            "[ 1 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 12 32 43 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 25 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 53 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 37.0 <------\n",
            "----- 75 ------\n",
            "[ 3 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 25 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 52 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 37.0 <------\n",
            "----- 76 ------\n",
            "[ 1 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 25 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 52 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 37.0 <------\n",
            "----- 77 ------\n",
            "[ 1 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 12 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 52 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 37.0 <------\n",
            "----- 78 ------\n",
            "[ 1 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 12 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 52 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 37.0 <------\n",
            "----- 79 ------\n",
            "[ 1 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 12 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 3 28 28 51 67  2] [ 9 12 15 31 60  2] [] [2] 6.0\n",
            "[ 1 28 52 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 43.0 <------\n",
            "----- 80 ------\n",
            "[ 1 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 52 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 37.0 <------\n",
            "----- 81 ------\n",
            "[ 1 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 39 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 37.0 <------\n",
            "----- 82 ------\n",
            "[ 1 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 63 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 39 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 37.0 <------\n",
            "----- 83 ------\n",
            "[ 1 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 39 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 7.1667 | Match Score: 37.0 <------\n",
            "----- 84 ------\n",
            "[ 1 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 39 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 7.1667 | Match Score: 37.0 <------\n",
            "----- 85 ------\n",
            "[ 1 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 39 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 37.0 <------\n",
            "----- 86 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 19 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 1 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 39 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.8333 | Match Score: 37.0 <------\n",
            "----- 87 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 17 34 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 37 54 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.8333 | Match Score: 43.0 <------\n",
            "----- 88 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 37 53 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 37.0 <------\n",
            "----- 89 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 37 53 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 37.0 <------\n",
            "----- 90 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 37 53 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 37.0 <------\n",
            "----- 91 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 52 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 37 53 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 37.0 <------\n",
            "----- 92 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 37 53 69 17] [ 2 12 17 20 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 37.0 <------\n",
            "----- 93 ------\n",
            "[ 7 12 35 52 69 24] [ 5 25 38 52 67 24] [52] [24] 7.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 32.0 <------\n",
            "----- 94 ------\n",
            "[ 7 12 35 52 69 24] [ 5 25 38 52 67 24] [52] [24] 7.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 32.0 <------\n",
            "----- 95 ------\n",
            "[ 7 12 35 52 69 24] [ 5 25 38 52 67 24] [52] [24] 7.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 32.0 <------\n",
            "----- 96 ------\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 25.0 <------\n",
            "----- 97 ------\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 25.0 <------\n",
            "----- 98 ------\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 25.0 <------\n",
            "----- 99 ------\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "-----> Accuracy: 6.5 | Match Score: 25.0 <------\n",
            "----- 100 ------\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 27 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 20 35 42 68 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 37.0 <------\n",
            "----- 101 ------\n",
            "[ 5 17 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 20 35 42 68 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.8333 | Match Score: 43.0 <------\n",
            "----- 102 ------\n",
            "[ 5 17 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 18 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 20 35 42 68 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "-----> Accuracy: 7.0 | Match Score: 43.0 <------\n",
            "----- 103 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 5 17 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 28 35 53 68 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 7.5 | Match Score: 50.0 <------\n",
            "----- 104 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 5 17 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 33 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 28 35 53 68 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 7.5 | Match Score: 50.0 <------\n",
            "----- 105 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 5 17 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 7.3333 | Match Score: 36.0 <------\n",
            "----- 106 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 5 17 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 7.1667 | Match Score: 36.0 <------\n",
            "----- 107 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 17 32 45 62  4] [ 6 14 36 51 54  4] [] [4] 6.0\n",
            "[ 3 21 41 32 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 27 53 69 13] [ 1 10 27 28 36 12] [1, 27, 28] [] 6.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 7.1667 | Match Score: 36.0 <------\n",
            "----- 108 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 59 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 24.0 <------\n",
            "----- 109 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 59 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 30.0 <------\n",
            "----- 110 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 59 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 30.0 <------\n",
            "----- 111 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 59 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 21 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 30.0 <------\n",
            "----- 112 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 59 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 30.0 <------\n",
            "----- 113 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 59 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 45 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 37.0 <------\n",
            "----- 114 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 45 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 37.0 <------\n",
            "----- 115 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 15 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 45 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "-----> Accuracy: 6.5 | Match Score: 37.0 <------\n",
            "----- 116 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 45 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 37.0 <------\n",
            "----- 117 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 45 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "-----> Accuracy: 6.8333 | Match Score: 37.0 <------\n",
            "----- 118 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 8 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 45 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "-----> Accuracy: 7.3333 | Match Score: 43.0 <------\n",
            "----- 119 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 8 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 45 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "-----> Accuracy: 7.6667 | Match Score: 43.0 <------\n",
            "----- 120 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 8 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 36 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "-----> Accuracy: 7.8333 | Match Score: 43.0 <------\n",
            "----- 121 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 8 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 2 12 33 36 69  8] [21 31 50 51 69  8] [69] [8] 7.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 7.8333 | Match Score: 50.0 <------\n",
            "----- 122 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 8 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 7.6667 | Match Score: 43.0 <------\n",
            "----- 123 ------\n",
            "[ 1 12 35 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 7.1667 | Match Score: 43.0 <------\n",
            "----- 124 ------\n",
            "[ 1 12 33 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.8333 | Match Score: 36.0 <------\n",
            "----- 125 ------\n",
            "[ 1 12 33 48 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.8333 | Match Score: 36.0 <------\n",
            "----- 126 ------\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 30.0 <------\n",
            "----- 127 ------\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.8333 | Match Score: 30.0 <------\n",
            "----- 128 ------\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.6667 | Match Score: 30.0 <------\n",
            "----- 129 ------\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.5 | Match Score: 30.0 <------\n",
            "----- 130 ------\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 30.0 <------\n",
            "----- 131 ------\n",
            "[ 2 12 26 36 69 24] [ 5 29 34 53 57 24] [] [24] 6.0\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 42 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 39 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 30.0 <------\n",
            "----- 132 ------\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 24.0 <------\n",
            "----- 133 ------\n",
            "[ 3 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 6.5 | Match Score: 31.0 <------\n",
            "----- 134 ------\n",
            "[ 1 21 41 45 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 31.0 <------\n",
            "----- 135 ------\n",
            "[ 1 21 41 45 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 21] [19 22 52 56 67 21] [] [21] 6.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 31.0 <------\n",
            "----- 136 ------\n",
            "[ 1 21 41 45 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 30 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 31.0 <------\n",
            "----- 137 ------\n",
            "[ 1 21 41 45 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 1 28 35 40 63 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 30.0 <------\n",
            "----- 138 ------\n",
            "[ 1 21 41 45 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 24.0 <------\n",
            "----- 139 ------\n",
            "[ 1 21 41 53 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 18.0 <------\n",
            "----- 140 ------\n",
            "[ 1 21 41 53 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 24.0 <------\n",
            "----- 141 ------\n",
            "[ 1 21 41 53 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 34 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 24.0 <------\n",
            "----- 142 ------\n",
            "[ 1 21 41 53 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 32 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 24.0 <------\n",
            "----- 143 ------\n",
            "[ 1 21 41 53 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 24.0 <------\n",
            "----- 144 ------\n",
            "[ 1 21 41 53 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 24.0 <------\n",
            "----- 145 ------\n",
            "[ 5 21 41 53 62 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 1 28 35 42 69 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 30.0 <------\n",
            "----- 146 ------\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 17] [ 8 14 32 58 67 17] [] [17] 6.0\n",
            "[ 1 28 35 42 63 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 24.0 <------\n",
            "----- 147 ------\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 42 63 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "[ 1 28 37 43 69 24] [ 1  5 16 22 54 24] [1] [24] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 148 ------\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 42 63 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "[ 1 28 37 43 69 24] [ 1  5 16 22 54 24] [1] [24] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 149 ------\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 42 63 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "[ 1 28 37 53 69 24] [ 1  5 16 22 54 24] [1] [24] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 25.0 <------\n",
            "----- 150 ------\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 42 63 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "[ 1 28 37 53 69 24] [ 1  5 16 22 54 24] [1] [24] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 25.0 <------\n",
            "----- 151 ------\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 42 63 21] [15 26 37 53 55 21] [] [21] 6.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 18.0 <------\n",
            "----- 152 ------\n",
            "[ 3 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 19.0 <------\n",
            "----- 153 ------\n",
            "[ 3 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 35 53 69 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 19.0 <------\n",
            "----- 154 ------\n",
            "[ 1 12 26 53 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 37 53 69 17] [40 41 58 64 65 17] [] [17] 6.0\n",
            "[ 1 28 28 53 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[ 1 28 35 53 63 21] [15 26 37 53 55 21] [53] [21] 7.0\n",
            "-----> Accuracy: 6.3333 | Match Score: 26.0 <------\n"
          ]
        }
      ],
      "source": [
        "winningScore = 0\n",
        "winningState = 0\n",
        "\n",
        "in_neighbors = 1\n",
        "while in_neighbors <= 154:\n",
        "    # Fitting KNN\n",
        "    KNNWeights = \"uniform\" # weights{\"uniform\", \"distance\"}\n",
        "    KNNAlgorithm = \"auto\" # algorithm{\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"}\n",
        "    neigh = KNeighborsClassifier(weights=KNNWeights, algorithm=KNNAlgorithm, n_neighbors=in_neighbors)\n",
        "    neigh.fit(X_fit_train, y_train)\n",
        "\n",
        "    # Predicting the Test set results\n",
        "    y_n_pred = neigh.predict(X_fit_test)\n",
        "    \n",
        "    print('----- ' + str(in_neighbors) + ' ------')\n",
        "    accuracyScore = 0\n",
        "    totalMatchScore = 0\n",
        "    for index, pred in enumerate(y_n_pred):\n",
        "        accuracy = accuracy_score(y_test[index], pred)\n",
        "        accuracyScore += accuracy\n",
        "        comparePOS = list(set(pred[:5]) & set(y_test[index][:5]))\n",
        "        comparePWB = list(set(pred[5:]) & set(y_test[index][5:]))\n",
        "        matchScore = predictionScore(pred[:5], y_test[index][:5]) + (predictionScore(pred[5:], y_test[index][5:])*6)\n",
        "        if matchScore >= 6:\n",
        "            totalMatchScore += matchScore\n",
        "            print(pred, y_test[index], comparePOS, comparePWB, matchScore)\n",
        "        # Find the winner!\n",
        "        if totalMatchScore >= winningScore:\n",
        "            winningScore = totalMatchScore\n",
        "            winningState = in_neighbors\n",
        "    print('-----> Accuracy: ' + str(round(accuracyScore,4)) + ' | Match Score: ' + str(totalMatchScore) + ' <------')\n",
        "\n",
        "    in_neighbors += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLhBSqRgIwzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af12c1bf-ee7e-4571-c015-d0bc975022bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----> Winner is 121 with 50 <------\n",
            "[ 1 28 36 59 68 11] [29.97, 74.8, 86.84, 81, 81.06, 2]\n"
          ]
        }
      ],
      "source": [
        "print('-----> Winner is ' + str(int(winningState)) + ' with ' + str(int(winningScore)) + ' <------')\n",
        "# Fitting KNN\n",
        "neigh = KNeighborsClassifier(weights=KNNWeights, algorithm=KNNAlgorithm, n_neighbors=int(winningState))\n",
        "neigh.fit(X_fit, y)\n",
        "\n",
        "# Predicting the next draw set results\n",
        "nextdraw_n_pred = neigh.predict([nextdraw_set])\n",
        "print(nextdraw_n_pred[0], nextdraw_set)\n",
        "\n",
        "nextDrawResults.append([{\"numbers\":nextdraw_n_pred[0]},{\"score\":int(winningScore)},{\"class\":\"weather - KNeighborsClassifier - U\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbWTRa7J_VWZ"
      },
      "source": [
        "# KNN Classifier - distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjTPj3y-_VWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793cb486-e926-4841-9c21-e057b379cae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9.0\n",
            "[ 3 43 45 61 65 14] [19 25 43 46 48 14] [43] [14] 7.0\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7.0\n",
            "[ 1 15 21 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[17 54 56 63 69 20] [ 3  7  9 31 33 20] [] [20] 6.0\n",
            "-----> Accuracy: 3.8333 | Match Score: 49.0 <------\n",
            "----- 2 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9.0\n",
            "[ 3 43 45 61 65 14] [19 25 43 46 48 14] [43] [14] 7.0\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7.0\n",
            "[ 1 15 21 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[17 54 56 63 69 20] [ 3  7  9 31 33 20] [] [20] 6.0\n",
            "-----> Accuracy: 3.8333 | Match Score: 49.0 <------\n",
            "----- 3 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9.0\n",
            "[ 3 43 45 61 65 14] [19 25 43 46 48 14] [43] [14] 7.0\n",
            "[24 61 63 64 69 18] [ 5 21 36 61 62 18] [61] [18] 7.0\n",
            "[ 1 15 21 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[17 54 56 63 69 20] [ 3  7  9 31 33 20] [] [20] 6.0\n",
            "-----> Accuracy: 4.0 | Match Score: 49.0 <------\n",
            "----- 4 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[19 28 43 67 69  7] [19 28 41 42 51  7] [19, 28] [7] 9.0\n",
            "[ 3 43 45 61 65 14] [19 25 43 46 48 14] [43] [14] 7.0\n",
            "[ 1 15 49 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "[ 8 54 18 63 69 20] [ 3  7  9 31 33 20] [] [20] 6.0\n",
            "-----> Accuracy: 4.1667 | Match Score: 42.0 <------\n",
            "----- 5 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 1 15 49 32 64  1] [ 7 10 16 46 56  1] [] [1] 6.0\n",
            "[ 8 54 18 63 69 20] [ 3  7  9 31 33 20] [] [20] 6.0\n",
            "-----> Accuracy: 3.5 | Match Score: 25.0 <------\n",
            "----- 6 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 1 15 49 32 64  1] [ 7 10 16 46 56  1] [] [1] 6.0\n",
            "[ 8 54 18 63 69 20] [ 3  7  9 31 33 20] [] [20] 6.0\n",
            "-----> Accuracy: 3.5 | Match Score: 25.0 <------\n",
            "----- 7 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 3 15 49 32 64  1] [ 7 10 16 46 56  1] [] [1] 6.0\n",
            "[ 8 54 18 63 69 20] [ 3  7  9 31 33 20] [] [20] 6.0\n",
            "-----> Accuracy: 3.5 | Match Score: 25.0 <------\n",
            "----- 8 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 3 15 49 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "-----> Accuracy: 3.5 | Match Score: 20.0 <------\n",
            "----- 9 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 3 53 49 32 46  1] [ 7 10 16 46 56  1] [46] [1] 7.0\n",
            "-----> Accuracy: 3.6667 | Match Score: 20.0 <------\n",
            "----- 10 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 3.6667 | Match Score: 13.0 <------\n",
            "----- 11 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 3.3333 | Match Score: 13.0 <------\n",
            "----- 12 ------\n",
            "[ 5 12 50 47 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.1667 | Match Score: 20.0 <------\n",
            "----- 13 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.3333 | Match Score: 13.0 <------\n",
            "----- 14 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.5 | Match Score: 13.0 <------\n",
            "----- 15 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.5 | Match Score: 13.0 <------\n",
            "----- 16 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.6667 | Match Score: 13.0 <------\n",
            "----- 17 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 8 33 18 53 69 20] [ 3  7  9 31 33 20] [33] [20] 7.0\n",
            "-----> Accuracy: 5.0 | Match Score: 20.0 <------\n",
            "----- 18 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.0 | Match Score: 13.0 <------\n",
            "----- 19 ------\n",
            "[ 7 15 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.0 | Match Score: 13.0 <------\n",
            "----- 20 ------\n",
            "[ 7 12 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 13.0 <------\n",
            "----- 21 ------\n",
            "[ 7 12 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.6667 | Match Score: 13.0 <------\n",
            "----- 22 ------\n",
            "[ 7 12 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.5 | Match Score: 13.0 <------\n",
            "----- 23 ------\n",
            "[ 7 12 18 32 45 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.6667 | Match Score: 13.0 <------\n",
            "----- 24 ------\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 4.6667 | Match Score: 13.0 <------\n",
            "----- 25 ------\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 8 33 18 53 69 20] [ 3  7  9 31 33 20] [33] [20] 7.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 20.0 <------\n",
            "----- 26 ------\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 8 33 18 53 69 20] [ 3  7  9 31 33 20] [33] [20] 7.0\n",
            "-----> Accuracy: 5.1667 | Match Score: 20.0 <------\n",
            "----- 27 ------\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[11 17 38 58 62 12] [ 3 11 38 44 58  2] [58, 11, 38] [] 6.0\n",
            "[ 8 33 18 53 69 20] [ 3  7  9 31 33 20] [33] [20] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 28 ------\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[11 17 38 58 62 12] [ 3 11 38 44 58  2] [58, 11, 38] [] 6.0\n",
            "[ 8 33 18 53 69 20] [ 3  7  9 31 33 20] [33] [20] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 29 ------\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[11 17 38 58 62 11] [ 3 11 38 44 58  2] [58, 11, 38] [] 6.0\n",
            "[ 8 33 18 53 69 20] [ 3  7  9 31 33 20] [33] [20] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 26.0 <------\n",
            "----- 30 ------\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[11 17 38 58 62 11] [ 3 11 38 44 58  2] [58, 11, 38] [] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 19.0 <------\n",
            "----- 31 ------\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[11 17 38 58 62 11] [ 3 11 38 44 58  2] [58, 11, 38] [] 6.0\n",
            "-----> Accuracy: 5.0 | Match Score: 19.0 <------\n",
            "----- 32 ------\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[11 17 38 58 62 11] [ 3 11 38 44 58  2] [58, 11, 38] [] 6.0\n",
            "-----> Accuracy: 4.8333 | Match Score: 19.0 <------\n",
            "----- 33 ------\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[11 17 38 58 62 11] [ 3 11 38 44 58  2] [58, 11, 38] [] 6.0\n",
            "-----> Accuracy: 5.0 | Match Score: 19.0 <------\n",
            "----- 34 ------\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 17 27 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.0 | Match Score: 19.0 <------\n",
            "----- 35 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 17 27 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 36 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 17 27 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 26.0 <------\n",
            "----- 37 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 17 27 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 1 23 42 59 69 11] [ 2 23 40 59 69 13] [59, 69, 23] [] 6.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 32.0 <------\n",
            "----- 38 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 17 27 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 1 23 42 59 69 11] [ 2 23 40 59 69 13] [59, 69, 23] [] 6.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 32.0 <------\n",
            "----- 39 ------\n",
            "[ 5 33 28 42 63 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 20 27 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 1 23 42 59 69 11] [ 2 23 40 59 69 13] [59, 69, 23] [] 6.0\n",
            "-----> Accuracy: 5.5 | Match Score: 32.0 <------\n",
            "----- 40 ------\n",
            "[ 5 33 28 42 63 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 20 27 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 1 23 42 59 69 11] [ 2 23 40 59 69 13] [59, 69, 23] [] 6.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 32.0 <------\n",
            "----- 41 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 20 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 1 23 42 59 69 11] [ 2 23 40 59 69 13] [59, 69, 23] [] 6.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 32.0 <------\n",
            "----- 42 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 20 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 1 23 38 59 69 11] [ 2 23 40 59 69 13] [59, 69, 23] [] 6.0\n",
            "-----> Accuracy: 6.0 | Match Score: 32.0 <------\n",
            "----- 43 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 20 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 26.0 <------\n",
            "----- 44 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 20 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 26.0 <------\n",
            "----- 45 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 20 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 26.0 <------\n",
            "----- 46 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 20 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 26.0 <------\n",
            "----- 47 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 26.0 <------\n",
            "----- 48 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 26.0 <------\n",
            "----- 49 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 26.0 <------\n",
            "----- 50 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 26.0 <------\n",
            "----- 51 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 52 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 53 ------\n",
            "[ 5 33 28 42 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 54 ------\n",
            "[ 5 33 28 55 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 55 ------\n",
            "[ 5 33 28 55 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 56 ------\n",
            "[ 5 33 28 55 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 26.0 <------\n",
            "----- 57 ------\n",
            "[ 5 33 40 55 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 48 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 26.0 <------\n",
            "----- 58 ------\n",
            "[ 5 33 40 55 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 26.0 <------\n",
            "----- 59 ------\n",
            "[ 5 33 40 55 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 53 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 26.0 <------\n",
            "----- 60 ------\n",
            "[ 5 33 40 55 69 24] [ 5 25 38 52 67 24] [5] [24] 7.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 26.0 <------\n",
            "----- 61 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 25.0 <------\n",
            "----- 62 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 2 23 38 59 62 11] [ 2 23 40 59 69 13] [2, 59, 23] [] 6.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 31.0 <------\n",
            "----- 63 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 2 23 38 59 62 11] [ 2 23 40 59 69 13] [2, 59, 23] [] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 31.0 <------\n",
            "----- 64 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 2 23 57 59 62 11] [ 2 23 40 59 69 13] [2, 59, 23] [] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 25.0 <------\n",
            "----- 65 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "[ 2 23 57 59 62 11] [ 2 23 40 59 69 13] [2, 59, 23] [] 6.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 25.0 <------\n",
            "----- 66 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.0 | Match Score: 19.0 <------\n",
            "----- 67 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.1667 | Match Score: 25.0 <------\n",
            "----- 68 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 14 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 25.0 <------\n",
            "----- 69 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 14 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 25.0 <------\n",
            "----- 70 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 14 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 25.0 <------\n",
            "----- 71 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 14 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 25.0 <------\n",
            "----- 72 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 25.0 <------\n",
            "----- 73 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 25.0 <------\n",
            "----- 74 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 25.0 <------\n",
            "----- 75 ------\n",
            "[ 7 33 40 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[40 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 31.0 <------\n",
            "----- 76 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[40 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 31.0 <------\n",
            "----- 77 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[40 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 38.0 <------\n",
            "----- 78 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[40 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 38.0 <------\n",
            "----- 79 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 38.0 <------\n",
            "----- 80 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 38.0 <------\n",
            "----- 81 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 38.0 <------\n",
            "----- 82 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 38.0 <------\n",
            "----- 83 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 38.0 <------\n",
            "----- 84 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 12 18 32 65 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 38.0 <------\n",
            "----- 85 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 23 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 38.0 <------\n",
            "----- 86 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 23 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 38.0 <------\n",
            "----- 87 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 23 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 38.0 <------\n",
            "----- 88 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 23 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 38.0 <------\n",
            "----- 89 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 23 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 38.0 <------\n",
            "----- 90 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 23 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 38.0 <------\n",
            "----- 91 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 7 23 18 32 62 20] [10 30 51 57 63 20] [] [20] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 38.0 <------\n",
            "----- 92 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.1667 | Match Score: 32.0 <------\n",
            "----- 93 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 32.0 <------\n",
            "----- 94 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.1667 | Match Score: 32.0 <------\n",
            "----- 95 ------\n",
            "[ 7 33 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 32.0 <------\n",
            "----- 96 ------\n",
            "[ 7 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 32.0 <------\n",
            "----- 97 ------\n",
            "[ 7 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 32.0 <------\n",
            "----- 98 ------\n",
            "[ 7 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 32.0 <------\n",
            "----- 99 ------\n",
            "[ 7 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 32 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 32.0 <------\n",
            "----- 100 ------\n",
            "[ 7 12 28 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 32.0 <------\n",
            "----- 101 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 5 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[ 1 28 33 36 69 15] [ 1 15 17 46 66 15] [1] [15] 7.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 32.0 <------\n",
            "----- 102 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 25.0 <------\n",
            "----- 103 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 25.0 <------\n",
            "----- 104 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 25.0 <------\n",
            "----- 105 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 25.0 <------\n",
            "----- 106 ------\n",
            "[ 1 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 25.0 <------\n",
            "----- 107 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 108 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 25.0 <------\n",
            "----- 109 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 110 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 111 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 112 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 25.0 <------\n",
            "----- 113 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 25.0 <------\n",
            "----- 114 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 25.0 <------\n",
            "----- 115 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 1 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 25.0 <------\n",
            "----- 116 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 25.0 <------\n",
            "----- 117 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 118 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 119 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 19.0 <------\n",
            "----- 120 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 19.0 <------\n",
            "----- 121 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.1667 | Match Score: 19.0 <------\n",
            "----- 122 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 19.0 <------\n",
            "----- 123 ------\n",
            "[ 7 12 35 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 19.0 <------\n",
            "----- 124 ------\n",
            "[ 7 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 19.0 <------\n",
            "----- 125 ------\n",
            "[ 7 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 19.0 <------\n",
            "----- 126 ------\n",
            "[ 7 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 19.0 <------\n",
            "----- 127 ------\n",
            "[ 7 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 19.0 <------\n",
            "----- 128 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 13.0 <------\n",
            "----- 129 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 19.0 <------\n",
            "----- 130 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 6.0 | Match Score: 19.0 <------\n",
            "----- 131 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.8333 | Match Score: 19.0 <------\n",
            "----- 132 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 133 ------\n",
            "[ 1 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 134 ------\n",
            "[ 1 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 135 ------\n",
            "[ 1 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 136 ------\n",
            "[ 1 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 137 ------\n",
            "[ 1 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 138 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 13.0 <------\n",
            "----- 139 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 13.0 <------\n",
            "----- 140 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 13.0 <------\n",
            "----- 141 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 13.0 <------\n",
            "----- 142 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 13.0 <------\n",
            "----- 143 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 13.0 <------\n",
            "----- 144 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 13.0 <------\n",
            "----- 145 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 13.0 <------\n",
            "----- 146 ------\n",
            "[ 1 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 147 ------\n",
            "[ 1 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 25.0 <------\n",
            "----- 148 ------\n",
            "[ 1 12 33 55 69 24] [ 5 25 38 52 67 24] [] [24] 6.0\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 25.0 <------\n",
            "----- 149 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 19.0 <------\n",
            "----- 150 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 19.0 <------\n",
            "----- 151 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 19.0 <------\n",
            "----- 152 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[ 3 12 48 59 69 18] [ 4  6 16 30 56 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.6667 | Match Score: 19.0 <------\n",
            "----- 153 ------\n",
            "[ 6 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.5 | Match Score: 13.0 <------\n",
            "----- 154 ------\n",
            "[ 1 21 41 45 65 18] [15 35 42 63 68 18] [] [18] 6.0\n",
            "[23 25 39 54 67 11] [ 4 39 48 50 51 11] [39] [11] 7.0\n",
            "-----> Accuracy: 5.3333 | Match Score: 13.0 <------\n"
          ]
        }
      ],
      "source": [
        "winningScore = 0\n",
        "winningState = 0\n",
        "\n",
        "in_neighbors = 1\n",
        "while in_neighbors <= 154:\n",
        "    # Fitting KNN\n",
        "    KNNWeights = \"distance\" # weights{\"uniform\", \"distance\"}\n",
        "    KNNAlgorithm = \"auto\" # algorithm{\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"}\n",
        "    neigh = KNeighborsClassifier(weights=KNNWeights, algorithm=KNNAlgorithm, n_neighbors=in_neighbors)\n",
        "    neigh.fit(X_fit_train, y_train)\n",
        "\n",
        "    # Predicting the Test set results\n",
        "    y_n_pred = neigh.predict(X_fit_test)\n",
        "    \n",
        "    print('----- ' + str(in_neighbors) + ' ------')\n",
        "    accuracyScore = 0\n",
        "    totalMatchScore = 0\n",
        "    for index, pred in enumerate(y_n_pred):\n",
        "        accuracy = accuracy_score(y_test[index], pred)\n",
        "        accuracyScore += accuracy\n",
        "        comparePOS = list(set(pred[:5]) & set(y_test[index][:5]))\n",
        "        comparePWB = list(set(pred[5:]) & set(y_test[index][5:]))\n",
        "        matchScore = predictionScore(pred[:5], y_test[index][:5]) + (predictionScore(pred[5:], y_test[index][5:])*6)\n",
        "        if matchScore >= 6:\n",
        "            totalMatchScore += matchScore\n",
        "            print(pred, y_test[index], comparePOS, comparePWB, matchScore)\n",
        "        # Find the winner!\n",
        "        if totalMatchScore >= winningScore:\n",
        "            winningScore = totalMatchScore\n",
        "            winningState = in_neighbors\n",
        "    print('-----> Accuracy: ' + str(round(accuracyScore,4)) + ' | Match Score: ' + str(totalMatchScore) + ' <------')\n",
        "\n",
        "    in_neighbors += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-37ht07O_VWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acef232-1d4e-4831-eb10-31fdd9d2231c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----> Winner is 3 with 49 <------\n",
            "[19 23 32 35 68 21] [29.97, 74.8, 86.84, 81, 81.06, 2]\n"
          ]
        }
      ],
      "source": [
        "print('-----> Winner is ' + str(int(winningState)) + ' with ' + str(int(winningScore)) + ' <------')\n",
        "# Fitting KNN\n",
        "neigh = KNeighborsClassifier(weights=KNNWeights, algorithm=KNNAlgorithm, n_neighbors=int(winningState))\n",
        "neigh.fit(X_fit, y)\n",
        "\n",
        "# Predicting the next draw set results\n",
        "nextdraw_n_pred = neigh.predict([nextdraw_set])\n",
        "print(nextdraw_n_pred[0], nextdraw_set)\n",
        "\n",
        "nextDrawResults.append([{\"numbers\":nextdraw_n_pred[0]},{\"score\":int(winningScore)},{\"class\":\"weather - KNeighborsClassifier - D\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJbJZMla4a9O"
      },
      "source": [
        "# MLPRegressor - lbfgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHAuFyOYsWJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439c97cd-e718-4f7b-c94a-f0ed6a378ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 2 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 3 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 4 ------ \n",
            "[13, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[11, 22, 33, 44, 54, 12] [11 33 44 59 67  8] [33, 11, 44] [] 6.0\n",
            "[12, 24, 38, 50, 61, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 35, 48, 60, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 46.0 <------\n",
            "----- 5 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 6 ------ \n",
            "[13, 25, 37, 49, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 58, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 23, 34, 46, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 52.0 <------\n",
            "----- 7 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 8 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 9 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 10 ------ \n",
            "[11, 22, 33, 45, 58, 13] [12 33 54 57 60 13] [33] [13] 7.0\n",
            "[11, 22, 34, 45, 58, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[11, 22, 33, 45, 59, 13] [11 33 44 59 67  8] [33, 11, 59] [] 6.0\n",
            "[12, 23, 34, 46, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 11 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 35, 46, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[13, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 12 ------ \n",
            "[13, 23, 34, 47, 56, 13] [12 33 54 57 60 13] [] [13] 6.0\n",
            "[13, 24, 34, 47, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 34, 48, 57, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[13, 24, 35, 49, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[14, 25, 36, 49, 59, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "-----> Match Score: 31.0 <------\n",
            "----- 13 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "-----> Match Score: 53.0 <------\n",
            "----- 14 ------ \n",
            "[11, 22, 32, 45, 58, 13] [12 33 54 57 60 13] [] [13] 6.0\n",
            "[11, 22, 33, 46, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 58, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 46.0 <------\n",
            "----- 15 ------ \n",
            "[12, 24, 35, 48, 59, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 39.0 <------\n",
            "----- 16 ------ \n",
            "[12, 23, 35, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 35, 47, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "-----> Match Score: 48.0 <------\n",
            "----- 17 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 18 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 35, 46, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[13, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 19 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 20 ------ \n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 40.0 <------\n",
            "----- 21 ------ \n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 34.0 <------\n",
            "----- 22 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[13, 24, 35, 46, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[13, 24, 35, 47, 58, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "-----> Match Score: 34.0 <------\n",
            "----- 23 ------ \n",
            "[11, 24, 35, 47, 58, 13] [12 33 54 57 60 13] [] [13] 6.0\n",
            "[12, 22, 34, 45, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 41.0 <------\n",
            "----- 24 ------ \n",
            "[12, 24, 36, 48, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[11, 22, 33, 44, 54, 12] [19 37 48 61 63 12] [] [12] 6.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[13, 24, 35, 48, 60, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 60.0 <------\n",
            "----- 25 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 26 ------ \n",
            "[11, 21, 32, 45, 57, 13] [12 33 54 57 60 13] [57] [13] 7.0\n",
            "[11, 22, 33, 46, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 27 ------ \n",
            "[13, 25, 37, 49, 59, 13] [ 6 15 50 59 60 13] [59] [13] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 24, 35, 48, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 58, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 23, 34, 46, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 46.0 <------\n",
            "----- 28 ------ \n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 46, 57, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 27.0 <------\n",
            "----- 29 ------ \n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 27.0 <------\n",
            "----- 30 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 42.0 <------\n",
            "----- 31 ------ \n",
            "[11, 22, 32, 45, 58, 13] [12 33 54 57 60 13] [] [13] 6.0\n",
            "[11, 22, 33, 45, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 40.0 <------\n",
            "----- 32 ------ \n",
            "[12, 22, 34, 45, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 48.0 <------\n",
            "----- 33 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 34 ------ \n",
            "[12, 23, 34, 47, 57, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[13, 24, 35, 47, 59, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 38, 50, 61, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[13, 25, 36, 49, 60, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 37.0 <------\n",
            "----- 35 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 48.0 <------\n",
            "----- 36 ------ \n",
            "[11, 22, 33, 45, 58, 13] [12 33 54 57 60 13] [33] [13] 7.0\n",
            "[11, 22, 33, 46, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 24, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 23, 34, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[11, 21, 32, 44, 57, 13] [12 21 32 44 66 15] [32, 44, 21] [] 6.0\n",
            "-----> Match Score: 46.0 <------\n",
            "----- 37 ------ \n",
            "[13, 25, 37, 49, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[11, 21, 33, 45, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[12, 23, 34, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[11, 22, 34, 46, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 45.0 <------\n",
            "----- 38 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 39 ------ \n",
            "[12, 23, 34, 46, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 34.0 <------\n",
            "----- 40 ------ \n",
            "[11, 22, 32, 45, 57, 13] [12 33 54 57 60 13] [57] [13] 7.0\n",
            "[11, 22, 33, 45, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 38, 50, 60, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 41 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 42 ------ \n",
            "[12, 22, 34, 45, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 42.0 <------\n",
            "----- 43 ------ \n",
            "[11, 23, 33, 44, 54, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 23, 34, 46, 56, 13] [ 8 12 42 46 56 12] [56, 12, 46] [] 6.0\n",
            "[12, 23, 34, 46, 56, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 32.0 <------\n",
            "----- 44 ------ \n",
            "[12, 23, 34, 46, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 34.0 <------\n",
            "----- 45 ------ \n",
            "[11, 22, 33, 45, 57, 13] [12 33 54 57 60 13] [33, 57] [13] 9.0\n",
            "[11, 22, 33, 45, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 38, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[11, 22, 34, 46, 58, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "-----> Match Score: 49.0 <------\n",
            "----- 46 ------ \n",
            "[12, 22, 34, 45, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 42.0 <------\n",
            "----- 47 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 48 ------ \n",
            "[11, 22, 32, 45, 57, 13] [12 33 54 57 60 13] [57] [13] 7.0\n",
            "[11, 22, 33, 46, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 41.0 <------\n",
            "----- 49 ------ \n",
            "[12, 22, 33, 45, 55, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[8, 39, 42, 50, 49, 20] [ 7 15 18 19 36 20] [] [20] 6.0\n",
            "[12, 23, 34, 45, 55, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 48, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 58, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 37.0 <------\n",
            "----- 50 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 35, 46, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[13, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 51 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 52 ------ \n",
            "[13, 25, 37, 49, 59, 13] [ 6 15 50 59 60 13] [59] [13] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[13, 24, 35, 48, 58, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 24, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 41.0 <------\n",
            "----- 53 ------ \n",
            "[12, 22, 34, 45, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 37, 49, 60, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[13, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 54 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 55 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 56 ------ \n",
            "[11, 22, 33, 45, 58, 13] [12 33 54 57 60 13] [33] [13] 7.0\n",
            "[11, 22, 33, 45, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 57 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[13, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 48.0 <------\n",
            "----- 58 ------ \n",
            "[12, 23, 34, 46, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 46, 57, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 59 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 60 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 61 ------ \n",
            "[11, 22, 33, 45, 56, 13] [12 33 54 57 60 13] [33] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 62 ------ \n",
            "[11, 21, 31, 44, 57, 13] [12 33 54 57 60 13] [57] [13] 7.0\n",
            "[11, 22, 33, 46, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 50, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 40.0 <------\n",
            "----- 63 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 64 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 65 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 66 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 67 ------ \n",
            "[12, 23, 34, 45, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 42.0 <------\n",
            "----- 68 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 69 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 35, 46, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[11, 22, 33, 44, 55, 13] [11 33 44 59 67  8] [33, 11, 44] [] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 70 ------ \n",
            "[12, 23, 35, 47, 58, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 58, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 71 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 13] [ 2 23 40 59 69 13] [59] [13] 7.0\n",
            "-----> Match Score: 55.0 <------\n",
            "----- 72 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 73 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 74 ------ \n",
            "[12, 24, 36, 48, 59, 13] [ 6 15 50 59 60 13] [59] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 23, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 14] [19 25 43 46 48 14] [46] [14] 7.0\n",
            "[12, 24, 37, 50, 60, 12] [23 30 33 40 69 12] [] [12] 6.0\n",
            "[12, 23, 34, 46, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 23, 34, 46, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 23, 34, 46, 58, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 51.0 <------\n",
            "----- 75 ------ \n",
            "[11, 21, 32, 45, 58, 13] [12 33 54 57 60 13] [] [13] 6.0\n",
            "[11, 22, 33, 46, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 46.0 <------\n",
            "----- 76 ------ \n",
            "[13, 24, 37, 49, 59, 13] [ 6 15 50 59 60 13] [59] [13] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[12, 24, 37, 49, 59, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 46.0 <------\n",
            "----- 77 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 78 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 79 ------ \n",
            "[11, 22, 33, 46, 57, 13] [12 33 54 57 60 13] [33, 57] [13] 9.0\n",
            "[11, 22, 33, 46, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 24, 37, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 35, 48, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 55.0 <------\n",
            "----- 80 ------ \n",
            "[12, 22, 34, 45, 55, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[13, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 81 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 82 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 83 ------ \n",
            "[12, 22, 34, 45, 55, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 42.0 <------\n",
            "----- 84 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 35, 46, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[13, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 85 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 46.0 <------\n",
            "----- 86 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 35, 48, 58, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 53.0 <------\n",
            "----- 87 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 88 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 89 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 90 ------ \n",
            "[11, 22, 34, 46, 57, 13] [12 33 54 57 60 13] [57] [13] 7.0\n",
            "[12, 22, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 25, 37, 49, 60, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 24, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "-----> Match Score: 48.0 <------\n",
            "----- 91 ------ \n",
            "[11, 21, 32, 44, 57, 13] [12 33 54 57 60 13] [57] [13] 7.0\n",
            "[11, 22, 33, 45, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 92 ------ \n",
            "[12, 23, 34, 45, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "-----> Match Score: 48.0 <------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 93 ------ \n",
            "[12, 23, 34, 46, 56, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 46.0 <------\n",
            "----- 94 ------ \n",
            "[11, 22, 33, 45, 57, 13] [12 33 54 57 60 13] [33, 57] [13] 9.0\n",
            "[12, 23, 34, 46, 58, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 25, 37, 49, 59, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 24, 37, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "-----> Match Score: 50.0 <------\n",
            "----- 95 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 96 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 97 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 98 ------ \n",
            "[12, 23, 34, 46, 56, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 24, 36, 49, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 60, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 48, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 54.0 <------\n",
            "----- 99 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 100 ------ \n",
            "[13, 25, 37, 49, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[13, 25, 37, 49, 58, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 23, 34, 46, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 39.0 <------\n",
            "----- 101 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 34, 46, 57, 13] [27 32 34 43 52 13] [34] [13] 7.0\n",
            "[13, 25, 37, 49, 60, 14] [16 25 36 44 55 14] [25] [14] 7.0\n",
            "[13, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 58, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 23, 34, 46, 57, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[11, 21, 32, 44, 55, 13] [12 21 32 44 66 15] [32, 44, 21] [] 6.0\n",
            "-----> Match Score: 62.0 <------\n",
            "----- 102 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "----- 103 ------ \n",
            "[12, 23, 34, 46, 57, 13] [12 33 54 57 60 13] [57, 12] [13] 9.0\n",
            "[12, 23, 35, 46, 57, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 60, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[13, 24, 36, 49, 60, 14] [ 7 24 36 54 60 23] [24, 36, 60] [] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 24, 35, 48, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "-----> Match Score: 47.0 <------\n",
            "----- 104 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n"
          ]
        }
      ],
      "source": [
        "winningScore = 0\n",
        "winningState = 0\n",
        "\n",
        "in_randoms = 1\n",
        "while in_randoms <= 104:\n",
        "    # Fitting MLPC\n",
        "    MLPCSolver = \"lbfgs\" # solver{\"lbfgs\", \"sgd\", \"adam\"}, default=adam\n",
        "    MLPclf = MLPRegressor(hidden_layer_sizes=(4,4), max_iter=1536, alpha=0.0001,  verbose=10,\n",
        "                           solver=MLPCSolver, random_state=in_randoms, tol=0.000000001)\n",
        "    MLPclf.fit(X_train, y_train)\n",
        "\n",
        "    # Predicting the Test set results\n",
        "    y_r_pred = MLPclf.predict(X_test)\n",
        "\n",
        "    totalMatchScore = 0\n",
        "    print('----- ' + str(in_randoms) + ' ------ ')\n",
        "    for index, pred in enumerate(y_r_pred):\n",
        "        pred = list(map(round, pred))\n",
        "        comparePOS = list(set(pred[:5]) & set(y_test[index][:5]))\n",
        "        comparePWB = list(set(pred[5:]) & set(y_test[index][5:]))\n",
        "        matchScore = predictionScore(pred[:5], y_test[index][:5]) + (predictionScore(pred[5:], y_test[index][5:])*6)\n",
        "        if matchScore >= 6:\n",
        "            totalMatchScore += matchScore\n",
        "            print(pred, y_test[index], comparePOS, comparePWB, matchScore)#, round(accuracy,3), X_test[index])\n",
        "        # Find the winner!\n",
        "        if totalMatchScore >= winningScore:\n",
        "            winningScore = totalMatchScore\n",
        "            winningState = in_randoms\n",
        "    print('-----> Match Score: ' + str(totalMatchScore) + ' <------')\n",
        "\n",
        "    in_randoms += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "botsdTX3sdx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f77a98-f808-4820-a3cb-5483d1838dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----> Winner is 101 with 62 <------\n",
            "[12. 24. 36. 48. 60. 14.] [29.97, 74.8, 86.84, 81, 81.06, 2]\n"
          ]
        }
      ],
      "source": [
        "print('-----> Winner is ' + str(int(winningState)) + ' with ' + str(int(winningScore)) + ' <------')\n",
        "# Fitting RNC\n",
        "MLPclf = MLPRegressor(hidden_layer_sizes=(4,4), max_iter=1536, alpha=0.0001,  verbose=10,\n",
        "                           solver=MLPCSolver, random_state=int(winningState), tol=0.000000001)\n",
        "MLPclf.fit(X, y)\n",
        "\n",
        "# Predicting the next draw set results\n",
        "nextdraw_MLpred = MLPclf.predict([nextdraw_set])\n",
        "nextdraw_MLpred[0] = list(map(round, nextdraw_MLpred[0]))\n",
        "print(nextdraw_MLpred[0], nextdraw_set)\n",
        "\n",
        "nextDrawResults.append([{\"numbers\":list(map(round, nextdraw_MLpred[0]))},{\"score\":int(winningScore)},{\"class\":\"weather - MLPRegressor - L\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVjs_yD_lOz"
      },
      "source": [
        "# MLPRegressor - sgd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64HVo0Zc_lOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430068d4-6670-451d-f0ff-15fc5d66ead4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration 194, loss = 60.98349086\n",
            "Iteration 195, loss = 60.98316600\n",
            "Iteration 196, loss = 60.98326786\n",
            "Iteration 197, loss = 60.98294904\n",
            "Iteration 198, loss = 60.98554822\n",
            "Iteration 199, loss = 60.98276235\n",
            "Iteration 200, loss = 60.98316598\n",
            "Iteration 201, loss = 60.98273116\n",
            "Iteration 202, loss = 60.98295140\n",
            "Iteration 203, loss = 60.98254361\n",
            "Iteration 204, loss = 60.98241354\n",
            "Iteration 205, loss = 60.98291100\n",
            "Iteration 206, loss = 60.98301739\n",
            "Iteration 207, loss = 60.98278365\n",
            "Iteration 208, loss = 60.98230240\n",
            "Iteration 209, loss = 60.98235430\n",
            "Iteration 210, loss = 60.98274019\n",
            "Iteration 211, loss = 60.98307833\n",
            "Iteration 212, loss = 60.98224058\n",
            "Iteration 213, loss = 60.98213066\n",
            "Iteration 214, loss = 60.98277400\n",
            "Iteration 215, loss = 60.98189167\n",
            "Iteration 216, loss = 60.98217713\n",
            "Iteration 217, loss = 60.98196309\n",
            "Iteration 218, loss = 60.98201934\n",
            "Iteration 219, loss = 60.98239725\n",
            "Iteration 220, loss = 60.98195054\n",
            "Iteration 221, loss = 60.98181990\n",
            "Iteration 222, loss = 60.98192968\n",
            "Iteration 223, loss = 60.98254702\n",
            "Iteration 224, loss = 60.98199723\n",
            "Iteration 225, loss = 60.98224253\n",
            "Iteration 226, loss = 60.98219472\n",
            "Iteration 227, loss = 60.98177938\n",
            "Iteration 228, loss = 60.98168199\n",
            "Iteration 229, loss = 60.98281326\n",
            "Iteration 230, loss = 60.98174569\n",
            "Iteration 231, loss = 60.98194588\n",
            "Iteration 232, loss = 60.98163080\n",
            "Iteration 233, loss = 60.98173736\n",
            "Iteration 234, loss = 60.98244417\n",
            "Iteration 235, loss = 60.98184749\n",
            "Iteration 236, loss = 60.98274818\n",
            "Iteration 237, loss = 60.98208749\n",
            "Iteration 238, loss = 60.98154644\n",
            "Iteration 239, loss = 60.98157592\n",
            "Iteration 240, loss = 60.98176071\n",
            "Iteration 241, loss = 60.98147605\n",
            "Iteration 242, loss = 60.98297800\n",
            "Iteration 243, loss = 60.98170310\n",
            "Iteration 244, loss = 60.98209730\n",
            "Iteration 245, loss = 60.98174516\n",
            "Iteration 246, loss = 60.98183060\n",
            "Iteration 247, loss = 60.98165960\n",
            "Iteration 248, loss = 60.98186134\n",
            "Iteration 249, loss = 60.98206452\n",
            "Iteration 250, loss = 60.98207375\n",
            "Iteration 251, loss = 60.98232920\n",
            "Iteration 252, loss = 60.98160586\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 55 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 4487.88471443\n",
            "Iteration 2, loss = 710.73803675\n",
            "Iteration 3, loss = 694.92498033\n",
            "Iteration 4, loss = 673.53334499\n",
            "Iteration 5, loss = 648.40633141\n",
            "Iteration 6, loss = 620.93156434\n",
            "Iteration 7, loss = 592.78293828\n",
            "Iteration 8, loss = 564.22324959\n",
            "Iteration 9, loss = 535.91965283\n",
            "Iteration 10, loss = 508.49523763\n",
            "Iteration 11, loss = 481.98318551\n",
            "Iteration 12, loss = 456.44733604\n",
            "Iteration 13, loss = 432.23508476\n",
            "Iteration 14, loss = 409.28812524\n",
            "Iteration 15, loss = 387.51016976\n",
            "Iteration 16, loss = 366.97972670\n",
            "Iteration 17, loss = 347.75754415\n",
            "Iteration 18, loss = 329.57965712\n",
            "Iteration 19, loss = 312.47068796\n",
            "Iteration 20, loss = 296.48283858\n",
            "Iteration 21, loss = 281.46533328\n",
            "Iteration 22, loss = 267.41224021\n",
            "Iteration 23, loss = 254.22062434\n",
            "Iteration 24, loss = 241.86437300\n",
            "Iteration 25, loss = 230.19098208\n",
            "Iteration 26, loss = 219.40776450\n",
            "Iteration 27, loss = 209.34683087\n",
            "Iteration 28, loss = 199.75275320\n",
            "Iteration 29, loss = 190.83744598\n",
            "Iteration 30, loss = 182.55772623\n",
            "Iteration 31, loss = 174.75237771\n",
            "Iteration 32, loss = 167.47967965\n",
            "Iteration 33, loss = 160.71198621\n",
            "Iteration 34, loss = 154.29404820\n",
            "Iteration 35, loss = 148.25377959\n",
            "Iteration 36, loss = 142.76002008\n",
            "Iteration 37, loss = 137.46715051\n",
            "Iteration 38, loss = 132.58838924\n",
            "Iteration 39, loss = 127.99190261\n",
            "Iteration 40, loss = 123.74886761\n",
            "Iteration 41, loss = 119.68857731\n",
            "Iteration 42, loss = 115.94979181\n",
            "Iteration 43, loss = 112.43814827\n",
            "Iteration 44, loss = 109.19595094\n",
            "Iteration 45, loss = 106.12368994\n",
            "Iteration 46, loss = 103.22052745\n",
            "Iteration 47, loss = 100.47746588\n",
            "Iteration 48, loss = 97.97890560\n",
            "Iteration 49, loss = 95.64061889\n",
            "Iteration 50, loss = 93.42274770\n",
            "Iteration 51, loss = 91.33704440\n",
            "Iteration 52, loss = 89.43127211\n",
            "Iteration 53, loss = 87.63561290\n",
            "Iteration 54, loss = 85.90826480\n",
            "Iteration 55, loss = 84.36128447\n",
            "Iteration 56, loss = 82.85341645\n",
            "Iteration 57, loss = 81.49640220\n",
            "Iteration 58, loss = 80.15822287\n",
            "Iteration 59, loss = 78.95591407\n",
            "Iteration 60, loss = 77.82448095\n",
            "Iteration 61, loss = 76.75180180\n",
            "Iteration 62, loss = 75.76413360\n",
            "Iteration 63, loss = 74.84334931\n",
            "Iteration 64, loss = 73.94191616\n",
            "Iteration 65, loss = 73.14779161\n",
            "Iteration 66, loss = 72.39093924\n",
            "Iteration 67, loss = 71.64578434\n",
            "Iteration 68, loss = 70.98169542\n",
            "Iteration 69, loss = 70.37345151\n",
            "Iteration 70, loss = 69.77219758\n",
            "Iteration 71, loss = 69.21647476\n",
            "Iteration 72, loss = 68.70794669\n",
            "Iteration 73, loss = 68.23377229\n",
            "Iteration 74, loss = 67.77948085\n",
            "Iteration 75, loss = 67.36252331\n",
            "Iteration 76, loss = 66.96904467\n",
            "Iteration 77, loss = 66.59221337\n",
            "Iteration 78, loss = 66.24476464\n",
            "Iteration 79, loss = 65.93450408\n",
            "Iteration 80, loss = 65.62008708\n",
            "Iteration 81, loss = 65.33676146\n",
            "Iteration 82, loss = 65.07625907\n",
            "Iteration 83, loss = 64.83236855\n",
            "Iteration 84, loss = 64.60039095\n",
            "Iteration 85, loss = 64.37515313\n",
            "Iteration 86, loss = 64.18367811\n",
            "Iteration 87, loss = 63.99178816\n",
            "Iteration 88, loss = 63.80757023\n",
            "Iteration 89, loss = 63.64650255\n",
            "Iteration 90, loss = 63.48585630\n",
            "Iteration 91, loss = 63.34727952\n",
            "Iteration 92, loss = 63.21458539\n",
            "Iteration 93, loss = 63.08491284\n",
            "Iteration 94, loss = 62.96919001\n",
            "Iteration 95, loss = 62.86136547\n",
            "Iteration 96, loss = 62.74228195\n",
            "Iteration 97, loss = 62.65717663\n",
            "Iteration 98, loss = 62.55763635\n",
            "Iteration 99, loss = 62.48091794\n",
            "Iteration 100, loss = 62.39260099\n",
            "Iteration 101, loss = 62.32431022\n",
            "Iteration 102, loss = 62.25716896\n",
            "Iteration 103, loss = 62.18684176\n",
            "Iteration 104, loss = 62.12377366\n",
            "Iteration 105, loss = 62.07079925\n",
            "Iteration 106, loss = 62.01431478\n",
            "Iteration 107, loss = 61.96429600\n",
            "Iteration 108, loss = 61.91839626\n",
            "Iteration 109, loss = 61.87197384\n",
            "Iteration 110, loss = 61.83320470\n",
            "Iteration 111, loss = 61.79736783\n",
            "Iteration 112, loss = 61.75764421\n",
            "Iteration 113, loss = 61.72178515\n",
            "Iteration 114, loss = 61.69752266\n",
            "Iteration 115, loss = 61.66537816\n",
            "Iteration 116, loss = 61.64106804\n",
            "Iteration 117, loss = 61.61079280\n",
            "Iteration 118, loss = 61.58786979\n",
            "Iteration 119, loss = 61.56444433\n",
            "Iteration 120, loss = 61.54316720\n",
            "Iteration 121, loss = 61.52124603\n",
            "Iteration 122, loss = 61.50655079\n",
            "Iteration 123, loss = 61.48540759\n",
            "Iteration 124, loss = 61.47002933\n",
            "Iteration 125, loss = 61.45754583\n",
            "Iteration 126, loss = 61.44109963\n",
            "Iteration 127, loss = 61.42738680\n",
            "Iteration 128, loss = 61.41539395\n",
            "Iteration 129, loss = 61.40438250\n",
            "Iteration 130, loss = 61.39132211\n",
            "Iteration 131, loss = 61.38145774\n",
            "Iteration 132, loss = 61.37000975\n",
            "Iteration 133, loss = 61.36472218\n",
            "Iteration 134, loss = 61.35729899\n",
            "Iteration 135, loss = 61.34521988\n",
            "Iteration 136, loss = 61.33854579\n",
            "Iteration 137, loss = 61.33076889\n",
            "Iteration 138, loss = 61.32564601\n",
            "Iteration 139, loss = 61.31925576\n",
            "Iteration 140, loss = 61.31347299\n",
            "Iteration 141, loss = 61.31084571\n",
            "Iteration 142, loss = 61.30290656\n",
            "Iteration 143, loss = 61.29887677\n",
            "Iteration 144, loss = 61.29573837\n",
            "Iteration 145, loss = 61.28974647\n",
            "Iteration 146, loss = 61.28628230\n",
            "Iteration 147, loss = 61.28255106\n",
            "Iteration 148, loss = 61.27966281\n",
            "Iteration 149, loss = 61.27638565\n",
            "Iteration 150, loss = 61.27488562\n",
            "Iteration 151, loss = 61.27020112\n",
            "Iteration 152, loss = 61.26845917\n",
            "Iteration 153, loss = 61.26631167\n",
            "Iteration 154, loss = 61.26380309\n",
            "Iteration 155, loss = 61.26151316\n",
            "Iteration 156, loss = 61.25944962\n",
            "Iteration 157, loss = 61.25780543\n",
            "Iteration 158, loss = 61.25560267\n",
            "Iteration 159, loss = 61.25368163\n",
            "Iteration 160, loss = 61.25196642\n",
            "Iteration 161, loss = 61.25017637\n",
            "Iteration 162, loss = 61.25105241\n",
            "Iteration 163, loss = 61.24793751\n",
            "Iteration 164, loss = 61.24662631\n",
            "Iteration 165, loss = 61.24695613\n",
            "Iteration 166, loss = 61.24511714\n",
            "Iteration 167, loss = 61.24327520\n",
            "Iteration 168, loss = 61.24274640\n",
            "Iteration 169, loss = 61.24136004\n",
            "Iteration 170, loss = 61.24099584\n",
            "Iteration 171, loss = 61.24045779\n",
            "Iteration 172, loss = 61.24077248\n",
            "Iteration 173, loss = 61.23901726\n",
            "Iteration 174, loss = 61.23788517\n",
            "Iteration 175, loss = 61.23918934\n",
            "Iteration 176, loss = 61.23806066\n",
            "Iteration 177, loss = 61.23659233\n",
            "Iteration 178, loss = 61.23691021\n",
            "Iteration 179, loss = 61.23562227\n",
            "Iteration 180, loss = 61.23522258\n",
            "Iteration 181, loss = 61.23535769\n",
            "Iteration 182, loss = 61.23463388\n",
            "Iteration 183, loss = 61.23535503\n",
            "Iteration 184, loss = 61.23374403\n",
            "Iteration 185, loss = 61.23333747\n",
            "Iteration 186, loss = 61.23303148\n",
            "Iteration 187, loss = 61.23353842\n",
            "Iteration 188, loss = 61.23300463\n",
            "Iteration 189, loss = 61.23255505\n",
            "Iteration 190, loss = 61.23267662\n",
            "Iteration 191, loss = 61.23253974\n",
            "Iteration 192, loss = 61.23257357\n",
            "Iteration 193, loss = 61.23174925\n",
            "Iteration 194, loss = 61.23131805\n",
            "Iteration 195, loss = 61.23110377\n",
            "Iteration 196, loss = 61.23098006\n",
            "Iteration 197, loss = 61.23103239\n",
            "Iteration 198, loss = 61.23130007\n",
            "Iteration 199, loss = 61.23091628\n",
            "Iteration 200, loss = 61.23097865\n",
            "Iteration 201, loss = 61.23069040\n",
            "Iteration 202, loss = 61.23150031\n",
            "Iteration 203, loss = 61.23032539\n",
            "Iteration 204, loss = 61.23116641\n",
            "Iteration 205, loss = 61.23081679\n",
            "Iteration 206, loss = 61.23055574\n",
            "Iteration 207, loss = 61.23023502\n",
            "Iteration 208, loss = 61.23058484\n",
            "Iteration 209, loss = 61.23068198\n",
            "Iteration 210, loss = 61.23018740\n",
            "Iteration 211, loss = 61.23007204\n",
            "Iteration 212, loss = 61.23013778\n",
            "Iteration 213, loss = 61.23051674\n",
            "Iteration 214, loss = 61.23005243\n",
            "Iteration 215, loss = 61.22990694\n",
            "Iteration 216, loss = 61.22987979\n",
            "Iteration 217, loss = 61.23005848\n",
            "Iteration 218, loss = 61.23010541\n",
            "Iteration 219, loss = 61.22980622\n",
            "Iteration 220, loss = 61.22969695\n",
            "Iteration 221, loss = 61.22980826\n",
            "Iteration 222, loss = 61.23040939\n",
            "Iteration 223, loss = 61.23054894\n",
            "Iteration 224, loss = 61.23067905\n",
            "Iteration 225, loss = 61.23002532\n",
            "Iteration 226, loss = 61.22960707\n",
            "Iteration 227, loss = 61.23038385\n",
            "Iteration 228, loss = 61.23057097\n",
            "Iteration 229, loss = 61.23010998\n",
            "Iteration 230, loss = 61.22968606\n",
            "Iteration 231, loss = 61.23050147\n",
            "Iteration 232, loss = 61.22995343\n",
            "Iteration 233, loss = 61.23043522\n",
            "Iteration 234, loss = 61.22955734\n",
            "Iteration 235, loss = 61.22964501\n",
            "Iteration 236, loss = 61.22957096\n",
            "Iteration 237, loss = 61.22960473\n",
            "Iteration 238, loss = 61.22979032\n",
            "Iteration 239, loss = 61.23003139\n",
            "Iteration 240, loss = 61.22998389\n",
            "Iteration 241, loss = 61.22960497\n",
            "Iteration 242, loss = 61.22967486\n",
            "Iteration 243, loss = 61.22952464\n",
            "Iteration 244, loss = 61.22960112\n",
            "Iteration 245, loss = 61.22961718\n",
            "Iteration 246, loss = 61.22959473\n",
            "Iteration 247, loss = 61.22966119\n",
            "Iteration 248, loss = 61.22978285\n",
            "Iteration 249, loss = 61.22967669\n",
            "Iteration 250, loss = 61.22953600\n",
            "Iteration 251, loss = 61.22966225\n",
            "Iteration 252, loss = 61.22978733\n",
            "Iteration 253, loss = 61.22976590\n",
            "Iteration 254, loss = 61.22947372\n",
            "Iteration 255, loss = 61.22956181\n",
            "Iteration 256, loss = 61.22955414\n",
            "Iteration 257, loss = 61.22989479\n",
            "Iteration 258, loss = 61.22968713\n",
            "Iteration 259, loss = 61.23020008\n",
            "Iteration 260, loss = 61.22991923\n",
            "Iteration 261, loss = 61.22965297\n",
            "Iteration 262, loss = 61.22963063\n",
            "Iteration 263, loss = 61.22967775\n",
            "Iteration 264, loss = 61.22964414\n",
            "Iteration 265, loss = 61.22968261\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 56 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 1391.92263711\n",
            "Iteration 2, loss = 706.10890286\n",
            "Iteration 3, loss = 692.54931669\n",
            "Iteration 4, loss = 672.84301153\n",
            "Iteration 5, loss = 648.77662357\n",
            "Iteration 6, loss = 622.33764356\n",
            "Iteration 7, loss = 594.69076881\n",
            "Iteration 8, loss = 566.35359081\n",
            "Iteration 9, loss = 538.52105269\n",
            "Iteration 10, loss = 511.06019960\n",
            "Iteration 11, loss = 484.63436939\n",
            "Iteration 12, loss = 459.05566898\n",
            "Iteration 13, loss = 434.95160613\n",
            "Iteration 14, loss = 411.78257997\n",
            "Iteration 15, loss = 389.94696012\n",
            "Iteration 16, loss = 369.40481251\n",
            "Iteration 17, loss = 350.04519554\n",
            "Iteration 18, loss = 331.67804688\n",
            "Iteration 19, loss = 314.52861720\n",
            "Iteration 20, loss = 298.55809436\n",
            "Iteration 21, loss = 283.38661499\n",
            "Iteration 22, loss = 269.19847434\n",
            "Iteration 23, loss = 255.97756340\n",
            "Iteration 24, loss = 243.60609443\n",
            "Iteration 25, loss = 231.92218298\n",
            "Iteration 26, loss = 221.02143687\n",
            "Iteration 27, loss = 210.76608665\n",
            "Iteration 28, loss = 201.16300651\n",
            "Iteration 29, loss = 192.31561310\n",
            "Iteration 30, loss = 183.91106421\n",
            "Iteration 31, loss = 176.15872524\n",
            "Iteration 32, loss = 168.78037510\n",
            "Iteration 33, loss = 161.90309734\n",
            "Iteration 34, loss = 155.45518897\n",
            "Iteration 35, loss = 149.48578083\n",
            "Iteration 36, loss = 143.85669832\n",
            "Iteration 37, loss = 138.56797061\n",
            "Iteration 38, loss = 133.63087090\n",
            "Iteration 39, loss = 129.03040112\n",
            "Iteration 40, loss = 124.71036366\n",
            "Iteration 41, loss = 120.68802137\n",
            "Iteration 42, loss = 116.91171804\n",
            "Iteration 43, loss = 113.36098210\n",
            "Iteration 44, loss = 110.04852062\n",
            "Iteration 45, loss = 106.95822499\n",
            "Iteration 46, loss = 104.06176573\n",
            "Iteration 47, loss = 101.31177629\n",
            "Iteration 48, loss = 98.81813247\n",
            "Iteration 49, loss = 96.41925624\n",
            "Iteration 50, loss = 94.19292276\n",
            "Iteration 51, loss = 92.10974192\n",
            "Iteration 52, loss = 90.17113826\n",
            "Iteration 53, loss = 88.35800431\n",
            "Iteration 54, loss = 86.62620909\n",
            "Iteration 55, loss = 85.07510980\n",
            "Iteration 56, loss = 83.56522807\n",
            "Iteration 57, loss = 82.16438818\n",
            "Iteration 58, loss = 80.86655356\n",
            "Iteration 59, loss = 79.62625959\n",
            "Iteration 60, loss = 78.51527358\n",
            "Iteration 61, loss = 77.44542530\n",
            "Iteration 62, loss = 76.41168213\n",
            "Iteration 63, loss = 75.50052659\n",
            "Iteration 64, loss = 74.60237443\n",
            "Iteration 65, loss = 73.78295307\n",
            "Iteration 66, loss = 73.03192468\n",
            "Iteration 67, loss = 72.30807589\n",
            "Iteration 68, loss = 71.63226764\n",
            "Iteration 69, loss = 71.01219173\n",
            "Iteration 70, loss = 70.41851694\n",
            "Iteration 71, loss = 69.87090015\n",
            "Iteration 72, loss = 69.34556323\n",
            "Iteration 73, loss = 68.87571987\n",
            "Iteration 74, loss = 68.40813983\n",
            "Iteration 75, loss = 67.99705561\n",
            "Iteration 76, loss = 67.61690818\n",
            "Iteration 77, loss = 67.23728870\n",
            "Iteration 78, loss = 66.88148984\n",
            "Iteration 79, loss = 66.55260741\n",
            "Iteration 80, loss = 66.25248163\n",
            "Iteration 81, loss = 65.97737825\n",
            "Iteration 82, loss = 65.71104373\n",
            "Iteration 83, loss = 65.45498188\n",
            "Iteration 84, loss = 65.22875375\n",
            "Iteration 85, loss = 65.01339037\n",
            "Iteration 86, loss = 64.80864234\n",
            "Iteration 87, loss = 64.61869849\n",
            "Iteration 88, loss = 64.43730889\n",
            "Iteration 89, loss = 64.26922991\n",
            "Iteration 90, loss = 64.10801726\n",
            "Iteration 91, loss = 63.96655324\n",
            "Iteration 92, loss = 63.82953531\n",
            "Iteration 93, loss = 63.70384363\n",
            "Iteration 94, loss = 63.58023265\n",
            "Iteration 95, loss = 63.46692758\n",
            "Iteration 96, loss = 63.36848107\n",
            "Iteration 97, loss = 63.26863652\n",
            "Iteration 98, loss = 63.17202062\n",
            "Iteration 99, loss = 63.08967733\n",
            "Iteration 100, loss = 63.00714442\n",
            "Iteration 101, loss = 62.93481574\n",
            "Iteration 102, loss = 62.86031739\n",
            "Iteration 103, loss = 62.80215928\n",
            "Iteration 104, loss = 62.73400475\n",
            "Iteration 105, loss = 62.67798702\n",
            "Iteration 106, loss = 62.62632477\n",
            "Iteration 107, loss = 62.57620083\n",
            "Iteration 108, loss = 62.52923461\n",
            "Iteration 109, loss = 62.48204719\n",
            "Iteration 110, loss = 62.44036062\n",
            "Iteration 111, loss = 62.40427284\n",
            "Iteration 112, loss = 62.36660831\n",
            "Iteration 113, loss = 62.32926181\n",
            "Iteration 114, loss = 62.29928086\n",
            "Iteration 115, loss = 62.27073693\n",
            "Iteration 116, loss = 62.24240334\n",
            "Iteration 117, loss = 62.21840877\n",
            "Iteration 118, loss = 62.19260560\n",
            "Iteration 119, loss = 62.16648547\n",
            "Iteration 120, loss = 62.14823427\n",
            "Iteration 121, loss = 62.13047459\n",
            "Iteration 122, loss = 62.10974987\n",
            "Iteration 123, loss = 62.08917787\n",
            "Iteration 124, loss = 62.07474820\n",
            "Iteration 125, loss = 62.06012578\n",
            "Iteration 126, loss = 62.04438734\n",
            "Iteration 127, loss = 62.03195585\n",
            "Iteration 128, loss = 62.02242167\n",
            "Iteration 129, loss = 62.00695281\n",
            "Iteration 130, loss = 61.99811664\n",
            "Iteration 131, loss = 61.98539616\n",
            "Iteration 132, loss = 61.97739459\n",
            "Iteration 133, loss = 61.96756422\n",
            "Iteration 134, loss = 61.95762050\n",
            "Iteration 135, loss = 61.95156764\n",
            "Iteration 136, loss = 61.94281242\n",
            "Iteration 137, loss = 61.93847944\n",
            "Iteration 138, loss = 61.93044878\n",
            "Iteration 139, loss = 61.92379316\n",
            "Iteration 140, loss = 61.91987503\n",
            "Iteration 141, loss = 61.91553212\n",
            "Iteration 142, loss = 61.90673365\n",
            "Iteration 143, loss = 61.90345159\n",
            "Iteration 144, loss = 61.89961373\n",
            "Iteration 145, loss = 61.89555345\n",
            "Iteration 146, loss = 61.89123735\n",
            "Iteration 147, loss = 61.88809204\n",
            "Iteration 148, loss = 61.88418891\n",
            "Iteration 149, loss = 61.88211984\n",
            "Iteration 150, loss = 61.87915045\n",
            "Iteration 151, loss = 61.87485607\n",
            "Iteration 152, loss = 61.87231357\n",
            "Iteration 153, loss = 61.87029711\n",
            "Iteration 154, loss = 61.86888706\n",
            "Iteration 155, loss = 61.86635514\n",
            "Iteration 156, loss = 61.86471239\n",
            "Iteration 157, loss = 61.86221165\n",
            "Iteration 158, loss = 61.86010042\n",
            "Iteration 159, loss = 61.85894207\n",
            "Iteration 160, loss = 61.85838552\n",
            "Iteration 161, loss = 61.85655230\n",
            "Iteration 162, loss = 61.85498028\n",
            "Iteration 163, loss = 61.85316345\n",
            "Iteration 164, loss = 61.85205591\n",
            "Iteration 165, loss = 61.85121132\n",
            "Iteration 166, loss = 61.85056085\n",
            "Iteration 167, loss = 61.84923835\n",
            "Iteration 168, loss = 61.84842715\n",
            "Iteration 169, loss = 61.84770574\n",
            "Iteration 170, loss = 61.84646687\n",
            "Iteration 171, loss = 61.84696500\n",
            "Iteration 172, loss = 61.84600580\n",
            "Iteration 173, loss = 61.84537907\n",
            "Iteration 174, loss = 61.84397333\n",
            "Iteration 175, loss = 61.84373613\n",
            "Iteration 176, loss = 61.84362248\n",
            "Iteration 177, loss = 61.84292935\n",
            "Iteration 178, loss = 61.84285971\n",
            "Iteration 179, loss = 61.84241572\n",
            "Iteration 180, loss = 61.84197960\n",
            "Iteration 181, loss = 61.84158234\n",
            "Iteration 182, loss = 61.84077963\n",
            "Iteration 183, loss = 61.84049802\n",
            "Iteration 184, loss = 61.84036575\n",
            "Iteration 185, loss = 61.84037927\n",
            "Iteration 186, loss = 61.83954921\n",
            "Iteration 187, loss = 61.83951523\n",
            "Iteration 188, loss = 61.83992734\n",
            "Iteration 189, loss = 61.83902764\n",
            "Iteration 190, loss = 61.83898812\n",
            "Iteration 191, loss = 61.83844492\n",
            "Iteration 192, loss = 61.83806451\n",
            "Iteration 193, loss = 61.83796267\n",
            "Iteration 194, loss = 61.83813382\n",
            "Iteration 195, loss = 61.83797256\n",
            "Iteration 196, loss = 61.83785254\n",
            "Iteration 197, loss = 61.83774210\n",
            "Iteration 198, loss = 61.83764111\n",
            "Iteration 199, loss = 61.83808930\n",
            "Iteration 200, loss = 61.83780513\n",
            "Iteration 201, loss = 61.83718093\n",
            "Iteration 202, loss = 61.83759501\n",
            "Iteration 203, loss = 61.83692258\n",
            "Iteration 204, loss = 61.83681133\n",
            "Iteration 205, loss = 61.83662258\n",
            "Iteration 206, loss = 61.83767404\n",
            "Iteration 207, loss = 61.83647950\n",
            "Iteration 208, loss = 61.83709372\n",
            "Iteration 209, loss = 61.83666074\n",
            "Iteration 210, loss = 61.83681809\n",
            "Iteration 211, loss = 61.83654359\n",
            "Iteration 212, loss = 61.83645798\n",
            "Iteration 213, loss = 61.83670504\n",
            "Iteration 214, loss = 61.83620729\n",
            "Iteration 215, loss = 61.83618589\n",
            "Iteration 216, loss = 61.83653333\n",
            "Iteration 217, loss = 61.83636085\n",
            "Iteration 218, loss = 61.83627939\n",
            "Iteration 219, loss = 61.83597716\n",
            "Iteration 220, loss = 61.83637876\n",
            "Iteration 221, loss = 61.83636219\n",
            "Iteration 222, loss = 61.83608137\n",
            "Iteration 223, loss = 61.83623465\n",
            "Iteration 224, loss = 61.83595886\n",
            "Iteration 225, loss = 61.83596383\n",
            "Iteration 226, loss = 61.83614644\n",
            "Iteration 227, loss = 61.83621243\n",
            "Iteration 228, loss = 61.83594456\n",
            "Iteration 229, loss = 61.83599732\n",
            "Iteration 230, loss = 61.83596829\n",
            "Iteration 231, loss = 61.83593962\n",
            "Iteration 232, loss = 61.83633840\n",
            "Iteration 233, loss = 61.83610551\n",
            "Iteration 234, loss = 61.83593360\n",
            "Iteration 235, loss = 61.83600447\n",
            "Iteration 236, loss = 61.83582264\n",
            "Iteration 237, loss = 61.83602569\n",
            "Iteration 238, loss = 61.83612434\n",
            "Iteration 239, loss = 61.83594805\n",
            "Iteration 240, loss = 61.83601887\n",
            "Iteration 241, loss = 61.83576249\n",
            "Iteration 242, loss = 61.83569070\n",
            "Iteration 243, loss = 61.83583437\n",
            "Iteration 244, loss = 61.83572901\n",
            "Iteration 245, loss = 61.83647488\n",
            "Iteration 246, loss = 61.83663803\n",
            "Iteration 247, loss = 61.83579707\n",
            "Iteration 248, loss = 61.83628278\n",
            "Iteration 249, loss = 61.83597426\n",
            "Iteration 250, loss = 61.83607047\n",
            "Iteration 251, loss = 61.83644612\n",
            "Iteration 252, loss = 61.83593455\n",
            "Iteration 253, loss = 61.83578655\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 57 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 2879540.90319652\n",
            "Iteration 2, loss = 6605.43651839\n",
            "Iteration 3, loss = 17262.13787764\n",
            "Iteration 4, loss = 28033.30988610\n",
            "Iteration 5, loss = 37143.69613739\n",
            "Iteration 6, loss = 45419.31731983\n",
            "Iteration 7, loss = 51925.00450634\n",
            "Iteration 8, loss = 57009.54195036\n",
            "Iteration 9, loss = 60875.58544919\n",
            "Iteration 10, loss = 63775.28269320\n",
            "Iteration 11, loss = 65933.01231755\n",
            "Iteration 12, loss = 67528.56401635\n",
            "Iteration 13, loss = 68703.87551123\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 58 ------ \n",
            "[12, 24, 35, 47, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 1  7 45 47 69 13] [47] [13] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 707.89752624\n",
            "Iteration 2, loss = 687.80633651\n",
            "Iteration 3, loss = 631.01870996\n",
            "Iteration 4, loss = 448.61633488\n",
            "Iteration 5, loss = 120.91839134\n",
            "Iteration 6, loss = 145.02986029\n",
            "Iteration 7, loss = 87.14368537\n",
            "Iteration 8, loss = 66.19902374\n",
            "Iteration 9, loss = 68.88233045\n",
            "Iteration 10, loss = 61.74892873\n",
            "Iteration 11, loss = 62.03285688\n",
            "Iteration 12, loss = 61.52286600\n",
            "Iteration 13, loss = 61.25570545\n",
            "Iteration 14, loss = 61.16078225\n",
            "Iteration 15, loss = 61.07232224\n",
            "Iteration 16, loss = 60.99771226\n",
            "Iteration 17, loss = 60.99392390\n",
            "Iteration 18, loss = 61.01944899\n",
            "Iteration 19, loss = 61.08529997\n",
            "Iteration 20, loss = 60.98575949\n",
            "Iteration 21, loss = 61.03118743\n",
            "Iteration 22, loss = 61.01095371\n",
            "Iteration 23, loss = 61.01867496\n",
            "Iteration 24, loss = 61.03345181\n",
            "Iteration 25, loss = 61.01960598\n",
            "Iteration 26, loss = 61.09679881\n",
            "Iteration 27, loss = 61.20318422\n",
            "Iteration 28, loss = 61.01652228\n",
            "Iteration 29, loss = 61.00884813\n",
            "Iteration 30, loss = 61.02089481\n",
            "Iteration 31, loss = 61.04479825\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 59 ------ \n",
            "[12, 23, 35, 47, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 1  7 45 47 69 13] [47] [13] 7.0\n",
            "-----> Match Score: 40.0 <------\n",
            "Iteration 1, loss = 679.16523573\n",
            "Iteration 2, loss = 432.27007635\n",
            "Iteration 3, loss = 101.95028791\n",
            "Iteration 4, loss = 165.09513270\n",
            "Iteration 5, loss = 68.63669365\n",
            "Iteration 6, loss = 71.43204000\n",
            "Iteration 7, loss = 64.94924117\n",
            "Iteration 8, loss = 62.22299703\n",
            "Iteration 9, loss = 62.06217192\n",
            "Iteration 10, loss = 61.18153230\n",
            "Iteration 11, loss = 61.32727059\n",
            "Iteration 12, loss = 61.06418370\n",
            "Iteration 13, loss = 61.14468413\n",
            "Iteration 14, loss = 61.01630486\n",
            "Iteration 15, loss = 60.98758745\n",
            "Iteration 16, loss = 61.04371022\n",
            "Iteration 17, loss = 61.02678151\n",
            "Iteration 18, loss = 61.05436665\n",
            "Iteration 19, loss = 61.01225974\n",
            "Iteration 20, loss = 61.29014890\n",
            "Iteration 21, loss = 61.00007511\n",
            "Iteration 22, loss = 61.03163498\n",
            "Iteration 23, loss = 61.02216264\n",
            "Iteration 24, loss = 61.00657841\n",
            "Iteration 25, loss = 61.00556300\n",
            "Iteration 26, loss = 61.11136348\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 60 ------ \n",
            "[12, 24, 35, 47, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 1  7 45 47 69 13] [47] [13] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 1393.63003492\n",
            "Iteration 2, loss = 692.27613386\n",
            "Iteration 3, loss = 675.19079990\n",
            "Iteration 4, loss = 653.18965958\n",
            "Iteration 5, loss = 627.89309045\n",
            "Iteration 6, loss = 600.87547468\n",
            "Iteration 7, loss = 573.19952389\n",
            "Iteration 8, loss = 545.25842802\n",
            "Iteration 9, loss = 517.84750382\n",
            "Iteration 10, loss = 491.10605086\n",
            "Iteration 11, loss = 465.58662381\n",
            "Iteration 12, loss = 440.98287831\n",
            "Iteration 13, loss = 417.60748719\n",
            "Iteration 14, loss = 395.50411009\n",
            "Iteration 15, loss = 374.61025571\n",
            "Iteration 16, loss = 354.84448955\n",
            "Iteration 17, loss = 336.21173095\n",
            "Iteration 18, loss = 318.72477484\n",
            "Iteration 19, loss = 302.39039412\n",
            "Iteration 20, loss = 286.97827567\n",
            "Iteration 21, loss = 272.61996385\n",
            "Iteration 22, loss = 259.11109232\n",
            "Iteration 23, loss = 246.32410845\n",
            "Iteration 24, loss = 234.53959901\n",
            "Iteration 25, loss = 223.36812715\n",
            "Iteration 26, loss = 212.95109974\n",
            "Iteration 27, loss = 203.29737723\n",
            "Iteration 28, loss = 194.12021224\n",
            "Iteration 29, loss = 185.50064464\n",
            "Iteration 30, loss = 177.58810309\n",
            "Iteration 31, loss = 170.08944031\n",
            "Iteration 32, loss = 163.05436862\n",
            "Iteration 33, loss = 156.54948264\n",
            "Iteration 34, loss = 150.43058692\n",
            "Iteration 35, loss = 144.66160095\n",
            "Iteration 36, loss = 139.30573265\n",
            "Iteration 37, loss = 134.26209954\n",
            "Iteration 38, loss = 129.52493139\n",
            "Iteration 39, loss = 125.17953580\n",
            "Iteration 40, loss = 121.03178354\n",
            "Iteration 41, loss = 117.17430501\n",
            "Iteration 42, loss = 113.62109578\n",
            "Iteration 43, loss = 110.19284148\n",
            "Iteration 44, loss = 107.02556315\n",
            "Iteration 45, loss = 104.09813638\n",
            "Iteration 46, loss = 101.31304767\n",
            "Iteration 47, loss = 98.73777887\n",
            "Iteration 48, loss = 96.28456895\n",
            "Iteration 49, loss = 94.06277384\n",
            "Iteration 50, loss = 91.95617253\n",
            "Iteration 51, loss = 89.92110727\n",
            "Iteration 52, loss = 88.08236452\n",
            "Iteration 53, loss = 86.35548214\n",
            "Iteration 54, loss = 84.70085893\n",
            "Iteration 55, loss = 83.18595777\n",
            "Iteration 56, loss = 81.76073171\n",
            "Iteration 57, loss = 80.46215706\n",
            "Iteration 58, loss = 79.19536959\n",
            "Iteration 59, loss = 78.03450036\n",
            "Iteration 60, loss = 76.92274020\n",
            "Iteration 61, loss = 75.90958540\n",
            "Iteration 62, loss = 74.95634083\n",
            "Iteration 63, loss = 74.05900696\n",
            "Iteration 64, loss = 73.23892371\n",
            "Iteration 65, loss = 72.43427672\n",
            "Iteration 66, loss = 71.71489246\n",
            "Iteration 67, loss = 71.02629363\n",
            "Iteration 68, loss = 70.40333005\n",
            "Iteration 69, loss = 69.78028633\n",
            "Iteration 70, loss = 69.22296082\n",
            "Iteration 71, loss = 68.68344640\n",
            "Iteration 72, loss = 68.18481270\n",
            "Iteration 73, loss = 67.73206227\n",
            "Iteration 74, loss = 67.30813698\n",
            "Iteration 75, loss = 66.89348726\n",
            "Iteration 76, loss = 66.51478680\n",
            "Iteration 77, loss = 66.16471854\n",
            "Iteration 78, loss = 65.83184827\n",
            "Iteration 79, loss = 65.51141771\n",
            "Iteration 80, loss = 65.21897427\n",
            "Iteration 81, loss = 64.96359473\n",
            "Iteration 82, loss = 64.70142770\n",
            "Iteration 83, loss = 64.46803474\n",
            "Iteration 84, loss = 64.23992578\n",
            "Iteration 85, loss = 64.02750968\n",
            "Iteration 86, loss = 63.83622737\n",
            "Iteration 87, loss = 63.65428187\n",
            "Iteration 88, loss = 63.48816141\n",
            "Iteration 89, loss = 63.32893290\n",
            "Iteration 90, loss = 63.17206065\n",
            "Iteration 91, loss = 63.03947437\n",
            "Iteration 92, loss = 62.90481432\n",
            "Iteration 93, loss = 62.77923074\n",
            "Iteration 94, loss = 62.67235473\n",
            "Iteration 95, loss = 62.56753601\n",
            "Iteration 96, loss = 62.46240030\n",
            "Iteration 97, loss = 62.36793826\n",
            "Iteration 98, loss = 62.28173497\n",
            "Iteration 99, loss = 62.19522121\n",
            "Iteration 100, loss = 62.12528289\n",
            "Iteration 101, loss = 62.04629992\n",
            "Iteration 102, loss = 61.97758824\n",
            "Iteration 103, loss = 61.92269135\n",
            "Iteration 104, loss = 61.86141055\n",
            "Iteration 105, loss = 61.80758940\n",
            "Iteration 106, loss = 61.75268821\n",
            "Iteration 107, loss = 61.71084224\n",
            "Iteration 108, loss = 61.66276338\n",
            "Iteration 109, loss = 61.61785442\n",
            "Iteration 110, loss = 61.57667600\n",
            "Iteration 111, loss = 61.54268417\n",
            "Iteration 112, loss = 61.50357370\n",
            "Iteration 113, loss = 61.47370547\n",
            "Iteration 114, loss = 61.44567994\n",
            "Iteration 115, loss = 61.41309706\n",
            "Iteration 116, loss = 61.38795209\n",
            "Iteration 117, loss = 61.36469248\n",
            "Iteration 118, loss = 61.33882485\n",
            "Iteration 119, loss = 61.31965686\n",
            "Iteration 120, loss = 61.29845247\n",
            "Iteration 121, loss = 61.27657322\n",
            "Iteration 122, loss = 61.26313546\n",
            "Iteration 123, loss = 61.24605206\n",
            "Iteration 124, loss = 61.22714767\n",
            "Iteration 125, loss = 61.21428480\n",
            "Iteration 126, loss = 61.20229496\n",
            "Iteration 127, loss = 61.19067850\n",
            "Iteration 128, loss = 61.17386182\n",
            "Iteration 129, loss = 61.16352459\n",
            "Iteration 130, loss = 61.15685838\n",
            "Iteration 131, loss = 61.14388670\n",
            "Iteration 132, loss = 61.13462517\n",
            "Iteration 133, loss = 61.12591606\n",
            "Iteration 134, loss = 61.11781456\n",
            "Iteration 135, loss = 61.11094983\n",
            "Iteration 136, loss = 61.10487519\n",
            "Iteration 137, loss = 61.09638523\n",
            "Iteration 138, loss = 61.09203798\n",
            "Iteration 139, loss = 61.08544794\n",
            "Iteration 140, loss = 61.08055636\n",
            "Iteration 141, loss = 61.07541029\n",
            "Iteration 142, loss = 61.07058957\n",
            "Iteration 143, loss = 61.06514844\n",
            "Iteration 144, loss = 61.06148030\n",
            "Iteration 145, loss = 61.05861745\n",
            "Iteration 146, loss = 61.05533780\n",
            "Iteration 147, loss = 61.05210569\n",
            "Iteration 148, loss = 61.04976860\n",
            "Iteration 149, loss = 61.04651018\n",
            "Iteration 150, loss = 61.04320745\n",
            "Iteration 151, loss = 61.03988442\n",
            "Iteration 152, loss = 61.03837984\n",
            "Iteration 153, loss = 61.03720939\n",
            "Iteration 154, loss = 61.03428949\n",
            "Iteration 155, loss = 61.03295385\n",
            "Iteration 156, loss = 61.03004592\n",
            "Iteration 157, loss = 61.02912584\n",
            "Iteration 158, loss = 61.02753105\n",
            "Iteration 159, loss = 61.02705584\n",
            "Iteration 160, loss = 61.02465284\n",
            "Iteration 161, loss = 61.02314990\n",
            "Iteration 162, loss = 61.02253424\n",
            "Iteration 163, loss = 61.02129193\n",
            "Iteration 164, loss = 61.02018184\n",
            "Iteration 165, loss = 61.01909596\n",
            "Iteration 166, loss = 61.01810141\n",
            "Iteration 167, loss = 61.01692666\n",
            "Iteration 168, loss = 61.01595531\n",
            "Iteration 169, loss = 61.01528338\n",
            "Iteration 170, loss = 61.01478045\n",
            "Iteration 171, loss = 61.01442803\n",
            "Iteration 172, loss = 61.01283688\n",
            "Iteration 173, loss = 61.01236602\n",
            "Iteration 174, loss = 61.01162370\n",
            "Iteration 175, loss = 61.01153547\n",
            "Iteration 176, loss = 61.01106775\n",
            "Iteration 177, loss = 61.01134641\n",
            "Iteration 178, loss = 61.01011034\n",
            "Iteration 179, loss = 61.00942207\n",
            "Iteration 180, loss = 61.00939290\n",
            "Iteration 181, loss = 61.00907079\n",
            "Iteration 182, loss = 61.00829768\n",
            "Iteration 183, loss = 61.00843815\n",
            "Iteration 184, loss = 61.00826269\n",
            "Iteration 185, loss = 61.00807676\n",
            "Iteration 186, loss = 61.00744861\n",
            "Iteration 187, loss = 61.00697787\n",
            "Iteration 188, loss = 61.00694895\n",
            "Iteration 189, loss = 61.00750344\n",
            "Iteration 190, loss = 61.00656111\n",
            "Iteration 191, loss = 61.00742015\n",
            "Iteration 192, loss = 61.00633688\n",
            "Iteration 193, loss = 61.00573972\n",
            "Iteration 194, loss = 61.00680810\n",
            "Iteration 195, loss = 61.00548533\n",
            "Iteration 196, loss = 61.00527283\n",
            "Iteration 197, loss = 61.00585223\n",
            "Iteration 198, loss = 61.00501429\n",
            "Iteration 199, loss = 61.00490468\n",
            "Iteration 200, loss = 61.00565568\n",
            "Iteration 201, loss = 61.00515661\n",
            "Iteration 202, loss = 61.00497642\n",
            "Iteration 203, loss = 61.00487430\n",
            "Iteration 204, loss = 61.00456646\n",
            "Iteration 205, loss = 61.00452576\n",
            "Iteration 206, loss = 61.00430357\n",
            "Iteration 207, loss = 61.00501200\n",
            "Iteration 208, loss = 61.00419608\n",
            "Iteration 209, loss = 61.00436645\n",
            "Iteration 210, loss = 61.00414024\n",
            "Iteration 211, loss = 61.00394895\n",
            "Iteration 212, loss = 61.00416760\n",
            "Iteration 213, loss = 61.00404035\n",
            "Iteration 214, loss = 61.00400350\n",
            "Iteration 215, loss = 61.00379809\n",
            "Iteration 216, loss = 61.00367628\n",
            "Iteration 217, loss = 61.00386169\n",
            "Iteration 218, loss = 61.00369672\n",
            "Iteration 219, loss = 61.00379840\n",
            "Iteration 220, loss = 61.00360922\n",
            "Iteration 221, loss = 61.00354328\n",
            "Iteration 222, loss = 61.00351295\n",
            "Iteration 223, loss = 61.00364971\n",
            "Iteration 224, loss = 61.00455628\n",
            "Iteration 225, loss = 61.00351065\n",
            "Iteration 226, loss = 61.00354911\n",
            "Iteration 227, loss = 61.00340745\n",
            "Iteration 228, loss = 61.00335277\n",
            "Iteration 229, loss = 61.00380534\n",
            "Iteration 230, loss = 61.00359724\n",
            "Iteration 231, loss = 61.00340990\n",
            "Iteration 232, loss = 61.00373177\n",
            "Iteration 233, loss = 61.00315888\n",
            "Iteration 234, loss = 61.00347023\n",
            "Iteration 235, loss = 61.00329296\n",
            "Iteration 236, loss = 61.00331791\n",
            "Iteration 237, loss = 61.00324223\n",
            "Iteration 238, loss = 61.00330052\n",
            "Iteration 239, loss = 61.00354195\n",
            "Iteration 240, loss = 61.00348191\n",
            "Iteration 241, loss = 61.00358102\n",
            "Iteration 242, loss = 61.00364858\n",
            "Iteration 243, loss = 61.00323814\n",
            "Iteration 244, loss = 61.00357163\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 61 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 6739.17602548\n",
            "Iteration 2, loss = 695.32414588\n",
            "Iteration 3, loss = 679.16562899\n",
            "Iteration 4, loss = 657.82738190\n",
            "Iteration 5, loss = 633.17204113\n",
            "Iteration 6, loss = 606.64606442\n",
            "Iteration 7, loss = 579.14325999\n",
            "Iteration 8, loss = 551.40712541\n",
            "Iteration 9, loss = 524.09622776\n",
            "Iteration 10, loss = 497.51384415\n",
            "Iteration 11, loss = 471.70695761\n",
            "Iteration 12, loss = 447.03663834\n",
            "Iteration 13, loss = 423.67579546\n",
            "Iteration 14, loss = 401.27792295\n",
            "Iteration 15, loss = 380.23396563\n",
            "Iteration 16, loss = 360.43958970\n",
            "Iteration 17, loss = 341.61463141\n",
            "Iteration 18, loss = 324.07968986\n",
            "Iteration 19, loss = 307.51416044\n",
            "Iteration 20, loss = 291.94635864\n",
            "Iteration 21, loss = 277.56310951\n",
            "Iteration 22, loss = 263.81605329\n",
            "Iteration 23, loss = 251.11152369\n",
            "Iteration 24, loss = 239.07485848\n",
            "Iteration 25, loss = 227.94760807\n",
            "Iteration 26, loss = 217.33760800\n",
            "Iteration 27, loss = 207.58756789\n",
            "Iteration 28, loss = 198.37757077\n",
            "Iteration 29, loss = 189.71898904\n",
            "Iteration 30, loss = 181.65660243\n",
            "Iteration 31, loss = 174.11357730\n",
            "Iteration 32, loss = 167.02261484\n",
            "Iteration 33, loss = 160.51731077\n",
            "Iteration 34, loss = 154.27204963\n",
            "Iteration 35, loss = 148.50399358\n",
            "Iteration 36, loss = 143.07946427\n",
            "Iteration 37, loss = 138.00206391\n",
            "Iteration 38, loss = 133.25067280\n",
            "Iteration 39, loss = 128.89526011\n",
            "Iteration 40, loss = 124.62128907\n",
            "Iteration 41, loss = 120.78713261\n",
            "Iteration 42, loss = 117.14341105\n",
            "Iteration 43, loss = 113.75992698\n",
            "Iteration 44, loss = 110.54262599\n",
            "Iteration 45, loss = 107.56853469\n",
            "Iteration 46, loss = 104.77832586\n",
            "Iteration 47, loss = 102.15397782\n",
            "Iteration 48, loss = 99.72053815\n",
            "Iteration 49, loss = 97.46693836\n",
            "Iteration 50, loss = 95.31886867\n",
            "Iteration 51, loss = 93.31880523\n",
            "Iteration 52, loss = 91.45326768\n",
            "Iteration 53, loss = 89.68096594\n",
            "Iteration 54, loss = 88.02712705\n",
            "Iteration 55, loss = 86.52389319\n",
            "Iteration 56, loss = 85.09319546\n",
            "Iteration 57, loss = 83.72062746\n",
            "Iteration 58, loss = 82.46585741\n",
            "Iteration 59, loss = 81.27493803\n",
            "Iteration 60, loss = 80.20483387\n",
            "Iteration 61, loss = 79.16781202\n",
            "Iteration 62, loss = 78.22006532\n",
            "Iteration 63, loss = 77.31917583\n",
            "Iteration 64, loss = 76.44828401\n",
            "Iteration 65, loss = 75.64714312\n",
            "Iteration 66, loss = 74.93284142\n",
            "Iteration 67, loss = 74.22506359\n",
            "Iteration 68, loss = 73.59824382\n",
            "Iteration 69, loss = 72.99153677\n",
            "Iteration 70, loss = 72.39273026\n",
            "Iteration 71, loss = 71.88727926\n",
            "Iteration 72, loss = 71.37367817\n",
            "Iteration 73, loss = 70.93106366\n",
            "Iteration 74, loss = 70.49688230\n",
            "Iteration 75, loss = 70.07714383\n",
            "Iteration 76, loss = 69.69446824\n",
            "Iteration 77, loss = 69.33075245\n",
            "Iteration 78, loss = 69.00590683\n",
            "Iteration 79, loss = 68.70177646\n",
            "Iteration 80, loss = 68.40015268\n",
            "Iteration 81, loss = 68.12942737\n",
            "Iteration 82, loss = 67.87153712\n",
            "Iteration 83, loss = 67.62568827\n",
            "Iteration 84, loss = 67.41314076\n",
            "Iteration 85, loss = 67.19350728\n",
            "Iteration 86, loss = 67.00266134\n",
            "Iteration 87, loss = 66.82183114\n",
            "Iteration 88, loss = 66.64112220\n",
            "Iteration 89, loss = 66.48252517\n",
            "Iteration 90, loss = 66.33993100\n",
            "Iteration 91, loss = 66.20208063\n",
            "Iteration 92, loss = 66.06160324\n",
            "Iteration 93, loss = 65.94877464\n",
            "Iteration 94, loss = 65.82432430\n",
            "Iteration 95, loss = 65.72418387\n",
            "Iteration 96, loss = 65.62111712\n",
            "Iteration 97, loss = 65.53035406\n",
            "Iteration 98, loss = 65.43890085\n",
            "Iteration 99, loss = 65.35873251\n",
            "Iteration 100, loss = 65.28299005\n",
            "Iteration 101, loss = 65.20982888\n",
            "Iteration 102, loss = 65.14314531\n",
            "Iteration 103, loss = 65.07309973\n",
            "Iteration 104, loss = 65.02218658\n",
            "Iteration 105, loss = 64.96959438\n",
            "Iteration 106, loss = 64.90935971\n",
            "Iteration 107, loss = 64.86836983\n",
            "Iteration 108, loss = 64.81959394\n",
            "Iteration 109, loss = 64.77638044\n",
            "Iteration 110, loss = 64.74230516\n",
            "Iteration 111, loss = 64.69672536\n",
            "Iteration 112, loss = 64.66245980\n",
            "Iteration 113, loss = 64.63564205\n",
            "Iteration 114, loss = 64.60117600\n",
            "Iteration 115, loss = 64.57522819\n",
            "Iteration 116, loss = 64.55114958\n",
            "Iteration 117, loss = 64.51809351\n",
            "Iteration 118, loss = 64.49933000\n",
            "Iteration 119, loss = 64.47625801\n",
            "Iteration 120, loss = 64.45424371\n",
            "Iteration 121, loss = 64.43847028\n",
            "Iteration 122, loss = 64.41753426\n",
            "Iteration 123, loss = 64.40187741\n",
            "Iteration 124, loss = 64.39036851\n",
            "Iteration 125, loss = 64.37062207\n",
            "Iteration 126, loss = 64.35804398\n",
            "Iteration 127, loss = 64.34433101\n",
            "Iteration 128, loss = 64.33451813\n",
            "Iteration 129, loss = 64.32112193\n",
            "Iteration 130, loss = 64.31085875\n",
            "Iteration 131, loss = 64.30011859\n",
            "Iteration 132, loss = 64.29158049\n",
            "Iteration 133, loss = 64.28380113\n",
            "Iteration 134, loss = 64.27520356\n",
            "Iteration 135, loss = 64.26657839\n",
            "Iteration 136, loss = 64.25809742\n",
            "Iteration 137, loss = 64.25375300\n",
            "Iteration 138, loss = 64.24637462\n",
            "Iteration 139, loss = 64.23982589\n",
            "Iteration 140, loss = 64.23609287\n",
            "Iteration 141, loss = 64.23106582\n",
            "Iteration 142, loss = 64.22453597\n",
            "Iteration 143, loss = 64.22188356\n",
            "Iteration 144, loss = 64.21508317\n",
            "Iteration 145, loss = 64.21316137\n",
            "Iteration 146, loss = 64.21013406\n",
            "Iteration 147, loss = 64.20691583\n",
            "Iteration 148, loss = 64.20196919\n",
            "Iteration 149, loss = 64.19849170\n",
            "Iteration 150, loss = 64.19689392\n",
            "Iteration 151, loss = 64.19408073\n",
            "Iteration 152, loss = 64.19152672\n",
            "Iteration 153, loss = 64.18945222\n",
            "Iteration 154, loss = 64.18742684\n",
            "Iteration 155, loss = 64.18535162\n",
            "Iteration 156, loss = 64.18310450\n",
            "Iteration 157, loss = 64.18357933\n",
            "Iteration 158, loss = 64.17986451\n",
            "Iteration 159, loss = 64.17847564\n",
            "Iteration 160, loss = 64.17729833\n",
            "Iteration 161, loss = 64.17594254\n",
            "Iteration 162, loss = 64.17506492\n",
            "Iteration 163, loss = 64.17409945\n",
            "Iteration 164, loss = 64.17219538\n",
            "Iteration 165, loss = 64.17126028\n",
            "Iteration 166, loss = 64.17192338\n",
            "Iteration 167, loss = 64.16959272\n",
            "Iteration 168, loss = 64.16935866\n",
            "Iteration 169, loss = 64.16852082\n",
            "Iteration 170, loss = 64.16727056\n",
            "Iteration 171, loss = 64.16642646\n",
            "Iteration 172, loss = 64.16676108\n",
            "Iteration 173, loss = 64.16574877\n",
            "Iteration 174, loss = 64.16529062\n",
            "Iteration 175, loss = 64.16484652\n",
            "Iteration 176, loss = 64.16387334\n",
            "Iteration 177, loss = 64.16352959\n",
            "Iteration 178, loss = 64.16296464\n",
            "Iteration 179, loss = 64.16249555\n",
            "Iteration 180, loss = 64.16294056\n",
            "Iteration 181, loss = 64.16173863\n",
            "Iteration 182, loss = 64.16195197\n",
            "Iteration 183, loss = 64.16117812\n",
            "Iteration 184, loss = 64.16141994\n",
            "Iteration 185, loss = 64.16115797\n",
            "Iteration 186, loss = 64.16081629\n",
            "Iteration 187, loss = 64.16027409\n",
            "Iteration 188, loss = 64.16095102\n",
            "Iteration 189, loss = 64.15978507\n",
            "Iteration 190, loss = 64.15971869\n",
            "Iteration 191, loss = 64.16038495\n",
            "Iteration 192, loss = 64.15992093\n",
            "Iteration 193, loss = 64.15958924\n",
            "Iteration 194, loss = 64.15902602\n",
            "Iteration 195, loss = 64.15890908\n",
            "Iteration 196, loss = 64.15901470\n",
            "Iteration 197, loss = 64.15994578\n",
            "Iteration 198, loss = 64.15869521\n",
            "Iteration 199, loss = 64.15849727\n",
            "Iteration 200, loss = 64.15833853\n",
            "Iteration 201, loss = 64.15845776\n",
            "Iteration 202, loss = 64.15814177\n",
            "Iteration 203, loss = 64.15818828\n",
            "Iteration 204, loss = 64.15804907\n",
            "Iteration 205, loss = 64.15810990\n",
            "Iteration 206, loss = 64.15773202\n",
            "Iteration 207, loss = 64.15780133\n",
            "Iteration 208, loss = 64.15954805\n",
            "Iteration 209, loss = 64.15802706\n",
            "Iteration 210, loss = 64.15751192\n",
            "Iteration 211, loss = 64.15758408\n",
            "Iteration 212, loss = 64.15759239\n",
            "Iteration 213, loss = 64.15778369\n",
            "Iteration 214, loss = 64.15797045\n",
            "Iteration 215, loss = 64.15760004\n",
            "Iteration 216, loss = 64.15729173\n",
            "Iteration 217, loss = 64.15737574\n",
            "Iteration 218, loss = 64.15797143\n",
            "Iteration 219, loss = 64.15708220\n",
            "Iteration 220, loss = 64.15721928\n",
            "Iteration 221, loss = 64.15758796\n",
            "Iteration 222, loss = 64.15724328\n",
            "Iteration 223, loss = 64.15701209\n",
            "Iteration 224, loss = 64.15753785\n",
            "Iteration 225, loss = 64.15746597\n",
            "Iteration 226, loss = 64.15699498\n",
            "Iteration 227, loss = 64.15737956\n",
            "Iteration 228, loss = 64.15747726\n",
            "Iteration 229, loss = 64.15707792\n",
            "Iteration 230, loss = 64.15733476\n",
            "Iteration 231, loss = 64.15696638\n",
            "Iteration 232, loss = 64.15739789\n",
            "Iteration 233, loss = 64.15707858\n",
            "Iteration 234, loss = 64.15676394\n",
            "Iteration 235, loss = 64.15695718\n",
            "Iteration 236, loss = 64.15699068\n",
            "Iteration 237, loss = 64.15712486\n",
            "Iteration 238, loss = 64.15741564\n",
            "Iteration 239, loss = 64.15680741\n",
            "Iteration 240, loss = 64.15764100\n",
            "Iteration 241, loss = 64.15711260\n",
            "Iteration 242, loss = 64.15699409\n",
            "Iteration 243, loss = 64.15716973\n",
            "Iteration 244, loss = 64.15729333\n",
            "Iteration 245, loss = 64.15719568\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 62 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 5222720.74360619\n",
            "Iteration 2, loss = 30078.12861389\n",
            "Iteration 3, loss = 66915.14239040\n",
            "Iteration 4, loss = 103433.41334056\n",
            "Iteration 5, loss = 135164.79527529\n",
            "Iteration 6, loss = 160989.02657430\n",
            "Iteration 7, loss = 181220.36156741\n",
            "Iteration 8, loss = 196693.38954241\n",
            "Iteration 9, loss = 208336.54391499\n",
            "Iteration 10, loss = 216997.21562456\n",
            "Iteration 11, loss = 223383.86542890\n",
            "Iteration 12, loss = 228060.84051822\n",
            "Iteration 13, loss = 231464.81239552\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 63 ------ \n",
            "-----> Match Score: 0 <------\n",
            "Iteration 1, loss = 718.81248665\n",
            "Iteration 2, loss = 683.50083301\n",
            "Iteration 3, loss = 572.77592372\n",
            "Iteration 4, loss = 262.62197186\n",
            "Iteration 5, loss = 102.08580373\n",
            "Iteration 6, loss = 129.33948389\n",
            "Iteration 7, loss = 65.61315493\n",
            "Iteration 8, loss = 69.99966170\n",
            "Iteration 9, loss = 63.27940484\n",
            "Iteration 10, loss = 61.38946090\n",
            "Iteration 11, loss = 61.95922013\n",
            "Iteration 12, loss = 61.08691629\n",
            "Iteration 13, loss = 61.10192743\n",
            "Iteration 14, loss = 61.06352276\n",
            "Iteration 15, loss = 61.01789445\n",
            "Iteration 16, loss = 61.06379313\n",
            "Iteration 17, loss = 61.03073720\n",
            "Iteration 18, loss = 60.99808832\n",
            "Iteration 19, loss = 61.02868854\n",
            "Iteration 20, loss = 61.02600350\n",
            "Iteration 21, loss = 61.00555081\n",
            "Iteration 22, loss = 61.09525527\n",
            "Iteration 23, loss = 61.00792124\n",
            "Iteration 24, loss = 61.01572427\n",
            "Iteration 25, loss = 61.03494020\n",
            "Iteration 26, loss = 61.09286701\n",
            "Iteration 27, loss = 60.99568361\n",
            "Iteration 28, loss = 61.00840300\n",
            "Iteration 29, loss = 61.06012476\n",
            "Iteration 30, loss = 61.02354042\n",
            "Iteration 31, loss = 61.05574213\n",
            "Iteration 32, loss = 61.09097899\n",
            "Iteration 33, loss = 61.02381365\n",
            "Iteration 34, loss = 61.01521354\n",
            "Iteration 35, loss = 61.05011442\n",
            "Iteration 36, loss = 60.99883180\n",
            "Iteration 37, loss = 61.15327432\n",
            "Iteration 38, loss = 61.02908952\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 64 ------ \n",
            "[12, 23, 35, 47, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 23, 35, 47, 58, 13] [ 8 23 37 52 63 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 2 23 40 59 69 13] [23] [13] 7.0\n",
            "[12, 23, 35, 47, 58, 13] [ 1  7 45 47 69 13] [47] [13] 7.0\n",
            "-----> Match Score: 40.0 <------\n",
            "Iteration 1, loss = 790.70557012\n",
            "Iteration 2, loss = 693.60523154\n",
            "Iteration 3, loss = 665.73055576\n",
            "Iteration 4, loss = 601.88262011\n",
            "Iteration 5, loss = 411.90996336\n",
            "Iteration 6, loss = 111.50558233\n",
            "Iteration 7, loss = 142.49380024\n",
            "Iteration 8, loss = 82.39232541\n",
            "Iteration 9, loss = 67.00010528\n",
            "Iteration 10, loss = 68.47572672\n",
            "Iteration 11, loss = 61.72620041\n",
            "Iteration 12, loss = 62.25865372\n",
            "Iteration 13, loss = 61.46528364\n",
            "Iteration 14, loss = 61.11899060\n",
            "Iteration 15, loss = 61.21708035\n",
            "Iteration 16, loss = 60.99410005\n",
            "Iteration 17, loss = 60.99557899\n",
            "Iteration 18, loss = 61.05211469\n",
            "Iteration 19, loss = 61.03956417\n",
            "Iteration 20, loss = 61.01339429\n",
            "Iteration 21, loss = 61.01629217\n",
            "Iteration 22, loss = 61.00152400\n",
            "Iteration 23, loss = 60.99971417\n",
            "Iteration 24, loss = 61.01165783\n",
            "Iteration 25, loss = 61.06095773\n",
            "Iteration 26, loss = 61.03435489\n",
            "Iteration 27, loss = 60.99276721\n",
            "Iteration 28, loss = 61.11384850\n",
            "Iteration 29, loss = 61.12169846\n",
            "Iteration 30, loss = 61.04430241\n",
            "Iteration 31, loss = 61.00988477\n",
            "Iteration 32, loss = 61.03835191\n",
            "Iteration 33, loss = 61.00530291\n",
            "Iteration 34, loss = 60.99320623\n",
            "Iteration 35, loss = 61.03142229\n",
            "Iteration 36, loss = 60.99652317\n",
            "Iteration 37, loss = 61.00396700\n",
            "Iteration 38, loss = 61.19879115\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 65 ------ \n",
            "[12, 24, 35, 47, 59, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 35, 47, 59, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 996.38355698\n",
            "Iteration 2, loss = 688.49426772\n",
            "Iteration 3, loss = 668.94156990\n",
            "Iteration 4, loss = 645.22276501\n",
            "Iteration 5, loss = 618.94788536\n",
            "Iteration 6, loss = 591.32298531\n",
            "Iteration 7, loss = 563.34221349\n",
            "Iteration 8, loss = 535.39973058\n",
            "Iteration 9, loss = 508.19461444\n",
            "Iteration 10, loss = 481.87405876\n",
            "Iteration 11, loss = 456.52898157\n",
            "Iteration 12, loss = 432.33928182\n",
            "Iteration 13, loss = 409.52955726\n",
            "Iteration 14, loss = 387.67728639\n",
            "Iteration 15, loss = 367.10414210\n",
            "Iteration 16, loss = 347.87358465\n",
            "Iteration 17, loss = 329.63437569\n",
            "Iteration 18, loss = 312.68504957\n",
            "Iteration 19, loss = 296.58782329\n",
            "Iteration 20, loss = 281.54999126\n",
            "Iteration 21, loss = 267.47673605\n",
            "Iteration 22, loss = 254.23040317\n",
            "Iteration 23, loss = 241.85190987\n",
            "Iteration 24, loss = 230.25264957\n",
            "Iteration 25, loss = 219.46199576\n",
            "Iteration 26, loss = 209.27810851\n",
            "Iteration 27, loss = 199.67548045\n",
            "Iteration 28, loss = 190.91875895\n",
            "Iteration 29, loss = 182.51145832\n",
            "Iteration 30, loss = 174.70254367\n",
            "Iteration 31, loss = 167.41060985\n",
            "Iteration 32, loss = 160.57333396\n",
            "Iteration 33, loss = 154.21218073\n",
            "Iteration 34, loss = 148.24883821\n",
            "Iteration 35, loss = 142.62079706\n",
            "Iteration 36, loss = 137.39652772\n",
            "Iteration 37, loss = 132.46709653\n",
            "Iteration 38, loss = 127.88146134\n",
            "Iteration 39, loss = 123.57825263\n",
            "Iteration 40, loss = 119.58511012\n",
            "Iteration 41, loss = 115.84218569\n",
            "Iteration 42, loss = 112.31998664\n",
            "Iteration 43, loss = 109.00245445\n",
            "Iteration 44, loss = 105.89330018\n",
            "Iteration 45, loss = 103.02177933\n",
            "Iteration 46, loss = 100.31938237\n",
            "Iteration 47, loss = 97.82621463\n",
            "Iteration 48, loss = 95.44168977\n",
            "Iteration 49, loss = 93.21717255\n",
            "Iteration 50, loss = 91.14562685\n",
            "Iteration 51, loss = 89.22039328\n",
            "Iteration 52, loss = 87.39462722\n",
            "Iteration 53, loss = 85.69630716\n",
            "Iteration 54, loss = 84.11814191\n",
            "Iteration 55, loss = 82.62645053\n",
            "Iteration 56, loss = 81.25116603\n",
            "Iteration 57, loss = 79.94042076\n",
            "Iteration 58, loss = 78.72944640\n",
            "Iteration 59, loss = 77.56902240\n",
            "Iteration 60, loss = 76.52526473\n",
            "Iteration 61, loss = 75.50707523\n",
            "Iteration 62, loss = 74.59212143\n",
            "Iteration 63, loss = 73.69540120\n",
            "Iteration 64, loss = 72.89169332\n",
            "Iteration 65, loss = 72.12798531\n",
            "Iteration 66, loss = 71.43648013\n",
            "Iteration 67, loss = 70.74190337\n",
            "Iteration 68, loss = 70.09427520\n",
            "Iteration 69, loss = 69.55993872\n",
            "Iteration 70, loss = 68.98462153\n",
            "Iteration 71, loss = 68.46226918\n",
            "Iteration 72, loss = 67.98450254\n",
            "Iteration 73, loss = 67.53206429\n",
            "Iteration 74, loss = 67.10373327\n",
            "Iteration 75, loss = 66.72296329\n",
            "Iteration 76, loss = 66.35629228\n",
            "Iteration 77, loss = 65.99736528\n",
            "Iteration 78, loss = 65.68957240\n",
            "Iteration 79, loss = 65.38343531\n",
            "Iteration 80, loss = 65.10220155\n",
            "Iteration 81, loss = 64.82678404\n",
            "Iteration 82, loss = 64.59387772\n",
            "Iteration 83, loss = 64.34810443\n",
            "Iteration 84, loss = 64.13824663\n",
            "Iteration 85, loss = 63.94238781\n",
            "Iteration 86, loss = 63.74240545\n",
            "Iteration 87, loss = 63.58465814\n",
            "Iteration 88, loss = 63.41382912\n",
            "Iteration 89, loss = 63.24409846\n",
            "Iteration 90, loss = 63.10052835\n",
            "Iteration 91, loss = 62.97218311\n",
            "Iteration 92, loss = 62.84231000\n",
            "Iteration 93, loss = 62.73346157\n",
            "Iteration 94, loss = 62.61781201\n",
            "Iteration 95, loss = 62.51294370\n",
            "Iteration 96, loss = 62.40717807\n",
            "Iteration 97, loss = 62.32142926\n",
            "Iteration 98, loss = 62.23852314\n",
            "Iteration 99, loss = 62.15258407\n",
            "Iteration 100, loss = 62.08319727\n",
            "Iteration 101, loss = 62.02290054\n",
            "Iteration 102, loss = 61.94170393\n",
            "Iteration 103, loss = 61.88533387\n",
            "Iteration 104, loss = 61.83028384\n",
            "Iteration 105, loss = 61.77008337\n",
            "Iteration 106, loss = 61.72392397\n",
            "Iteration 107, loss = 61.67348828\n",
            "Iteration 108, loss = 61.63375664\n",
            "Iteration 109, loss = 61.59290981\n",
            "Iteration 110, loss = 61.54960569\n",
            "Iteration 111, loss = 61.51504618\n",
            "Iteration 112, loss = 61.48354471\n",
            "Iteration 113, loss = 61.44872507\n",
            "Iteration 114, loss = 61.42051485\n",
            "Iteration 115, loss = 61.39047399\n",
            "Iteration 116, loss = 61.36646971\n",
            "Iteration 117, loss = 61.34314698\n",
            "Iteration 118, loss = 61.31749840\n",
            "Iteration 119, loss = 61.29682424\n",
            "Iteration 120, loss = 61.27481982\n",
            "Iteration 121, loss = 61.25876296\n",
            "Iteration 122, loss = 61.24259141\n",
            "Iteration 123, loss = 61.22617837\n",
            "Iteration 124, loss = 61.20850045\n",
            "Iteration 125, loss = 61.19712234\n",
            "Iteration 126, loss = 61.18004692\n",
            "Iteration 127, loss = 61.16877235\n",
            "Iteration 128, loss = 61.15565168\n",
            "Iteration 129, loss = 61.14771351\n",
            "Iteration 130, loss = 61.13727898\n",
            "Iteration 131, loss = 61.12556340\n",
            "Iteration 132, loss = 61.11611775\n",
            "Iteration 133, loss = 61.10813366\n",
            "Iteration 134, loss = 61.10298511\n",
            "Iteration 135, loss = 61.09145061\n",
            "Iteration 136, loss = 61.08713588\n",
            "Iteration 137, loss = 61.07890243\n",
            "Iteration 138, loss = 61.07344425\n",
            "Iteration 139, loss = 61.06862139\n",
            "Iteration 140, loss = 61.06437747\n",
            "Iteration 141, loss = 61.05659261\n",
            "Iteration 142, loss = 61.05383372\n",
            "Iteration 143, loss = 61.04794788\n",
            "Iteration 144, loss = 61.04351002\n",
            "Iteration 145, loss = 61.04082909\n",
            "Iteration 146, loss = 61.03828240\n",
            "Iteration 147, loss = 61.03436585\n",
            "Iteration 148, loss = 61.03178346\n",
            "Iteration 149, loss = 61.02811588\n",
            "Iteration 150, loss = 61.02557137\n",
            "Iteration 151, loss = 61.02269565\n",
            "Iteration 152, loss = 61.01999736\n",
            "Iteration 153, loss = 61.02029877\n",
            "Iteration 154, loss = 61.01613398\n",
            "Iteration 155, loss = 61.01392525\n",
            "Iteration 156, loss = 61.01208774\n",
            "Iteration 157, loss = 61.01157427\n",
            "Iteration 158, loss = 61.01066198\n",
            "Iteration 159, loss = 61.00686088\n",
            "Iteration 160, loss = 61.00740700\n",
            "Iteration 161, loss = 61.00392811\n",
            "Iteration 162, loss = 61.00316714\n",
            "Iteration 163, loss = 61.00154454\n",
            "Iteration 164, loss = 61.00027774\n",
            "Iteration 165, loss = 60.99971353\n",
            "Iteration 166, loss = 60.99841553\n",
            "Iteration 167, loss = 60.99826433\n",
            "Iteration 168, loss = 60.99705680\n",
            "Iteration 169, loss = 60.99563804\n",
            "Iteration 170, loss = 60.99480148\n",
            "Iteration 171, loss = 60.99440492\n",
            "Iteration 172, loss = 60.99311196\n",
            "Iteration 173, loss = 60.99408951\n",
            "Iteration 174, loss = 60.99248996\n",
            "Iteration 175, loss = 60.99142011\n",
            "Iteration 176, loss = 60.99111043\n",
            "Iteration 177, loss = 60.99068483\n",
            "Iteration 178, loss = 60.99013686\n",
            "Iteration 179, loss = 60.98987658\n",
            "Iteration 180, loss = 60.98958897\n",
            "Iteration 181, loss = 60.98870152\n",
            "Iteration 182, loss = 60.98896243\n",
            "Iteration 183, loss = 60.98884263\n",
            "Iteration 184, loss = 60.98849177\n",
            "Iteration 185, loss = 60.98775892\n",
            "Iteration 186, loss = 60.98733160\n",
            "Iteration 187, loss = 60.98696124\n",
            "Iteration 188, loss = 60.98691858\n",
            "Iteration 189, loss = 60.98661311\n",
            "Iteration 190, loss = 60.98643367\n",
            "Iteration 191, loss = 60.98641959\n",
            "Iteration 192, loss = 60.98639488\n",
            "Iteration 193, loss = 60.98607048\n",
            "Iteration 194, loss = 60.98551949\n",
            "Iteration 195, loss = 60.98582048\n",
            "Iteration 196, loss = 60.98577358\n",
            "Iteration 197, loss = 60.98581686\n",
            "Iteration 198, loss = 60.98517546\n",
            "Iteration 199, loss = 60.98532162\n",
            "Iteration 200, loss = 60.98457015\n",
            "Iteration 201, loss = 60.98458557\n",
            "Iteration 202, loss = 60.98499015\n",
            "Iteration 203, loss = 60.98424302\n",
            "Iteration 204, loss = 60.98456624\n",
            "Iteration 205, loss = 60.98459877\n",
            "Iteration 206, loss = 60.98402311\n",
            "Iteration 207, loss = 60.98464507\n",
            "Iteration 208, loss = 60.98403280\n",
            "Iteration 209, loss = 60.98394501\n",
            "Iteration 210, loss = 60.98397407\n",
            "Iteration 211, loss = 60.98396222\n",
            "Iteration 212, loss = 60.98399078\n",
            "Iteration 213, loss = 60.98367562\n",
            "Iteration 214, loss = 60.98420265\n",
            "Iteration 215, loss = 60.98386031\n",
            "Iteration 216, loss = 60.98442154\n",
            "Iteration 217, loss = 60.98388204\n",
            "Iteration 218, loss = 60.98392097\n",
            "Iteration 219, loss = 60.98350873\n",
            "Iteration 220, loss = 60.98363136\n",
            "Iteration 221, loss = 60.98365354\n",
            "Iteration 222, loss = 60.98371654\n",
            "Iteration 223, loss = 60.98343196\n",
            "Iteration 224, loss = 60.98342008\n",
            "Iteration 225, loss = 60.98338938\n",
            "Iteration 226, loss = 60.98348276\n",
            "Iteration 227, loss = 60.98344481\n",
            "Iteration 228, loss = 60.98335980\n",
            "Iteration 229, loss = 60.98317065\n",
            "Iteration 230, loss = 60.98343930\n",
            "Iteration 231, loss = 60.98360639\n",
            "Iteration 232, loss = 60.98348536\n",
            "Iteration 233, loss = 60.98329498\n",
            "Iteration 234, loss = 60.98313702\n",
            "Iteration 235, loss = 60.98292678\n",
            "Iteration 236, loss = 60.98363945\n",
            "Iteration 237, loss = 60.98317204\n",
            "Iteration 238, loss = 60.98305504\n",
            "Iteration 239, loss = 60.98304091\n",
            "Iteration 240, loss = 60.98316744\n",
            "Iteration 241, loss = 60.98301895\n",
            "Iteration 242, loss = 60.98383280\n",
            "Iteration 243, loss = 60.98302366\n",
            "Iteration 244, loss = 60.98286612\n",
            "Iteration 245, loss = 60.98355262\n",
            "Iteration 246, loss = 60.98305776\n",
            "Iteration 247, loss = 60.98294446\n",
            "Iteration 248, loss = 60.98373997\n",
            "Iteration 249, loss = 60.98347232\n",
            "Iteration 250, loss = 60.98382859\n",
            "Iteration 251, loss = 60.98345175\n",
            "Iteration 252, loss = 60.98290087\n",
            "Iteration 253, loss = 60.98293601\n",
            "Iteration 254, loss = 60.98289346\n",
            "Iteration 255, loss = 60.98350393\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 66 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 2035.47665976\n",
            "Iteration 2, loss = 724.91592343\n",
            "Iteration 3, loss = 704.28147896\n",
            "Iteration 4, loss = 653.48492984\n",
            "Iteration 5, loss = 487.01584171\n",
            "Iteration 6, loss = 148.71896492\n",
            "Iteration 7, loss = 137.22467983\n",
            "Iteration 8, loss = 95.40599754\n",
            "Iteration 9, loss = 66.40929872\n",
            "Iteration 10, loss = 70.25074267\n",
            "Iteration 11, loss = 62.20868167\n",
            "Iteration 12, loss = 62.59973549\n",
            "Iteration 13, loss = 62.01563425\n",
            "Iteration 14, loss = 61.47458242\n",
            "Iteration 15, loss = 61.49726451\n",
            "Iteration 16, loss = 61.34503973\n",
            "Iteration 17, loss = 61.36902195\n",
            "Iteration 18, loss = 61.34878890\n",
            "Iteration 19, loss = 61.36936047\n",
            "Iteration 20, loss = 61.33264991\n",
            "Iteration 21, loss = 61.33000025\n",
            "Iteration 22, loss = 61.44604723\n",
            "Iteration 23, loss = 61.32328065\n",
            "Iteration 24, loss = 61.34554830\n",
            "Iteration 25, loss = 61.33636981\n",
            "Iteration 26, loss = 61.34847585\n",
            "Iteration 27, loss = 61.40654110\n",
            "Iteration 28, loss = 61.33742220\n",
            "Iteration 29, loss = 61.36581098\n",
            "Iteration 30, loss = 61.34903207\n",
            "Iteration 31, loss = 61.44080317\n",
            "Iteration 32, loss = 61.38139990\n",
            "Iteration 33, loss = 61.32811064\n",
            "Iteration 34, loss = 61.38673446\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 67 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 8881.82532040\n",
            "Iteration 2, loss = 704.22995608\n",
            "Iteration 3, loss = 697.35517286\n",
            "Iteration 4, loss = 685.53474280\n",
            "Iteration 5, loss = 669.04168262\n",
            "Iteration 6, loss = 649.33804405\n",
            "Iteration 7, loss = 627.08288879\n",
            "Iteration 8, loss = 603.53284061\n",
            "Iteration 9, loss = 579.31022068\n",
            "Iteration 10, loss = 554.89289024\n",
            "Iteration 11, loss = 530.83667618\n",
            "Iteration 12, loss = 507.52164810\n",
            "Iteration 13, loss = 485.04160772\n",
            "Iteration 14, loss = 463.54198570\n",
            "Iteration 15, loss = 442.86102022\n",
            "Iteration 16, loss = 423.36811556\n",
            "Iteration 17, loss = 405.02900672\n",
            "Iteration 18, loss = 387.60754181\n",
            "Iteration 19, loss = 371.24570210\n",
            "Iteration 20, loss = 355.79606104\n",
            "Iteration 21, loss = 341.38836424\n",
            "Iteration 22, loss = 327.82533672\n",
            "Iteration 23, loss = 315.10336831\n",
            "Iteration 24, loss = 302.99192035\n",
            "Iteration 25, loss = 291.97229079\n",
            "Iteration 26, loss = 281.48224165\n",
            "Iteration 27, loss = 271.71008875\n",
            "Iteration 28, loss = 262.50204016\n",
            "Iteration 29, loss = 253.87952653\n",
            "Iteration 30, loss = 245.83540227\n",
            "Iteration 31, loss = 238.28222109\n",
            "Iteration 32, loss = 231.29180808\n",
            "Iteration 33, loss = 224.63932465\n",
            "Iteration 34, loss = 218.46868212\n",
            "Iteration 35, loss = 212.68093744\n",
            "Iteration 36, loss = 207.24666047\n",
            "Iteration 37, loss = 202.20463232\n",
            "Iteration 38, loss = 197.48001691\n",
            "Iteration 39, loss = 193.00824847\n",
            "Iteration 40, loss = 188.90500378\n",
            "Iteration 41, loss = 185.01005708\n",
            "Iteration 42, loss = 181.37868231\n",
            "Iteration 43, loss = 177.98529670\n",
            "Iteration 44, loss = 174.74655951\n",
            "Iteration 45, loss = 171.78784556\n",
            "Iteration 46, loss = 169.05910879\n",
            "Iteration 47, loss = 166.41618018\n",
            "Iteration 48, loss = 163.94248456\n",
            "Iteration 49, loss = 161.66584596\n",
            "Iteration 50, loss = 159.54988070\n",
            "Iteration 51, loss = 157.56091267\n",
            "Iteration 52, loss = 155.68651249\n",
            "Iteration 53, loss = 153.92438281\n",
            "Iteration 54, loss = 152.31167937\n",
            "Iteration 55, loss = 150.73088465\n",
            "Iteration 56, loss = 149.32372053\n",
            "Iteration 57, loss = 147.97489408\n",
            "Iteration 58, loss = 146.76912556\n",
            "Iteration 59, loss = 145.58537158\n",
            "Iteration 60, loss = 144.46281544\n",
            "Iteration 61, loss = 143.41947027\n",
            "Iteration 62, loss = 142.48486870\n",
            "Iteration 63, loss = 141.59006689\n",
            "Iteration 64, loss = 140.75036134\n",
            "Iteration 65, loss = 139.94362732\n",
            "Iteration 66, loss = 139.21026900\n",
            "Iteration 67, loss = 138.52522378\n",
            "Iteration 68, loss = 137.86222391\n",
            "Iteration 69, loss = 137.26235395\n",
            "Iteration 70, loss = 136.69774292\n",
            "Iteration 71, loss = 136.16430067\n",
            "Iteration 72, loss = 135.66734075\n",
            "Iteration 73, loss = 135.20379366\n",
            "Iteration 74, loss = 134.76051650\n",
            "Iteration 75, loss = 134.34985092\n",
            "Iteration 76, loss = 133.99116490\n",
            "Iteration 77, loss = 133.61147841\n",
            "Iteration 78, loss = 133.29316178\n",
            "Iteration 79, loss = 132.97275278\n",
            "Iteration 80, loss = 132.67856993\n",
            "Iteration 81, loss = 132.40168886\n",
            "Iteration 82, loss = 132.14524593\n",
            "Iteration 83, loss = 131.90643675\n",
            "Iteration 84, loss = 131.68204887\n",
            "Iteration 85, loss = 131.48014389\n",
            "Iteration 86, loss = 131.26225461\n",
            "Iteration 87, loss = 131.09792118\n",
            "Iteration 88, loss = 130.91873862\n",
            "Iteration 89, loss = 130.75741840\n",
            "Iteration 90, loss = 130.61313252\n",
            "Iteration 91, loss = 130.46321325\n",
            "Iteration 92, loss = 130.33649566\n",
            "Iteration 93, loss = 130.21666175\n",
            "Iteration 94, loss = 130.09506734\n",
            "Iteration 95, loss = 129.99657226\n",
            "Iteration 96, loss = 129.88133194\n",
            "Iteration 97, loss = 129.79521879\n",
            "Iteration 98, loss = 129.70526418\n",
            "Iteration 99, loss = 129.62353457\n",
            "Iteration 100, loss = 129.54854720\n",
            "Iteration 101, loss = 129.47632940\n",
            "Iteration 102, loss = 129.40457531\n",
            "Iteration 103, loss = 129.34549419\n",
            "Iteration 104, loss = 129.28103450\n",
            "Iteration 105, loss = 129.23308832\n",
            "Iteration 106, loss = 129.17483852\n",
            "Iteration 107, loss = 129.13903937\n",
            "Iteration 108, loss = 129.08361590\n",
            "Iteration 109, loss = 129.03996738\n",
            "Iteration 110, loss = 129.00000716\n",
            "Iteration 111, loss = 128.96444461\n",
            "Iteration 112, loss = 128.93078940\n",
            "Iteration 113, loss = 128.89433698\n",
            "Iteration 114, loss = 128.86439927\n",
            "Iteration 115, loss = 128.83814515\n",
            "Iteration 116, loss = 128.80672796\n",
            "Iteration 117, loss = 128.79070020\n",
            "Iteration 118, loss = 128.75778161\n",
            "Iteration 119, loss = 128.73991903\n",
            "Iteration 120, loss = 128.71755125\n",
            "Iteration 121, loss = 128.69985657\n",
            "Iteration 122, loss = 128.67847966\n",
            "Iteration 123, loss = 128.66490664\n",
            "Iteration 124, loss = 128.64738127\n",
            "Iteration 125, loss = 128.63373170\n",
            "Iteration 126, loss = 128.61791358\n",
            "Iteration 127, loss = 128.60459030\n",
            "Iteration 128, loss = 128.59165701\n",
            "Iteration 129, loss = 128.57937153\n",
            "Iteration 130, loss = 128.56996885\n",
            "Iteration 131, loss = 128.56004029\n",
            "Iteration 132, loss = 128.55209521\n",
            "Iteration 133, loss = 128.54101793\n",
            "Iteration 134, loss = 128.53418127\n",
            "Iteration 135, loss = 128.52616546\n",
            "Iteration 136, loss = 128.52179100\n",
            "Iteration 137, loss = 128.51137874\n",
            "Iteration 138, loss = 128.50405325\n",
            "Iteration 139, loss = 128.49920480\n",
            "Iteration 140, loss = 128.49473362\n",
            "Iteration 141, loss = 128.48998246\n",
            "Iteration 142, loss = 128.48612809\n",
            "Iteration 143, loss = 128.47992345\n",
            "Iteration 144, loss = 128.47559850\n",
            "Iteration 145, loss = 128.47212048\n",
            "Iteration 146, loss = 128.46840031\n",
            "Iteration 147, loss = 128.46474330\n",
            "Iteration 148, loss = 128.46235116\n",
            "Iteration 149, loss = 128.45899428\n",
            "Iteration 150, loss = 128.45596170\n",
            "Iteration 151, loss = 128.45365729\n",
            "Iteration 152, loss = 128.45087063\n",
            "Iteration 153, loss = 128.44872492\n",
            "Iteration 154, loss = 128.44756352\n",
            "Iteration 155, loss = 128.44520285\n",
            "Iteration 156, loss = 128.44287443\n",
            "Iteration 157, loss = 128.44113052\n",
            "Iteration 158, loss = 128.43910617\n",
            "Iteration 159, loss = 128.43788557\n",
            "Iteration 160, loss = 128.43727821\n",
            "Iteration 161, loss = 128.43550527\n",
            "Iteration 162, loss = 128.43363847\n",
            "Iteration 163, loss = 128.43256422\n",
            "Iteration 164, loss = 128.43162506\n",
            "Iteration 165, loss = 128.43060422\n",
            "Iteration 166, loss = 128.42999318\n",
            "Iteration 167, loss = 128.42964643\n",
            "Iteration 168, loss = 128.42821869\n",
            "Iteration 169, loss = 128.42757383\n",
            "Iteration 170, loss = 128.42740186\n",
            "Iteration 171, loss = 128.42591421\n",
            "Iteration 172, loss = 128.42698902\n",
            "Iteration 173, loss = 128.42484996\n",
            "Iteration 174, loss = 128.42459862\n",
            "Iteration 175, loss = 128.42526444\n",
            "Iteration 176, loss = 128.42356666\n",
            "Iteration 177, loss = 128.42359906\n",
            "Iteration 178, loss = 128.42294082\n",
            "Iteration 179, loss = 128.42260472\n",
            "Iteration 180, loss = 128.42239708\n",
            "Iteration 181, loss = 128.42214659\n",
            "Iteration 182, loss = 128.42230586\n",
            "Iteration 183, loss = 128.42168039\n",
            "Iteration 184, loss = 128.42118885\n",
            "Iteration 185, loss = 128.42098305\n",
            "Iteration 186, loss = 128.42085268\n",
            "Iteration 187, loss = 128.42046172\n",
            "Iteration 188, loss = 128.42049047\n",
            "Iteration 189, loss = 128.42047445\n",
            "Iteration 190, loss = 128.42004303\n",
            "Iteration 191, loss = 128.41968730\n",
            "Iteration 192, loss = 128.41970340\n",
            "Iteration 193, loss = 128.41949931\n",
            "Iteration 194, loss = 128.41932446\n",
            "Iteration 195, loss = 128.42031599\n",
            "Iteration 196, loss = 128.41929062\n",
            "Iteration 197, loss = 128.41906105\n",
            "Iteration 198, loss = 128.41911571\n",
            "Iteration 199, loss = 128.41882017\n",
            "Iteration 200, loss = 128.41892021\n",
            "Iteration 201, loss = 128.41863654\n",
            "Iteration 202, loss = 128.41870759\n",
            "Iteration 203, loss = 128.41858279\n",
            "Iteration 204, loss = 128.41835015\n",
            "Iteration 205, loss = 128.41939497\n",
            "Iteration 206, loss = 128.41823114\n",
            "Iteration 207, loss = 128.41875234\n",
            "Iteration 208, loss = 128.41823623\n",
            "Iteration 209, loss = 128.41801591\n",
            "Iteration 210, loss = 128.41792691\n",
            "Iteration 211, loss = 128.41803334\n",
            "Iteration 212, loss = 128.41853851\n",
            "Iteration 213, loss = 128.41766064\n",
            "Iteration 214, loss = 128.41775622\n",
            "Iteration 215, loss = 128.41777632\n",
            "Iteration 216, loss = 128.41810190\n",
            "Iteration 217, loss = 128.41772279\n",
            "Iteration 218, loss = 128.41778510\n",
            "Iteration 219, loss = 128.41790676\n",
            "Iteration 220, loss = 128.41751882\n",
            "Iteration 221, loss = 128.41738719\n",
            "Iteration 222, loss = 128.41740744\n",
            "Iteration 223, loss = 128.41742778\n",
            "Iteration 224, loss = 128.41727830\n",
            "Iteration 225, loss = 128.41728206\n",
            "Iteration 226, loss = 128.41756896\n",
            "Iteration 227, loss = 128.41719511\n",
            "Iteration 228, loss = 128.41790444\n",
            "Iteration 229, loss = 128.41745019\n",
            "Iteration 230, loss = 128.41786484\n",
            "Iteration 231, loss = 128.41753017\n",
            "Iteration 232, loss = 128.41732771\n",
            "Iteration 233, loss = 128.41754472\n",
            "Iteration 234, loss = 128.41729430\n",
            "Iteration 235, loss = 128.41716476\n",
            "Iteration 236, loss = 128.41752501\n",
            "Iteration 237, loss = 128.41743066\n",
            "Iteration 238, loss = 128.41786566\n",
            "Iteration 239, loss = 128.41747155\n",
            "Iteration 240, loss = 128.41740751\n",
            "Iteration 241, loss = 128.41706980\n",
            "Iteration 242, loss = 128.41747884\n",
            "Iteration 243, loss = 128.41731459\n",
            "Iteration 244, loss = 128.41729878\n",
            "Iteration 245, loss = 128.41749779\n",
            "Iteration 246, loss = 128.41725024\n",
            "Iteration 247, loss = 128.41719567\n",
            "Iteration 248, loss = 128.41704628\n",
            "Iteration 249, loss = 128.41699102\n",
            "Iteration 250, loss = 128.41707153\n",
            "Iteration 251, loss = 128.41697652\n",
            "Iteration 252, loss = 128.41732608\n",
            "Iteration 253, loss = 128.41700078\n",
            "Iteration 254, loss = 128.41768085\n",
            "Iteration 255, loss = 128.41704479\n",
            "Iteration 256, loss = 128.41746749\n",
            "Iteration 257, loss = 128.41726443\n",
            "Iteration 258, loss = 128.41709425\n",
            "Iteration 259, loss = 128.41742243\n",
            "Iteration 260, loss = 128.41729319\n",
            "Iteration 261, loss = 128.41688666\n",
            "Iteration 262, loss = 128.41775027\n",
            "Iteration 263, loss = 128.41709371\n",
            "Iteration 264, loss = 128.41712717\n",
            "Iteration 265, loss = 128.41725267\n",
            "Iteration 266, loss = 128.41694818\n",
            "Iteration 267, loss = 128.41693589\n",
            "Iteration 268, loss = 128.41720829\n",
            "Iteration 269, loss = 128.41681352\n",
            "Iteration 270, loss = 128.41689486\n",
            "Iteration 271, loss = 128.41734107\n",
            "Iteration 272, loss = 128.41697491\n",
            "Iteration 273, loss = 128.41721646\n",
            "Iteration 274, loss = 128.41697844\n",
            "Iteration 275, loss = 128.41728844\n",
            "Iteration 276, loss = 128.41684113\n",
            "Iteration 277, loss = 128.41685426\n",
            "Iteration 278, loss = 128.41696677\n",
            "Iteration 279, loss = 128.41719731\n",
            "Iteration 280, loss = 128.41704067\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 68 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 712.06326431\n",
            "Iteration 2, loss = 449240.04759314\n",
            "Iteration 3, loss = 1169.70057281\n",
            "Iteration 4, loss = 1885.07133795\n",
            "Iteration 5, loss = 2605.59600555\n",
            "Iteration 6, loss = 3227.69694654\n",
            "Iteration 7, loss = 3724.19470378\n",
            "Iteration 8, loss = 4101.06158224\n",
            "Iteration 9, loss = 4376.20279679\n",
            "Iteration 10, loss = 4570.04906483\n",
            "Iteration 11, loss = 4701.04875779\n",
            "Iteration 12, loss = 4784.84769142\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 69 ------ \n",
            "-----> Match Score: 0 <------\n",
            "Iteration 1, loss = 698.08409527\n",
            "Iteration 2, loss = 635.29436163\n",
            "Iteration 3, loss = 6525544.57196417\n",
            "Iteration 4, loss = 43108.47211561\n",
            "Iteration 5, loss = 81209.24274927\n",
            "Iteration 6, loss = 115878.19746503\n",
            "Iteration 7, loss = 146257.22563139\n",
            "Iteration 8, loss = 170622.27436403\n",
            "Iteration 9, loss = 189669.51046716\n",
            "Iteration 10, loss = 204206.57759126\n",
            "Iteration 11, loss = 215145.23700147\n",
            "Iteration 12, loss = 223301.81267827\n",
            "Iteration 13, loss = 229344.29254267\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 70 ------ \n",
            "[12, 24, 35, 48, 59, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 39.0 <------\n",
            "Iteration 1, loss = 1008.96148145\n",
            "Iteration 2, loss = 691.69579330\n",
            "Iteration 3, loss = 671.99153825\n",
            "Iteration 4, loss = 647.97409831\n",
            "Iteration 5, loss = 621.53511013\n",
            "Iteration 6, loss = 593.81727254\n",
            "Iteration 7, loss = 565.60893647\n",
            "Iteration 8, loss = 537.70142889\n",
            "Iteration 9, loss = 510.28400334\n",
            "Iteration 10, loss = 483.71963149\n",
            "Iteration 11, loss = 458.21944711\n",
            "Iteration 12, loss = 434.05967030\n",
            "Iteration 13, loss = 411.07395506\n",
            "Iteration 14, loss = 389.17906442\n",
            "Iteration 15, loss = 368.63406661\n",
            "Iteration 16, loss = 349.13105815\n",
            "Iteration 17, loss = 330.96220320\n",
            "Iteration 18, loss = 313.66393411\n",
            "Iteration 19, loss = 297.71498115\n",
            "Iteration 20, loss = 282.60979348\n",
            "Iteration 21, loss = 268.39554193\n",
            "Iteration 22, loss = 255.12666855\n",
            "Iteration 23, loss = 242.66886749\n",
            "Iteration 24, loss = 231.00983191\n",
            "Iteration 25, loss = 220.14467928\n",
            "Iteration 26, loss = 209.89293643\n",
            "Iteration 27, loss = 200.37489521\n",
            "Iteration 28, loss = 191.39862279\n",
            "Iteration 29, loss = 183.10871719\n",
            "Iteration 30, loss = 175.14932736\n",
            "Iteration 31, loss = 167.84230618\n",
            "Iteration 32, loss = 160.98518893\n",
            "Iteration 33, loss = 154.52456431\n",
            "Iteration 34, loss = 148.52413872\n",
            "Iteration 35, loss = 142.87474715\n",
            "Iteration 36, loss = 137.66598087\n",
            "Iteration 37, loss = 132.76571303\n",
            "Iteration 38, loss = 128.12670495\n",
            "Iteration 39, loss = 123.81781623\n",
            "Iteration 40, loss = 119.76086770\n",
            "Iteration 41, loss = 115.97369065\n",
            "Iteration 42, loss = 112.45531207\n",
            "Iteration 43, loss = 109.16519532\n",
            "Iteration 44, loss = 106.06448501\n",
            "Iteration 45, loss = 103.16613793\n",
            "Iteration 46, loss = 100.44521056\n",
            "Iteration 47, loss = 97.93574023\n",
            "Iteration 48, loss = 95.54113855\n",
            "Iteration 49, loss = 93.33485183\n",
            "Iteration 50, loss = 91.29554854\n",
            "Iteration 51, loss = 89.29376895\n",
            "Iteration 52, loss = 87.50638360\n",
            "Iteration 53, loss = 85.77188496\n",
            "Iteration 54, loss = 84.20902120\n",
            "Iteration 55, loss = 82.69502726\n",
            "Iteration 56, loss = 81.31474287\n",
            "Iteration 57, loss = 80.01021943\n",
            "Iteration 58, loss = 78.77839606\n",
            "Iteration 59, loss = 77.65044986\n",
            "Iteration 60, loss = 76.58545090\n",
            "Iteration 61, loss = 75.57278130\n",
            "Iteration 62, loss = 74.63291246\n",
            "Iteration 63, loss = 73.76444693\n",
            "Iteration 64, loss = 72.93635892\n",
            "Iteration 65, loss = 72.15294661\n",
            "Iteration 66, loss = 71.46437867\n",
            "Iteration 67, loss = 70.78105352\n",
            "Iteration 68, loss = 70.14540923\n",
            "Iteration 69, loss = 69.55853575\n",
            "Iteration 70, loss = 69.00699068\n",
            "Iteration 71, loss = 68.51138704\n",
            "Iteration 72, loss = 68.00897190\n",
            "Iteration 73, loss = 67.55845498\n",
            "Iteration 74, loss = 67.12683689\n",
            "Iteration 75, loss = 66.74152992\n",
            "Iteration 76, loss = 66.37182023\n",
            "Iteration 77, loss = 66.02521922\n",
            "Iteration 78, loss = 65.70172285\n",
            "Iteration 79, loss = 65.39558191\n",
            "Iteration 80, loss = 65.11859851\n",
            "Iteration 81, loss = 64.84858233\n",
            "Iteration 82, loss = 64.61189152\n",
            "Iteration 83, loss = 64.36650315\n",
            "Iteration 84, loss = 64.16665818\n",
            "Iteration 85, loss = 63.94104356\n",
            "Iteration 86, loss = 63.76098460\n",
            "Iteration 87, loss = 63.58216799\n",
            "Iteration 88, loss = 63.42290964\n",
            "Iteration 89, loss = 63.25540778\n",
            "Iteration 90, loss = 63.11945913\n",
            "Iteration 91, loss = 62.97595362\n",
            "Iteration 92, loss = 62.84812258\n",
            "Iteration 93, loss = 62.73644786\n",
            "Iteration 94, loss = 62.61437078\n",
            "Iteration 95, loss = 62.52045139\n",
            "Iteration 96, loss = 62.41548487\n",
            "Iteration 97, loss = 62.32561279\n",
            "Iteration 98, loss = 62.23436858\n",
            "Iteration 99, loss = 62.16034520\n",
            "Iteration 100, loss = 62.08413085\n",
            "Iteration 101, loss = 62.01189061\n",
            "Iteration 102, loss = 61.94311804\n",
            "Iteration 103, loss = 61.88713531\n",
            "Iteration 104, loss = 61.82626716\n",
            "Iteration 105, loss = 61.77239735\n",
            "Iteration 106, loss = 61.72368284\n",
            "Iteration 107, loss = 61.67751114\n",
            "Iteration 108, loss = 61.62620438\n",
            "Iteration 109, loss = 61.58977639\n",
            "Iteration 110, loss = 61.54969727\n",
            "Iteration 111, loss = 61.51470195\n",
            "Iteration 112, loss = 61.48051011\n",
            "Iteration 113, loss = 61.44758648\n",
            "Iteration 114, loss = 61.41614554\n",
            "Iteration 115, loss = 61.39184631\n",
            "Iteration 116, loss = 61.36679298\n",
            "Iteration 117, loss = 61.33640762\n",
            "Iteration 118, loss = 61.31656177\n",
            "Iteration 119, loss = 61.30095347\n",
            "Iteration 120, loss = 61.27402461\n",
            "Iteration 121, loss = 61.25925372\n",
            "Iteration 122, loss = 61.23914469\n",
            "Iteration 123, loss = 61.22606665\n",
            "Iteration 124, loss = 61.20993971\n",
            "Iteration 125, loss = 61.19534116\n",
            "Iteration 126, loss = 61.17970934\n",
            "Iteration 127, loss = 61.17048928\n",
            "Iteration 128, loss = 61.15768198\n",
            "Iteration 129, loss = 61.14736316\n",
            "Iteration 130, loss = 61.13726866\n",
            "Iteration 131, loss = 61.12684984\n",
            "Iteration 132, loss = 61.11668019\n",
            "Iteration 133, loss = 61.10802400\n",
            "Iteration 134, loss = 61.10224962\n",
            "Iteration 135, loss = 61.09400653\n",
            "Iteration 136, loss = 61.08711440\n",
            "Iteration 137, loss = 61.07954801\n",
            "Iteration 138, loss = 61.07375815\n",
            "Iteration 139, loss = 61.06739746\n",
            "Iteration 140, loss = 61.06166403\n",
            "Iteration 141, loss = 61.05667693\n",
            "Iteration 142, loss = 61.05192109\n",
            "Iteration 143, loss = 61.04738039\n",
            "Iteration 144, loss = 61.04460838\n",
            "Iteration 145, loss = 61.04096961\n",
            "Iteration 146, loss = 61.03573551\n",
            "Iteration 147, loss = 61.03226778\n",
            "Iteration 148, loss = 61.02926082\n",
            "Iteration 149, loss = 61.02541115\n",
            "Iteration 150, loss = 61.02344689\n",
            "Iteration 151, loss = 61.02038764\n",
            "Iteration 152, loss = 61.01824859\n",
            "Iteration 153, loss = 61.01525339\n",
            "Iteration 154, loss = 61.01279792\n",
            "Iteration 155, loss = 61.01086339\n",
            "Iteration 156, loss = 61.01085118\n",
            "Iteration 157, loss = 61.00722863\n",
            "Iteration 158, loss = 61.00588386\n",
            "Iteration 159, loss = 61.00475003\n",
            "Iteration 160, loss = 61.00371225\n",
            "Iteration 161, loss = 61.00202088\n",
            "Iteration 162, loss = 61.00047959\n",
            "Iteration 163, loss = 60.99967346\n",
            "Iteration 164, loss = 60.99877794\n",
            "Iteration 165, loss = 60.99724610\n",
            "Iteration 166, loss = 60.99690670\n",
            "Iteration 167, loss = 60.99644886\n",
            "Iteration 168, loss = 60.99492797\n",
            "Iteration 169, loss = 60.99394255\n",
            "Iteration 170, loss = 60.99390423\n",
            "Iteration 171, loss = 60.99257574\n",
            "Iteration 172, loss = 60.99260650\n",
            "Iteration 173, loss = 60.99164369\n",
            "Iteration 174, loss = 60.99098657\n",
            "Iteration 175, loss = 60.99032663\n",
            "Iteration 176, loss = 60.98998502\n",
            "Iteration 177, loss = 60.98966825\n",
            "Iteration 178, loss = 60.98930047\n",
            "Iteration 179, loss = 60.98873591\n",
            "Iteration 180, loss = 60.98849040\n",
            "Iteration 181, loss = 60.98808783\n",
            "Iteration 182, loss = 60.98792475\n",
            "Iteration 183, loss = 60.98784651\n",
            "Iteration 184, loss = 60.98698541\n",
            "Iteration 185, loss = 60.98689791\n",
            "Iteration 186, loss = 60.98702227\n",
            "Iteration 187, loss = 60.98662790\n",
            "Iteration 188, loss = 60.98630864\n",
            "Iteration 189, loss = 60.98613666\n",
            "Iteration 190, loss = 60.98656311\n",
            "Iteration 191, loss = 60.98608603\n",
            "Iteration 192, loss = 60.98572763\n",
            "Iteration 193, loss = 60.98629239\n",
            "Iteration 194, loss = 60.98496217\n",
            "Iteration 195, loss = 60.98537460\n",
            "Iteration 196, loss = 60.98480620\n",
            "Iteration 197, loss = 60.98515987\n",
            "Iteration 198, loss = 60.98487343\n",
            "Iteration 199, loss = 60.98509446\n",
            "Iteration 200, loss = 60.98442400\n",
            "Iteration 201, loss = 60.98488154\n",
            "Iteration 202, loss = 60.98471469\n",
            "Iteration 203, loss = 60.98430778\n",
            "Iteration 204, loss = 60.98440672\n",
            "Iteration 205, loss = 60.98434415\n",
            "Iteration 206, loss = 60.98426901\n",
            "Iteration 207, loss = 60.98434308\n",
            "Iteration 208, loss = 60.98401869\n",
            "Iteration 209, loss = 60.98441284\n",
            "Iteration 210, loss = 60.98399631\n",
            "Iteration 211, loss = 60.98417110\n",
            "Iteration 212, loss = 60.98391873\n",
            "Iteration 213, loss = 60.98387669\n",
            "Iteration 214, loss = 60.98378205\n",
            "Iteration 215, loss = 60.98385653\n",
            "Iteration 216, loss = 60.98363135\n",
            "Iteration 217, loss = 60.98368916\n",
            "Iteration 218, loss = 60.98348985\n",
            "Iteration 219, loss = 60.98366524\n",
            "Iteration 220, loss = 60.98362576\n",
            "Iteration 221, loss = 60.98340409\n",
            "Iteration 222, loss = 60.98390190\n",
            "Iteration 223, loss = 60.98414285\n",
            "Iteration 224, loss = 60.98341588\n",
            "Iteration 225, loss = 60.98341398\n",
            "Iteration 226, loss = 60.98336716\n",
            "Iteration 227, loss = 60.98371465\n",
            "Iteration 228, loss = 60.98332030\n",
            "Iteration 229, loss = 60.98365425\n",
            "Iteration 230, loss = 60.98329211\n",
            "Iteration 231, loss = 60.98346326\n",
            "Iteration 232, loss = 60.98322880\n",
            "Iteration 233, loss = 60.98310517\n",
            "Iteration 234, loss = 60.98374019\n",
            "Iteration 235, loss = 60.98343567\n",
            "Iteration 236, loss = 60.98355043\n",
            "Iteration 237, loss = 60.98340588\n",
            "Iteration 238, loss = 60.98341522\n",
            "Iteration 239, loss = 60.98321056\n",
            "Iteration 240, loss = 60.98441872\n",
            "Iteration 241, loss = 60.98300818\n",
            "Iteration 242, loss = 60.98326760\n",
            "Iteration 243, loss = 60.98327912\n",
            "Iteration 244, loss = 60.98304779\n",
            "Iteration 245, loss = 60.98416582\n",
            "Iteration 246, loss = 60.98319539\n",
            "Iteration 247, loss = 60.98338080\n",
            "Iteration 248, loss = 60.98298589\n",
            "Iteration 249, loss = 60.98314443\n",
            "Iteration 250, loss = 60.98352595\n",
            "Iteration 251, loss = 60.98295246\n",
            "Iteration 252, loss = 60.98337792\n",
            "Iteration 253, loss = 60.98334412\n",
            "Iteration 254, loss = 60.98304061\n",
            "Iteration 255, loss = 60.98351352\n",
            "Iteration 256, loss = 60.98315150\n",
            "Iteration 257, loss = 60.98356286\n",
            "Iteration 258, loss = 60.98326170\n",
            "Iteration 259, loss = 60.98304095\n",
            "Iteration 260, loss = 60.98358832\n",
            "Iteration 261, loss = 60.98305169\n",
            "Iteration 262, loss = 60.98311042\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 71 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 868.22079807\n",
            "Iteration 2, loss = 179.99877822\n",
            "Iteration 3, loss = 149.68555452\n",
            "Iteration 4, loss = 77.67345288\n",
            "Iteration 5, loss = 69.66854298\n",
            "Iteration 6, loss = 66.45543036\n",
            "Iteration 7, loss = 64.33480988\n",
            "Iteration 8, loss = 64.67736097\n",
            "Iteration 9, loss = 63.51302346\n",
            "Iteration 10, loss = 66.96495404\n",
            "Iteration 11, loss = 79.16163963\n",
            "Iteration 12, loss = 195.38027105\n",
            "Iteration 13, loss = 522.70212002\n",
            "Iteration 14, loss = 704.90951907\n",
            "Iteration 15, loss = 652.02922925\n",
            "Iteration 16, loss = 564.09384197\n",
            "Iteration 17, loss = 301.22825521\n",
            "Iteration 18, loss = 89.95200376\n",
            "Iteration 19, loss = 136.80213744\n",
            "Iteration 20, loss = 67.20421617\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 72 ------ \n",
            "[8, 20, 31, 43, 54, 15] [ 1 15 17 46 66 15] [] [15] 6.0\n",
            "[8, 20, 31, 43, 54, 15] [ 8 31 39 40 43  4] [8, 43, 31] [] 6.0\n",
            "[8, 20, 31, 43, 54, 15] [12 21 32 44 66 15] [] [15] 6.0\n",
            "[8, 20, 31, 43, 54, 15] [23 36 51 53 60 15] [] [15] 6.0\n",
            "-----> Match Score: 24.0 <------\n",
            "Iteration 1, loss = 709.29552373\n",
            "Iteration 2, loss = 598.01027934\n",
            "Iteration 3, loss = 295.34745442\n",
            "Iteration 4, loss = 105.27082908\n",
            "Iteration 5, loss = 133.92470152\n",
            "Iteration 6, loss = 64.69103004\n",
            "Iteration 7, loss = 71.18716368\n",
            "Iteration 8, loss = 64.92696330\n",
            "Iteration 9, loss = 61.88989340\n",
            "Iteration 10, loss = 62.00377855\n",
            "Iteration 11, loss = 61.34618219\n",
            "Iteration 12, loss = 61.13504366\n",
            "Iteration 13, loss = 61.00703499\n",
            "Iteration 14, loss = 61.13938744\n",
            "Iteration 15, loss = 61.01207393\n",
            "Iteration 16, loss = 61.00969261\n",
            "Iteration 17, loss = 61.03073843\n",
            "Iteration 18, loss = 61.01716921\n",
            "Iteration 19, loss = 61.04935001\n",
            "Iteration 20, loss = 60.99854804\n",
            "Iteration 21, loss = 61.01356302\n",
            "Iteration 22, loss = 61.05337886\n",
            "Iteration 23, loss = 61.03999743\n",
            "Iteration 24, loss = 60.97919432\n",
            "Iteration 25, loss = 60.99013427\n",
            "Iteration 26, loss = 60.99297442\n",
            "Iteration 27, loss = 61.09014991\n",
            "Iteration 28, loss = 61.02274711\n",
            "Iteration 29, loss = 61.00246334\n",
            "Iteration 30, loss = 61.01779443\n",
            "Iteration 31, loss = 61.01533012\n",
            "Iteration 32, loss = 61.04278017\n",
            "Iteration 33, loss = 61.01124483\n",
            "Iteration 34, loss = 61.07510578\n",
            "Iteration 35, loss = 61.08408761\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 73 ------ \n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 39.0 <------\n",
            "Iteration 1, loss = 815.83389998\n",
            "Iteration 2, loss = 695.54079463\n",
            "Iteration 3, loss = 651.52242351\n",
            "Iteration 4, loss = 510.73066751\n",
            "Iteration 5, loss = 189.87354994\n",
            "Iteration 6, loss = 120.19068074\n",
            "Iteration 7, loss = 107.79719176\n",
            "Iteration 8, loss = 64.03248714\n",
            "Iteration 9, loss = 70.10481792\n",
            "Iteration 10, loss = 62.67076660\n",
            "Iteration 11, loss = 61.76685426\n",
            "Iteration 12, loss = 61.95806266\n",
            "Iteration 13, loss = 61.08771350\n",
            "Iteration 14, loss = 61.11976498\n",
            "Iteration 15, loss = 61.13028536\n",
            "Iteration 16, loss = 61.01294014\n",
            "Iteration 17, loss = 61.00545198\n",
            "Iteration 18, loss = 61.10193282\n",
            "Iteration 19, loss = 61.11313279\n",
            "Iteration 20, loss = 61.01446539\n",
            "Iteration 21, loss = 61.01485388\n",
            "Iteration 22, loss = 61.04258426\n",
            "Iteration 23, loss = 61.05161377\n",
            "Iteration 24, loss = 61.21322641\n",
            "Iteration 25, loss = 61.20246454\n",
            "Iteration 26, loss = 61.09345605\n",
            "Iteration 27, loss = 61.02202205\n",
            "Iteration 28, loss = 61.01232483\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 74 ------ \n",
            "[12, 24, 35, 47, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 1  7 45 47 69 13] [47] [13] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 3308216.62352008\n",
            "Iteration 2, loss = 17446.05733028\n",
            "Iteration 3, loss = 37988.78501137\n",
            "Iteration 4, loss = 57441.66192568\n",
            "Iteration 5, loss = 75227.81635495\n",
            "Iteration 6, loss = 89551.55973542\n",
            "Iteration 7, loss = 100951.52598634\n",
            "Iteration 8, loss = 109695.08794717\n",
            "Iteration 9, loss = 116303.51492192\n",
            "Iteration 10, loss = 121244.60552472\n",
            "Iteration 11, loss = 124912.29514221\n",
            "Iteration 12, loss = 127620.31510873\n",
            "Iteration 13, loss = 129613.04278831\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 75 ------ \n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 39.0 <------\n",
            "Iteration 1, loss = 773975.33205084\n",
            "Iteration 2, loss = 27450.05745828\n",
            "Iteration 3, loss = 61292.00088685\n",
            "Iteration 4, loss = 94923.76814287\n",
            "Iteration 5, loss = 124195.66207584\n",
            "Iteration 6, loss = 148053.97864475\n",
            "Iteration 7, loss = 166778.57983818\n",
            "Iteration 8, loss = 181130.00312211\n",
            "Iteration 9, loss = 191958.65181065\n",
            "Iteration 10, loss = 200041.72224098\n",
            "Iteration 11, loss = 206029.28606111\n",
            "Iteration 12, loss = 210439.55304443\n",
            "Iteration 13, loss = 213674.22713676\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 76 ------ \n",
            "[0, 19, -2, 7, -11, 2] [27 49 50 51 52  2] [] [2] 6.0\n",
            "[0, 19, -2, 7, -11, 2] [ 4 29 49 50 67  2] [] [2] 6.0\n",
            "[0, 19, -2, 7, -11, 2] [ 3 11 38 44 58  2] [] [2] 6.0\n",
            "[0, 19, -2, 7, -11, 2] [ 9 12 15 31 60  2] [] [2] 6.0\n",
            "-----> Match Score: 24.0 <------\n",
            "Iteration 1, loss = 1657.52311362\n",
            "Iteration 2, loss = 695.78879159\n",
            "Iteration 3, loss = 676.23610255\n",
            "Iteration 4, loss = 652.50279127\n",
            "Iteration 5, loss = 626.27776284\n",
            "Iteration 6, loss = 598.61837184\n",
            "Iteration 7, loss = 570.52325755\n",
            "Iteration 8, loss = 542.56467925\n",
            "Iteration 9, loss = 515.15187349\n",
            "Iteration 10, loss = 488.55681411\n",
            "Iteration 11, loss = 463.12966339\n",
            "Iteration 12, loss = 438.86955454\n",
            "Iteration 13, loss = 415.65630524\n",
            "Iteration 14, loss = 393.80094955\n",
            "Iteration 15, loss = 373.04974533\n",
            "Iteration 16, loss = 353.60740354\n",
            "Iteration 17, loss = 335.34957290\n",
            "Iteration 18, loss = 318.08760595\n",
            "Iteration 19, loss = 301.99290679\n",
            "Iteration 20, loss = 286.80097297\n",
            "Iteration 21, loss = 272.51652098\n",
            "Iteration 22, loss = 259.16725498\n",
            "Iteration 23, loss = 246.71077488\n",
            "Iteration 24, loss = 235.08805427\n",
            "Iteration 25, loss = 224.11986043\n",
            "Iteration 26, loss = 213.76718847\n",
            "Iteration 27, loss = 204.28058907\n",
            "Iteration 28, loss = 195.26236801\n",
            "Iteration 29, loss = 186.83162285\n",
            "Iteration 30, loss = 178.96225771\n",
            "Iteration 31, loss = 171.62084136\n",
            "Iteration 32, loss = 164.72974565\n",
            "Iteration 33, loss = 158.21259681\n",
            "Iteration 34, loss = 152.22740528\n",
            "Iteration 35, loss = 146.53400860\n",
            "Iteration 36, loss = 141.22296468\n",
            "Iteration 37, loss = 136.28837538\n",
            "Iteration 38, loss = 131.69136102\n",
            "Iteration 39, loss = 127.31678421\n",
            "Iteration 40, loss = 123.26190971\n",
            "Iteration 41, loss = 119.44146670\n",
            "Iteration 42, loss = 115.91879463\n",
            "Iteration 43, loss = 112.60432744\n",
            "Iteration 44, loss = 109.47628762\n",
            "Iteration 45, loss = 106.55038139\n",
            "Iteration 46, loss = 103.83163885\n",
            "Iteration 47, loss = 101.28144635\n",
            "Iteration 48, loss = 98.85925025\n",
            "Iteration 49, loss = 96.63781311\n",
            "Iteration 50, loss = 94.56337671\n",
            "Iteration 51, loss = 92.61246938\n",
            "Iteration 52, loss = 90.75769834\n",
            "Iteration 53, loss = 89.03440711\n",
            "Iteration 54, loss = 87.42708667\n",
            "Iteration 55, loss = 85.94546046\n",
            "Iteration 56, loss = 84.54622780\n",
            "Iteration 57, loss = 83.22549525\n",
            "Iteration 58, loss = 81.97563230\n",
            "Iteration 59, loss = 80.84286810\n",
            "Iteration 60, loss = 79.75851230\n",
            "Iteration 61, loss = 78.73692542\n",
            "Iteration 62, loss = 77.80923176\n",
            "Iteration 63, loss = 76.91490571\n",
            "Iteration 64, loss = 76.08845600\n",
            "Iteration 65, loss = 75.30107463\n",
            "Iteration 66, loss = 74.61393096\n",
            "Iteration 67, loss = 73.90672884\n",
            "Iteration 68, loss = 73.28266257\n",
            "Iteration 69, loss = 72.68596658\n",
            "Iteration 70, loss = 72.13398245\n",
            "Iteration 71, loss = 71.60890975\n",
            "Iteration 72, loss = 71.11929368\n",
            "Iteration 73, loss = 70.67603803\n",
            "Iteration 74, loss = 70.24989661\n",
            "Iteration 75, loss = 69.83516559\n",
            "Iteration 76, loss = 69.48439946\n",
            "Iteration 77, loss = 69.13078551\n",
            "Iteration 78, loss = 68.80502103\n",
            "Iteration 79, loss = 68.49339337\n",
            "Iteration 80, loss = 68.21982429\n",
            "Iteration 81, loss = 67.93744054\n",
            "Iteration 82, loss = 67.70561137\n",
            "Iteration 83, loss = 67.47023625\n",
            "Iteration 84, loss = 67.24606617\n",
            "Iteration 85, loss = 67.04904029\n",
            "Iteration 86, loss = 66.86193143\n",
            "Iteration 87, loss = 66.68052207\n",
            "Iteration 88, loss = 66.51170781\n",
            "Iteration 89, loss = 66.35560371\n",
            "Iteration 90, loss = 66.20642770\n",
            "Iteration 91, loss = 66.07218738\n",
            "Iteration 92, loss = 65.95202967\n",
            "Iteration 93, loss = 65.82978687\n",
            "Iteration 94, loss = 65.70891411\n",
            "Iteration 95, loss = 65.60644685\n",
            "Iteration 96, loss = 65.51243043\n",
            "Iteration 97, loss = 65.41902854\n",
            "Iteration 98, loss = 65.33250684\n",
            "Iteration 99, loss = 65.24959820\n",
            "Iteration 100, loss = 65.17503833\n",
            "Iteration 101, loss = 65.10663927\n",
            "Iteration 102, loss = 65.04229101\n",
            "Iteration 103, loss = 64.97408430\n",
            "Iteration 104, loss = 64.91433962\n",
            "Iteration 105, loss = 64.86550615\n",
            "Iteration 106, loss = 64.81496587\n",
            "Iteration 107, loss = 64.76648062\n",
            "Iteration 108, loss = 64.71986330\n",
            "Iteration 109, loss = 64.67867489\n",
            "Iteration 110, loss = 64.64444654\n",
            "Iteration 111, loss = 64.60470362\n",
            "Iteration 112, loss = 64.56827805\n",
            "Iteration 113, loss = 64.53771438\n",
            "Iteration 114, loss = 64.50614610\n",
            "Iteration 115, loss = 64.48026498\n",
            "Iteration 116, loss = 64.45172345\n",
            "Iteration 117, loss = 64.43074991\n",
            "Iteration 118, loss = 64.40655303\n",
            "Iteration 119, loss = 64.38681791\n",
            "Iteration 120, loss = 64.36574677\n",
            "Iteration 121, loss = 64.34610141\n",
            "Iteration 122, loss = 64.33023225\n",
            "Iteration 123, loss = 64.31313765\n",
            "Iteration 124, loss = 64.29888956\n",
            "Iteration 125, loss = 64.28238469\n",
            "Iteration 126, loss = 64.27039152\n",
            "Iteration 127, loss = 64.25761541\n",
            "Iteration 128, loss = 64.24611192\n",
            "Iteration 129, loss = 64.23702469\n",
            "Iteration 130, loss = 64.22523142\n",
            "Iteration 131, loss = 64.21322964\n",
            "Iteration 132, loss = 64.21108356\n",
            "Iteration 133, loss = 64.19834975\n",
            "Iteration 134, loss = 64.18965515\n",
            "Iteration 135, loss = 64.18396405\n",
            "Iteration 136, loss = 64.17725679\n",
            "Iteration 137, loss = 64.16975452\n",
            "Iteration 138, loss = 64.16588404\n",
            "Iteration 139, loss = 64.15827371\n",
            "Iteration 140, loss = 64.15240104\n",
            "Iteration 141, loss = 64.14907475\n",
            "Iteration 142, loss = 64.14334106\n",
            "Iteration 143, loss = 64.14017517\n",
            "Iteration 144, loss = 64.13696068\n",
            "Iteration 145, loss = 64.13189665\n",
            "Iteration 146, loss = 64.12837267\n",
            "Iteration 147, loss = 64.12544495\n",
            "Iteration 148, loss = 64.12341556\n",
            "Iteration 149, loss = 64.11972799\n",
            "Iteration 150, loss = 64.11656909\n",
            "Iteration 151, loss = 64.11461610\n",
            "Iteration 152, loss = 64.11141203\n",
            "Iteration 153, loss = 64.11075809\n",
            "Iteration 154, loss = 64.10791468\n",
            "Iteration 155, loss = 64.10561134\n",
            "Iteration 156, loss = 64.10366814\n",
            "Iteration 157, loss = 64.10312457\n",
            "Iteration 158, loss = 64.10051471\n",
            "Iteration 159, loss = 64.09908670\n",
            "Iteration 160, loss = 64.09711197\n",
            "Iteration 161, loss = 64.09706133\n",
            "Iteration 162, loss = 64.09571693\n",
            "Iteration 163, loss = 64.09342667\n",
            "Iteration 164, loss = 64.09236225\n",
            "Iteration 165, loss = 64.09107258\n",
            "Iteration 166, loss = 64.09036868\n",
            "Iteration 167, loss = 64.08920426\n",
            "Iteration 168, loss = 64.08848048\n",
            "Iteration 169, loss = 64.08866777\n",
            "Iteration 170, loss = 64.08719217\n",
            "Iteration 171, loss = 64.08723039\n",
            "Iteration 172, loss = 64.08510311\n",
            "Iteration 173, loss = 64.08477882\n",
            "Iteration 174, loss = 64.08472529\n",
            "Iteration 175, loss = 64.08432398\n",
            "Iteration 176, loss = 64.08309899\n",
            "Iteration 177, loss = 64.08256159\n",
            "Iteration 178, loss = 64.08231437\n",
            "Iteration 179, loss = 64.08189312\n",
            "Iteration 180, loss = 64.08151959\n",
            "Iteration 181, loss = 64.08130061\n",
            "Iteration 182, loss = 64.08072658\n",
            "Iteration 183, loss = 64.08044746\n",
            "Iteration 184, loss = 64.08030843\n",
            "Iteration 185, loss = 64.08015524\n",
            "Iteration 186, loss = 64.07974812\n",
            "Iteration 187, loss = 64.07949720\n",
            "Iteration 188, loss = 64.07934433\n",
            "Iteration 189, loss = 64.07978565\n",
            "Iteration 190, loss = 64.07869954\n",
            "Iteration 191, loss = 64.07859786\n",
            "Iteration 192, loss = 64.07847227\n",
            "Iteration 193, loss = 64.07849360\n",
            "Iteration 194, loss = 64.07813025\n",
            "Iteration 195, loss = 64.07844939\n",
            "Iteration 196, loss = 64.07807197\n",
            "Iteration 197, loss = 64.07792531\n",
            "Iteration 198, loss = 64.07839361\n",
            "Iteration 199, loss = 64.07750946\n",
            "Iteration 200, loss = 64.07744001\n",
            "Iteration 201, loss = 64.07744187\n",
            "Iteration 202, loss = 64.07739724\n",
            "Iteration 203, loss = 64.07747822\n",
            "Iteration 204, loss = 64.07744637\n",
            "Iteration 205, loss = 64.07741166\n",
            "Iteration 206, loss = 64.07777317\n",
            "Iteration 207, loss = 64.07692783\n",
            "Iteration 208, loss = 64.07725760\n",
            "Iteration 209, loss = 64.07685944\n",
            "Iteration 210, loss = 64.07682234\n",
            "Iteration 211, loss = 64.07694960\n",
            "Iteration 212, loss = 64.07749121\n",
            "Iteration 213, loss = 64.07660652\n",
            "Iteration 214, loss = 64.07680730\n",
            "Iteration 215, loss = 64.07665285\n",
            "Iteration 216, loss = 64.07675769\n",
            "Iteration 217, loss = 64.07672611\n",
            "Iteration 218, loss = 64.07676195\n",
            "Iteration 219, loss = 64.07711210\n",
            "Iteration 220, loss = 64.07687354\n",
            "Iteration 221, loss = 64.07645859\n",
            "Iteration 222, loss = 64.07654566\n",
            "Iteration 223, loss = 64.07650306\n",
            "Iteration 224, loss = 64.07647423\n",
            "Iteration 225, loss = 64.07677830\n",
            "Iteration 226, loss = 64.07652330\n",
            "Iteration 227, loss = 64.07653646\n",
            "Iteration 228, loss = 64.07651656\n",
            "Iteration 229, loss = 64.07670398\n",
            "Iteration 230, loss = 64.07671697\n",
            "Iteration 231, loss = 64.07649228\n",
            "Iteration 232, loss = 64.07659444\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 77 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 20924.18923741\n",
            "Iteration 2, loss = 287.06532461\n",
            "Iteration 3, loss = 187.87292891\n",
            "Iteration 4, loss = 155.99630694\n",
            "Iteration 5, loss = 137.88164179\n",
            "Iteration 6, loss = 240.96764764\n",
            "Iteration 7, loss = 684.79657394\n",
            "Iteration 8, loss = 487.43307790\n",
            "Iteration 9, loss = 167.40929056\n",
            "Iteration 10, loss = 162.13855000\n",
            "Iteration 11, loss = 102.32035936\n",
            "Iteration 12, loss = 98.41562661\n",
            "Iteration 13, loss = 98.33467323\n",
            "Iteration 14, loss = 89.23835482\n",
            "Iteration 15, loss = 87.78916605\n",
            "Iteration 16, loss = 87.70898142\n",
            "Iteration 17, loss = 88.01254227\n",
            "Iteration 18, loss = 87.67546145\n",
            "Iteration 19, loss = 87.41940405\n",
            "Iteration 20, loss = 87.35192024\n",
            "Iteration 21, loss = 87.45172498\n",
            "Iteration 22, loss = 87.49705229\n",
            "Iteration 23, loss = 87.41868969\n",
            "Iteration 24, loss = 87.54287055\n",
            "Iteration 25, loss = 87.40458319\n",
            "Iteration 26, loss = 87.45056676\n",
            "Iteration 27, loss = 87.52767465\n",
            "Iteration 28, loss = 87.61461362\n",
            "Iteration 29, loss = 87.45676044\n",
            "Iteration 30, loss = 87.47612358\n",
            "Iteration 31, loss = 87.53210565\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 78 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 825.02987565\n",
            "Iteration 2, loss = 637.58531881\n",
            "Iteration 3, loss = 442.86369106\n",
            "Iteration 4, loss = 118.93328023\n",
            "Iteration 5, loss = 146.59393848\n",
            "Iteration 6, loss = 80.62220792\n",
            "Iteration 7, loss = 67.46090061\n",
            "Iteration 8, loss = 68.04486251\n",
            "Iteration 9, loss = 61.70942797\n",
            "Iteration 10, loss = 62.22877964\n",
            "Iteration 11, loss = 61.23948379\n",
            "Iteration 12, loss = 61.09589493\n",
            "Iteration 13, loss = 61.12195970\n",
            "Iteration 14, loss = 61.01793587\n",
            "Iteration 15, loss = 61.12617663\n",
            "Iteration 16, loss = 61.00381279\n",
            "Iteration 17, loss = 61.09197389\n",
            "Iteration 18, loss = 61.04887831\n",
            "Iteration 19, loss = 61.01289187\n",
            "Iteration 20, loss = 61.05995902\n",
            "Iteration 21, loss = 61.01863419\n",
            "Iteration 22, loss = 61.05259644\n",
            "Iteration 23, loss = 60.99999166\n",
            "Iteration 24, loss = 61.01379765\n",
            "Iteration 25, loss = 61.02639998\n",
            "Iteration 26, loss = 61.18611559\n",
            "Iteration 27, loss = 61.15776111\n",
            "Iteration 28, loss = 60.98743779\n",
            "Iteration 29, loss = 61.01855450\n",
            "Iteration 30, loss = 61.08229434\n",
            "Iteration 31, loss = 61.00561919\n",
            "Iteration 32, loss = 61.10698202\n",
            "Iteration 33, loss = 61.09991838\n",
            "Iteration 34, loss = 61.00331325\n",
            "Iteration 35, loss = 61.05553100\n",
            "Iteration 36, loss = 61.13116387\n",
            "Iteration 37, loss = 61.01436186\n",
            "Iteration 38, loss = 61.01275504\n",
            "Iteration 39, loss = 60.98931943\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 79 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 1317750.59197062\n",
            "Iteration 2, loss = 4838.03099861\n",
            "Iteration 3, loss = 9794.74213624\n",
            "Iteration 4, loss = 14268.23742786\n",
            "Iteration 5, loss = 17837.01886061\n",
            "Iteration 6, loss = 21283.26372789\n",
            "Iteration 7, loss = 23860.57152300\n",
            "Iteration 8, loss = 25925.78836063\n",
            "Iteration 9, loss = 27477.22518578\n",
            "Iteration 10, loss = 28642.84495608\n",
            "Iteration 11, loss = 29507.02756911\n",
            "Iteration 12, loss = 30145.65955596\n",
            "Iteration 13, loss = 30615.56862381\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 80 ------ \n",
            "[12, 24, 36, 48, 59, 13] [ 6 15 50 59 60 13] [59] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 59, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[12, 24, 36, 48, 59, 13] [ 2 23 40 59 69 13] [59] [13] 7.0\n",
            "[12, 24, 36, 48, 59, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "-----> Match Score: 39.0 <------\n",
            "Iteration 1, loss = 701.64587497\n",
            "Iteration 2, loss = 688.04477691\n",
            "Iteration 3, loss = 668.77671515\n",
            "Iteration 4, loss = 645.31621478\n",
            "Iteration 5, loss = 619.08461940\n",
            "Iteration 6, loss = 591.58245580\n",
            "Iteration 7, loss = 563.56011858\n",
            "Iteration 8, loss = 535.84833201\n",
            "Iteration 9, loss = 508.61213303\n",
            "Iteration 10, loss = 482.27845958\n",
            "Iteration 11, loss = 456.88799305\n",
            "Iteration 12, loss = 432.73620371\n",
            "Iteration 13, loss = 409.67185491\n",
            "Iteration 14, loss = 388.05601178\n",
            "Iteration 15, loss = 367.59415294\n",
            "Iteration 16, loss = 348.20180766\n",
            "Iteration 17, loss = 330.01165648\n",
            "Iteration 18, loss = 312.96615058\n",
            "Iteration 19, loss = 296.91326081\n",
            "Iteration 20, loss = 281.82562522\n",
            "Iteration 21, loss = 267.70343628\n",
            "Iteration 22, loss = 254.48738577\n",
            "Iteration 23, loss = 242.17696107\n",
            "Iteration 24, loss = 230.57416002\n",
            "Iteration 25, loss = 219.60494215\n",
            "Iteration 26, loss = 209.53058973\n",
            "Iteration 27, loss = 199.97855880\n",
            "Iteration 28, loss = 191.00648854\n",
            "Iteration 29, loss = 182.62546713\n",
            "Iteration 30, loss = 174.94520134\n",
            "Iteration 31, loss = 167.58253415\n",
            "Iteration 32, loss = 160.71733442\n",
            "Iteration 33, loss = 154.28457948\n",
            "Iteration 34, loss = 148.35161371\n",
            "Iteration 35, loss = 142.69376694\n",
            "Iteration 36, loss = 137.50078967\n",
            "Iteration 37, loss = 132.54706055\n",
            "Iteration 38, loss = 127.96222398\n",
            "Iteration 39, loss = 123.66244820\n",
            "Iteration 40, loss = 119.58540882\n",
            "Iteration 41, loss = 115.86318984\n",
            "Iteration 42, loss = 112.35223051\n",
            "Iteration 43, loss = 109.02943009\n",
            "Iteration 44, loss = 105.88813368\n",
            "Iteration 45, loss = 103.10668747\n",
            "Iteration 46, loss = 100.31761418\n",
            "Iteration 47, loss = 97.87168787\n",
            "Iteration 48, loss = 95.41458326\n",
            "Iteration 49, loss = 93.27112206\n",
            "Iteration 50, loss = 91.17830757\n",
            "Iteration 51, loss = 89.22764062\n",
            "Iteration 52, loss = 87.40244333\n",
            "Iteration 53, loss = 85.71626931\n",
            "Iteration 54, loss = 84.12560701\n",
            "Iteration 55, loss = 82.63769592\n",
            "Iteration 56, loss = 81.29875784\n",
            "Iteration 57, loss = 79.94210262\n",
            "Iteration 58, loss = 78.74697450\n",
            "Iteration 59, loss = 77.60163752\n",
            "Iteration 60, loss = 76.54374359\n",
            "Iteration 61, loss = 75.55090828\n",
            "Iteration 62, loss = 74.58431142\n",
            "Iteration 63, loss = 73.74309694\n",
            "Iteration 64, loss = 72.91366082\n",
            "Iteration 65, loss = 72.15418234\n",
            "Iteration 66, loss = 71.44186421\n",
            "Iteration 67, loss = 70.76440897\n",
            "Iteration 68, loss = 70.13817060\n",
            "Iteration 69, loss = 69.54084842\n",
            "Iteration 70, loss = 69.00575233\n",
            "Iteration 71, loss = 68.49096589\n",
            "Iteration 72, loss = 67.99497843\n",
            "Iteration 73, loss = 67.54670227\n",
            "Iteration 74, loss = 67.12018274\n",
            "Iteration 75, loss = 66.72320789\n",
            "Iteration 76, loss = 66.37083203\n",
            "Iteration 77, loss = 66.01439674\n",
            "Iteration 78, loss = 65.68238499\n",
            "Iteration 79, loss = 65.37834074\n",
            "Iteration 80, loss = 65.10165485\n",
            "Iteration 81, loss = 64.83379069\n",
            "Iteration 82, loss = 64.57872938\n",
            "Iteration 83, loss = 64.34820995\n",
            "Iteration 84, loss = 64.14053386\n",
            "Iteration 85, loss = 63.93476461\n",
            "Iteration 86, loss = 63.73439065\n",
            "Iteration 87, loss = 63.56365712\n",
            "Iteration 88, loss = 63.39240188\n",
            "Iteration 89, loss = 63.23923512\n",
            "Iteration 90, loss = 63.09286811\n",
            "Iteration 91, loss = 62.95660386\n",
            "Iteration 92, loss = 62.82767247\n",
            "Iteration 93, loss = 62.70948769\n",
            "Iteration 94, loss = 62.59665952\n",
            "Iteration 95, loss = 62.48606322\n",
            "Iteration 96, loss = 62.39593749\n",
            "Iteration 97, loss = 62.30875872\n",
            "Iteration 98, loss = 62.21488330\n",
            "Iteration 99, loss = 62.13271185\n",
            "Iteration 100, loss = 62.06293037\n",
            "Iteration 101, loss = 61.99261582\n",
            "Iteration 102, loss = 61.92712636\n",
            "Iteration 103, loss = 61.86234792\n",
            "Iteration 104, loss = 61.80937963\n",
            "Iteration 105, loss = 61.75933037\n",
            "Iteration 106, loss = 61.69875312\n",
            "Iteration 107, loss = 61.65379556\n",
            "Iteration 108, loss = 61.61316798\n",
            "Iteration 109, loss = 61.57520125\n",
            "Iteration 110, loss = 61.53451601\n",
            "Iteration 111, loss = 61.49808653\n",
            "Iteration 112, loss = 61.46558512\n",
            "Iteration 113, loss = 61.42918140\n",
            "Iteration 114, loss = 61.40060983\n",
            "Iteration 115, loss = 61.37542255\n",
            "Iteration 116, loss = 61.34619813\n",
            "Iteration 117, loss = 61.32259684\n",
            "Iteration 118, loss = 61.30124924\n",
            "Iteration 119, loss = 61.28087021\n",
            "Iteration 120, loss = 61.26103536\n",
            "Iteration 121, loss = 61.24170475\n",
            "Iteration 122, loss = 61.22469215\n",
            "Iteration 123, loss = 61.20708738\n",
            "Iteration 124, loss = 61.19029883\n",
            "Iteration 125, loss = 61.18211137\n",
            "Iteration 126, loss = 61.16333425\n",
            "Iteration 127, loss = 61.15135768\n",
            "Iteration 128, loss = 61.14129324\n",
            "Iteration 129, loss = 61.13123757\n",
            "Iteration 130, loss = 61.11867108\n",
            "Iteration 131, loss = 61.10858925\n",
            "Iteration 132, loss = 61.10073424\n",
            "Iteration 133, loss = 61.09193013\n",
            "Iteration 134, loss = 61.08321899\n",
            "Iteration 135, loss = 61.07942706\n",
            "Iteration 136, loss = 61.06998937\n",
            "Iteration 137, loss = 61.06346535\n",
            "Iteration 138, loss = 61.05766946\n",
            "Iteration 139, loss = 61.05318060\n",
            "Iteration 140, loss = 61.04661051\n",
            "Iteration 141, loss = 61.04262725\n",
            "Iteration 142, loss = 61.04126260\n",
            "Iteration 143, loss = 61.03357519\n",
            "Iteration 144, loss = 61.03038144\n",
            "Iteration 145, loss = 61.02472371\n",
            "Iteration 146, loss = 61.02392437\n",
            "Iteration 147, loss = 61.01867366\n",
            "Iteration 148, loss = 61.01614253\n",
            "Iteration 149, loss = 61.01312767\n",
            "Iteration 150, loss = 61.01063587\n",
            "Iteration 151, loss = 61.00875127\n",
            "Iteration 152, loss = 61.00593220\n",
            "Iteration 153, loss = 61.00346006\n",
            "Iteration 154, loss = 61.00188387\n",
            "Iteration 155, loss = 60.99941429\n",
            "Iteration 156, loss = 60.99786200\n",
            "Iteration 157, loss = 60.99621625\n",
            "Iteration 158, loss = 60.99437008\n",
            "Iteration 159, loss = 60.99310693\n",
            "Iteration 160, loss = 60.99140504\n",
            "Iteration 161, loss = 60.99022460\n",
            "Iteration 162, loss = 60.99040129\n",
            "Iteration 163, loss = 60.98735662\n",
            "Iteration 164, loss = 60.98734205\n",
            "Iteration 165, loss = 60.98532487\n",
            "Iteration 166, loss = 60.98513237\n",
            "Iteration 167, loss = 60.98382987\n",
            "Iteration 168, loss = 60.98251898\n",
            "Iteration 169, loss = 60.98250797\n",
            "Iteration 170, loss = 60.98177841\n",
            "Iteration 171, loss = 60.98095208\n",
            "Iteration 172, loss = 60.97990110\n",
            "Iteration 173, loss = 60.97963463\n",
            "Iteration 174, loss = 60.97966071\n",
            "Iteration 175, loss = 60.97873232\n",
            "Iteration 176, loss = 60.97865103\n",
            "Iteration 177, loss = 60.97837539\n",
            "Iteration 178, loss = 60.97711786\n",
            "Iteration 179, loss = 60.97695973\n",
            "Iteration 180, loss = 60.97684150\n",
            "Iteration 181, loss = 60.97637578\n",
            "Iteration 182, loss = 60.97616534\n",
            "Iteration 183, loss = 60.97589611\n",
            "Iteration 184, loss = 60.97566902\n",
            "Iteration 185, loss = 60.97530021\n",
            "Iteration 186, loss = 60.97578624\n",
            "Iteration 187, loss = 60.97489546\n",
            "Iteration 188, loss = 60.97511324\n",
            "Iteration 189, loss = 60.97469532\n",
            "Iteration 190, loss = 60.97467026\n",
            "Iteration 191, loss = 60.97422250\n",
            "Iteration 192, loss = 60.97402219\n",
            "Iteration 193, loss = 60.97439111\n",
            "Iteration 194, loss = 60.97439816\n",
            "Iteration 195, loss = 60.97411996\n",
            "Iteration 196, loss = 60.97354543\n",
            "Iteration 197, loss = 60.97364133\n",
            "Iteration 198, loss = 60.97387801\n",
            "Iteration 199, loss = 60.97320872\n",
            "Iteration 200, loss = 60.97369186\n",
            "Iteration 201, loss = 60.97358535\n",
            "Iteration 202, loss = 60.97344040\n",
            "Iteration 203, loss = 60.97290258\n",
            "Iteration 204, loss = 60.97295923\n",
            "Iteration 205, loss = 60.97284726\n",
            "Iteration 206, loss = 60.97279873\n",
            "Iteration 207, loss = 60.97254730\n",
            "Iteration 208, loss = 60.97320395\n",
            "Iteration 209, loss = 60.97241015\n",
            "Iteration 210, loss = 60.97246068\n",
            "Iteration 211, loss = 60.97279551\n",
            "Iteration 212, loss = 60.97229651\n",
            "Iteration 213, loss = 60.97259353\n",
            "Iteration 214, loss = 60.97215246\n",
            "Iteration 215, loss = 60.97235728\n",
            "Iteration 216, loss = 60.97337591\n",
            "Iteration 217, loss = 60.97288776\n",
            "Iteration 218, loss = 60.97227555\n",
            "Iteration 219, loss = 60.97234907\n",
            "Iteration 220, loss = 60.97223491\n",
            "Iteration 221, loss = 60.97208208\n",
            "Iteration 222, loss = 60.97386590\n",
            "Iteration 223, loss = 60.97244039\n",
            "Iteration 224, loss = 60.97196948\n",
            "Iteration 225, loss = 60.97216072\n",
            "Iteration 226, loss = 60.97226663\n",
            "Iteration 227, loss = 60.97212999\n",
            "Iteration 228, loss = 60.97243984\n",
            "Iteration 229, loss = 60.97209310\n",
            "Iteration 230, loss = 60.97187573\n",
            "Iteration 231, loss = 60.97214353\n",
            "Iteration 232, loss = 60.97187180\n",
            "Iteration 233, loss = 60.97187156\n",
            "Iteration 234, loss = 60.97211006\n",
            "Iteration 235, loss = 60.97245189\n",
            "Iteration 236, loss = 60.97190272\n",
            "Iteration 237, loss = 60.97204785\n",
            "Iteration 238, loss = 60.97210610\n",
            "Iteration 239, loss = 60.97235299\n",
            "Iteration 240, loss = 60.97190855\n",
            "Iteration 241, loss = 60.97190291\n",
            "Iteration 242, loss = 60.97186658\n",
            "Iteration 243, loss = 60.97191010\n",
            "Iteration 244, loss = 60.97200931\n",
            "Iteration 245, loss = 60.97180231\n",
            "Iteration 246, loss = 60.97193017\n",
            "Iteration 247, loss = 60.97225998\n",
            "Iteration 248, loss = 60.97228002\n",
            "Iteration 249, loss = 60.97239352\n",
            "Iteration 250, loss = 60.97192759\n",
            "Iteration 251, loss = 60.97207195\n",
            "Iteration 252, loss = 60.97283864\n",
            "Iteration 253, loss = 60.97204138\n",
            "Iteration 254, loss = 60.97198296\n",
            "Iteration 255, loss = 60.97204454\n",
            "Iteration 256, loss = 60.97213640\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 81 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 129165.26916010\n",
            "Iteration 2, loss = 813.05331415\n",
            "Iteration 3, loss = 979.02784963\n",
            "Iteration 4, loss = 1128.78174884\n",
            "Iteration 5, loss = 1179.02390921\n",
            "Iteration 6, loss = 1081.57155107\n",
            "Iteration 7, loss = 1158.74043648\n",
            "Iteration 8, loss = 1252.68237388\n",
            "Iteration 9, loss = 1280.97572216\n",
            "Iteration 10, loss = 1335.37664337\n",
            "Iteration 11, loss = 1370.22578695\n",
            "Iteration 12, loss = 1395.15795983\n",
            "Iteration 13, loss = 1416.70333010\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 82 ------ \n",
            "[12, 24, 36, 49, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 49, 59, 14] [ 8 40 49 58 63 14] [49] [14] 7.0\n",
            "[12, 24, 36, 49, 59, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 36, 49, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 36, 49, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 36, 49, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 39.0 <------\n",
            "Iteration 1, loss = 44959.37417962\n",
            "Iteration 2, loss = 761.70073866\n",
            "Iteration 3, loss = 815.69882929\n",
            "Iteration 4, loss = 784.53180947\n",
            "Iteration 5, loss = 503.85572692\n",
            "Iteration 6, loss = 353.64346892\n",
            "Iteration 7, loss = 412.57861044\n",
            "Iteration 8, loss = 372.28132481\n",
            "Iteration 9, loss = 399.89204214\n",
            "Iteration 10, loss = 407.08900447\n",
            "Iteration 11, loss = 417.15963445\n",
            "Iteration 12, loss = 425.75863228\n",
            "Iteration 13, loss = 431.47247941\n",
            "Iteration 14, loss = 436.31201635\n",
            "Iteration 15, loss = 439.60936041\n",
            "Iteration 16, loss = 442.06323081\n",
            "Iteration 17, loss = 443.90744154\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 83 ------ \n",
            "[12, 24, 35, 48, 59, 13] [ 6 15 50 59 60 13] [59] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 35, 48, 59, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[12, 24, 35, 48, 59, 13] [ 2 23 40 59 69 13] [59] [13] 7.0\n",
            "[12, 24, 35, 48, 59, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "-----> Match Score: 39.0 <------\n",
            "Iteration 1, loss = 1008.27187996\n",
            "Iteration 2, loss = 703.53222727\n",
            "Iteration 3, loss = 683.32554241\n",
            "Iteration 4, loss = 658.79248506\n",
            "Iteration 5, loss = 631.77269391\n",
            "Iteration 6, loss = 603.46669217\n",
            "Iteration 7, loss = 574.74308184\n",
            "Iteration 8, loss = 546.38155172\n",
            "Iteration 9, loss = 518.34973934\n",
            "Iteration 10, loss = 491.35540078\n",
            "Iteration 11, loss = 465.37302633\n",
            "Iteration 12, loss = 440.78670354\n",
            "Iteration 13, loss = 417.21638578\n",
            "Iteration 14, loss = 394.99491144\n",
            "Iteration 15, loss = 374.09220992\n",
            "Iteration 16, loss = 354.37804539\n",
            "Iteration 17, loss = 335.74329908\n",
            "Iteration 18, loss = 318.29345183\n",
            "Iteration 19, loss = 301.91080669\n",
            "Iteration 20, loss = 286.47571998\n",
            "Iteration 21, loss = 272.15032169\n",
            "Iteration 22, loss = 258.70377360\n",
            "Iteration 23, loss = 245.86197504\n",
            "Iteration 24, loss = 234.04479682\n",
            "Iteration 25, loss = 223.02081760\n",
            "Iteration 26, loss = 212.63903888\n",
            "Iteration 27, loss = 202.83998580\n",
            "Iteration 28, loss = 193.81712662\n",
            "Iteration 29, loss = 185.24077452\n",
            "Iteration 30, loss = 177.29389089\n",
            "Iteration 31, loss = 169.85815215\n",
            "Iteration 32, loss = 162.86147824\n",
            "Iteration 33, loss = 156.30393452\n",
            "Iteration 34, loss = 150.16463914\n",
            "Iteration 35, loss = 144.49431936\n",
            "Iteration 36, loss = 139.13938015\n",
            "Iteration 37, loss = 134.08583906\n",
            "Iteration 38, loss = 129.40650044\n",
            "Iteration 39, loss = 125.06906308\n",
            "Iteration 40, loss = 120.91477436\n",
            "Iteration 41, loss = 117.04193748\n",
            "Iteration 42, loss = 113.43508923\n",
            "Iteration 43, loss = 110.12488261\n",
            "Iteration 44, loss = 106.97848775\n",
            "Iteration 45, loss = 104.04914618\n",
            "Iteration 46, loss = 101.25321852\n",
            "Iteration 47, loss = 98.62755347\n",
            "Iteration 48, loss = 96.26428315\n",
            "Iteration 49, loss = 93.98592829\n",
            "Iteration 50, loss = 91.85838065\n",
            "Iteration 51, loss = 89.87809640\n",
            "Iteration 52, loss = 88.02382581\n",
            "Iteration 53, loss = 86.28012208\n",
            "Iteration 54, loss = 84.64665390\n",
            "Iteration 55, loss = 83.13447424\n",
            "Iteration 56, loss = 81.75409060\n",
            "Iteration 57, loss = 80.39454307\n",
            "Iteration 58, loss = 79.13331726\n",
            "Iteration 59, loss = 77.98792274\n",
            "Iteration 60, loss = 76.86943970\n",
            "Iteration 61, loss = 75.86432973\n",
            "Iteration 62, loss = 74.90256994\n",
            "Iteration 63, loss = 74.00981756\n",
            "Iteration 64, loss = 73.18238108\n",
            "Iteration 65, loss = 72.40187374\n",
            "Iteration 66, loss = 71.65066754\n",
            "Iteration 67, loss = 70.97239521\n",
            "Iteration 68, loss = 70.34631168\n",
            "Iteration 69, loss = 69.73478158\n",
            "Iteration 70, loss = 69.16753387\n",
            "Iteration 71, loss = 68.63499281\n",
            "Iteration 72, loss = 68.15069904\n",
            "Iteration 73, loss = 67.67371737\n",
            "Iteration 74, loss = 67.26355158\n",
            "Iteration 75, loss = 66.84389021\n",
            "Iteration 76, loss = 66.47109242\n",
            "Iteration 77, loss = 66.12956822\n",
            "Iteration 78, loss = 65.78695744\n",
            "Iteration 79, loss = 65.47113286\n",
            "Iteration 80, loss = 65.18202995\n",
            "Iteration 81, loss = 64.91898815\n",
            "Iteration 82, loss = 64.66536035\n",
            "Iteration 83, loss = 64.42308089\n",
            "Iteration 84, loss = 64.20642996\n",
            "Iteration 85, loss = 63.99437962\n",
            "Iteration 86, loss = 63.78976435\n",
            "Iteration 87, loss = 63.62270415\n",
            "Iteration 88, loss = 63.45007812\n",
            "Iteration 89, loss = 63.29138894\n",
            "Iteration 90, loss = 63.13838908\n",
            "Iteration 91, loss = 63.00101451\n",
            "Iteration 92, loss = 62.86942066\n",
            "Iteration 93, loss = 62.75191657\n",
            "Iteration 94, loss = 62.63716102\n",
            "Iteration 95, loss = 62.53013947\n",
            "Iteration 96, loss = 62.43257837\n",
            "Iteration 97, loss = 62.33747814\n",
            "Iteration 98, loss = 62.25018690\n",
            "Iteration 99, loss = 62.17039666\n",
            "Iteration 100, loss = 62.09183040\n",
            "Iteration 101, loss = 62.02286434\n",
            "Iteration 102, loss = 61.95466564\n",
            "Iteration 103, loss = 61.89307820\n",
            "Iteration 104, loss = 61.83323226\n",
            "Iteration 105, loss = 61.78184835\n",
            "Iteration 106, loss = 61.72409168\n",
            "Iteration 107, loss = 61.67833492\n",
            "Iteration 108, loss = 61.63429944\n",
            "Iteration 109, loss = 61.59164564\n",
            "Iteration 110, loss = 61.55635638\n",
            "Iteration 111, loss = 61.51411972\n",
            "Iteration 112, loss = 61.48249743\n",
            "Iteration 113, loss = 61.44977674\n",
            "Iteration 114, loss = 61.41808327\n",
            "Iteration 115, loss = 61.38960321\n",
            "Iteration 116, loss = 61.36314919\n",
            "Iteration 117, loss = 61.33867136\n",
            "Iteration 118, loss = 61.31606471\n",
            "Iteration 119, loss = 61.29738337\n",
            "Iteration 120, loss = 61.27300959\n",
            "Iteration 121, loss = 61.25590689\n",
            "Iteration 122, loss = 61.23507189\n",
            "Iteration 123, loss = 61.22139586\n",
            "Iteration 124, loss = 61.20543552\n",
            "Iteration 125, loss = 61.19099687\n",
            "Iteration 126, loss = 61.17772861\n",
            "Iteration 127, loss = 61.16577679\n",
            "Iteration 128, loss = 61.15217872\n",
            "Iteration 129, loss = 61.14080810\n",
            "Iteration 130, loss = 61.13124383\n",
            "Iteration 131, loss = 61.12014965\n",
            "Iteration 132, loss = 61.11179300\n",
            "Iteration 133, loss = 61.10536793\n",
            "Iteration 134, loss = 61.09509267\n",
            "Iteration 135, loss = 61.08811325\n",
            "Iteration 136, loss = 61.08192842\n",
            "Iteration 137, loss = 61.07423900\n",
            "Iteration 138, loss = 61.06915265\n",
            "Iteration 139, loss = 61.06329093\n",
            "Iteration 140, loss = 61.05755635\n",
            "Iteration 141, loss = 61.05315753\n",
            "Iteration 142, loss = 61.04864382\n",
            "Iteration 143, loss = 61.04380367\n",
            "Iteration 144, loss = 61.03977207\n",
            "Iteration 145, loss = 61.03636636\n",
            "Iteration 146, loss = 61.03228061\n",
            "Iteration 147, loss = 61.02912656\n",
            "Iteration 148, loss = 61.02554123\n",
            "Iteration 149, loss = 61.02318688\n",
            "Iteration 150, loss = 61.02009510\n",
            "Iteration 151, loss = 61.01785010\n",
            "Iteration 152, loss = 61.01561443\n",
            "Iteration 153, loss = 61.01265708\n",
            "Iteration 154, loss = 61.01124200\n",
            "Iteration 155, loss = 61.00891876\n",
            "Iteration 156, loss = 61.00669672\n",
            "Iteration 157, loss = 61.00630995\n",
            "Iteration 158, loss = 61.00372724\n",
            "Iteration 159, loss = 61.00204541\n",
            "Iteration 160, loss = 61.00172656\n",
            "Iteration 161, loss = 60.99901677\n",
            "Iteration 162, loss = 60.99878393\n",
            "Iteration 163, loss = 60.99746865\n",
            "Iteration 164, loss = 60.99574231\n",
            "Iteration 165, loss = 60.99496796\n",
            "Iteration 166, loss = 60.99382982\n",
            "Iteration 167, loss = 60.99440042\n",
            "Iteration 168, loss = 60.99258797\n",
            "Iteration 169, loss = 60.99167546\n",
            "Iteration 170, loss = 60.99139798\n",
            "Iteration 171, loss = 60.99098105\n",
            "Iteration 172, loss = 60.98973339\n",
            "Iteration 173, loss = 60.98899113\n",
            "Iteration 174, loss = 60.98862542\n",
            "Iteration 175, loss = 60.99043658\n",
            "Iteration 176, loss = 60.98808403\n",
            "Iteration 177, loss = 60.98721180\n",
            "Iteration 178, loss = 60.98718564\n",
            "Iteration 179, loss = 60.98693392\n",
            "Iteration 180, loss = 60.98634569\n",
            "Iteration 181, loss = 60.98576575\n",
            "Iteration 182, loss = 60.98545152\n",
            "Iteration 183, loss = 60.98531363\n",
            "Iteration 184, loss = 60.98516170\n",
            "Iteration 185, loss = 60.98478353\n",
            "Iteration 186, loss = 60.98514328\n",
            "Iteration 187, loss = 60.98429470\n",
            "Iteration 188, loss = 60.98394856\n",
            "Iteration 189, loss = 60.98417511\n",
            "Iteration 190, loss = 60.98354489\n",
            "Iteration 191, loss = 60.98367466\n",
            "Iteration 192, loss = 60.98378118\n",
            "Iteration 193, loss = 60.98315551\n",
            "Iteration 194, loss = 60.98302098\n",
            "Iteration 195, loss = 60.98294681\n",
            "Iteration 196, loss = 60.98333510\n",
            "Iteration 197, loss = 60.98272639\n",
            "Iteration 198, loss = 60.98265622\n",
            "Iteration 199, loss = 60.98322724\n",
            "Iteration 200, loss = 60.98272445\n",
            "Iteration 201, loss = 60.98239765\n",
            "Iteration 202, loss = 60.98242811\n",
            "Iteration 203, loss = 60.98233426\n",
            "Iteration 204, loss = 60.98219229\n",
            "Iteration 205, loss = 60.98230068\n",
            "Iteration 206, loss = 60.98215721\n",
            "Iteration 207, loss = 60.98198960\n",
            "Iteration 208, loss = 60.98219566\n",
            "Iteration 209, loss = 60.98256061\n",
            "Iteration 210, loss = 60.98204272\n",
            "Iteration 211, loss = 60.98207107\n",
            "Iteration 212, loss = 60.98170947\n",
            "Iteration 213, loss = 60.98182886\n",
            "Iteration 214, loss = 60.98174209\n",
            "Iteration 215, loss = 60.98174835\n",
            "Iteration 216, loss = 60.98177185\n",
            "Iteration 217, loss = 60.98164290\n",
            "Iteration 218, loss = 60.98169916\n",
            "Iteration 219, loss = 60.98182490\n",
            "Iteration 220, loss = 60.98144695\n",
            "Iteration 221, loss = 60.98131867\n",
            "Iteration 222, loss = 60.98139497\n",
            "Iteration 223, loss = 60.98157428\n",
            "Iteration 224, loss = 60.98118367\n",
            "Iteration 225, loss = 60.98147429\n",
            "Iteration 226, loss = 60.98131405\n",
            "Iteration 227, loss = 60.98107456\n",
            "Iteration 228, loss = 60.98167760\n",
            "Iteration 229, loss = 60.98103687\n",
            "Iteration 230, loss = 60.98123175\n",
            "Iteration 231, loss = 60.98127625\n",
            "Iteration 232, loss = 60.98142042\n",
            "Iteration 233, loss = 60.98109543\n",
            "Iteration 234, loss = 60.98100198\n",
            "Iteration 235, loss = 60.98099787\n",
            "Iteration 236, loss = 60.98133617\n",
            "Iteration 237, loss = 60.98134122\n",
            "Iteration 238, loss = 60.98115045\n",
            "Iteration 239, loss = 60.98143513\n",
            "Iteration 240, loss = 60.98102393\n",
            "Iteration 241, loss = 60.98195655\n",
            "Iteration 242, loss = 60.98114223\n",
            "Iteration 243, loss = 60.98102535\n",
            "Iteration 244, loss = 60.98103230\n",
            "Iteration 245, loss = 60.98105120\n",
            "Iteration 246, loss = 60.98101259\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 84 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 9314491.93532154\n",
            "Iteration 2, loss = 58672.16699158\n",
            "Iteration 3, loss = 130254.90646862\n",
            "Iteration 4, loss = 202020.37305244\n",
            "Iteration 5, loss = 264581.03173743\n",
            "Iteration 6, loss = 315804.43445346\n",
            "Iteration 7, loss = 356040.92619875\n",
            "Iteration 8, loss = 386910.84676963\n",
            "Iteration 9, loss = 410232.08377182\n",
            "Iteration 10, loss = 427667.26890576\n",
            "Iteration 11, loss = 440608.14494461\n",
            "Iteration 12, loss = 450164.83348023\n",
            "Iteration 13, loss = 457196.26147401\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 85 ------ \n",
            "[13, 24, 36, 48, 59, 13] [ 6 15 50 59 60 13] [59] [13] 7.0\n",
            "[13, 24, 36, 48, 59, 13] [12 33 54 57 60 13] [] [13] 6.0\n",
            "[13, 24, 36, 48, 59, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[13, 24, 36, 48, 59, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[13, 24, 36, 48, 59, 13] [ 2 23 40 59 69 13] [59] [13] 7.0\n",
            "[13, 24, 36, 48, 59, 13] [ 1  7 45 47 69 13] [] [13] 6.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 503689.42006442\n",
            "Iteration 2, loss = 1564.03307927\n",
            "Iteration 3, loss = 2515.06817527\n",
            "Iteration 4, loss = 3426.79622608\n",
            "Iteration 5, loss = 4199.19950770\n",
            "Iteration 6, loss = 4811.53115552\n",
            "Iteration 7, loss = 5276.64543083\n",
            "Iteration 8, loss = 5618.66413349\n",
            "Iteration 9, loss = 5862.96477322\n",
            "Iteration 10, loss = 6032.00784081\n",
            "Iteration 11, loss = 6145.01411333\n",
            "Iteration 12, loss = 6216.13268983\n",
            "Iteration 13, loss = 6257.25156393\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 86 ------ \n",
            "[0, -9, -3, 6, -6, 12] [20 33 36 47 52 12] [] [12] 6.0\n",
            "[0, -9, -3, 6, -6, 12] [ 1 10 27 28 36 12] [] [12] 6.0\n",
            "[0, -9, -3, 6, -6, 12] [17 18 39 56 64 12] [] [12] 6.0\n",
            "[0, -9, -3, 6, -6, 12] [19 37 48 61 63 12] [] [12] 6.0\n",
            "[0, -9, -3, 6, -6, 12] [ 8 12 42 46 56 12] [] [12] 6.0\n",
            "[0, -9, -3, 6, -6, 12] [23 56 61 64 67 12] [] [12] 6.0\n",
            "[0, -9, -3, 6, -6, 12] [23 30 33 40 69 12] [] [12] 6.0\n",
            "[0, -9, -3, 6, -6, 12] [ 1 28 40 45 48 12] [] [12] 6.0\n",
            "-----> Match Score: 48.0 <------\n",
            "Iteration 1, loss = 71965.19757223\n",
            "Iteration 2, loss = 276.89926135\n",
            "Iteration 3, loss = 248.09089557\n",
            "Iteration 4, loss = 283.10256018\n",
            "Iteration 5, loss = 337.23906812\n",
            "Iteration 6, loss = 465.01348136\n",
            "Iteration 7, loss = 1048.23506365\n",
            "Iteration 8, loss = 953.06927334\n",
            "Iteration 9, loss = 957.31442031\n",
            "Iteration 10, loss = 952.64194079\n",
            "Iteration 11, loss = 941.66232639\n",
            "Iteration 12, loss = 926.49152337\n",
            "Iteration 13, loss = 908.55429312\n",
            "Iteration 14, loss = 889.00744876\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 87 ------ \n",
            "[-3, 1, 5, 12, 15, 10] [ 8 25 34 38 41 10] [] [10] 6.0\n",
            "[-3, 1, 5, 12, 15, 10] [24 29 42 44 63 10] [] [10] 6.0\n",
            "[-3, 1, 5, 12, 15, 10] [ 9 43 57 60 64 10] [] [10] 6.0\n",
            "[-3, 1, 5, 12, 15, 10] [19 43 47 60 68 10] [] [10] 6.0\n",
            "[-3, 1, 5, 12, 15, 10] [ 7 10 63 64 68 10] [] [10] 6.0\n",
            "[-3, 1, 5, 12, 15, 10] [14 32 34 46 61 10] [] [10] 6.0\n",
            "[-3, 1, 5, 12, 15, 10] [ 5  6 15 29 42 10] [5, 15] [10] 9.0\n",
            "-----> Match Score: 45.0 <------\n",
            "Iteration 1, loss = 1501.82811515\n",
            "Iteration 2, loss = 689.93560656\n",
            "Iteration 3, loss = 669.50620547\n",
            "Iteration 4, loss = 645.22659395\n",
            "Iteration 5, loss = 618.54530315\n",
            "Iteration 6, loss = 590.65601264\n",
            "Iteration 7, loss = 562.45466724\n",
            "Iteration 8, loss = 534.59810169\n",
            "Iteration 9, loss = 507.26869910\n",
            "Iteration 10, loss = 480.81062774\n",
            "Iteration 11, loss = 455.68683846\n",
            "Iteration 12, loss = 431.45179520\n",
            "Iteration 13, loss = 408.50613513\n",
            "Iteration 14, loss = 386.82461842\n",
            "Iteration 15, loss = 366.39256788\n",
            "Iteration 16, loss = 347.07527578\n",
            "Iteration 17, loss = 328.94735652\n",
            "Iteration 18, loss = 312.08789209\n",
            "Iteration 19, loss = 296.09310131\n",
            "Iteration 20, loss = 281.00189277\n",
            "Iteration 21, loss = 266.97061680\n",
            "Iteration 22, loss = 253.73567986\n",
            "Iteration 23, loss = 241.44684537\n",
            "Iteration 24, loss = 229.89029953\n",
            "Iteration 25, loss = 219.09860291\n",
            "Iteration 26, loss = 208.95085235\n",
            "Iteration 27, loss = 199.47021888\n",
            "Iteration 28, loss = 190.54861601\n",
            "Iteration 29, loss = 182.25075759\n",
            "Iteration 30, loss = 174.46927477\n",
            "Iteration 31, loss = 167.13717265\n",
            "Iteration 32, loss = 160.37382343\n",
            "Iteration 33, loss = 153.92899447\n",
            "Iteration 34, loss = 148.06122084\n",
            "Iteration 35, loss = 142.40665488\n",
            "Iteration 36, loss = 137.19904376\n",
            "Iteration 37, loss = 132.28647788\n",
            "Iteration 38, loss = 127.69849294\n",
            "Iteration 39, loss = 123.46232875\n",
            "Iteration 40, loss = 119.40207034\n",
            "Iteration 41, loss = 115.66221714\n",
            "Iteration 42, loss = 112.08569913\n",
            "Iteration 43, loss = 108.82490548\n",
            "Iteration 44, loss = 105.83473821\n",
            "Iteration 45, loss = 102.90094007\n",
            "Iteration 46, loss = 100.21205439\n",
            "Iteration 47, loss = 97.72013234\n",
            "Iteration 48, loss = 95.34149993\n",
            "Iteration 49, loss = 93.10716261\n",
            "Iteration 50, loss = 91.04313423\n",
            "Iteration 51, loss = 89.14281568\n",
            "Iteration 52, loss = 87.33786831\n",
            "Iteration 53, loss = 85.63781923\n",
            "Iteration 54, loss = 84.03536552\n",
            "Iteration 55, loss = 82.57625801\n",
            "Iteration 56, loss = 81.17793554\n",
            "Iteration 57, loss = 79.87392779\n",
            "Iteration 58, loss = 78.65848391\n",
            "Iteration 59, loss = 77.55110808\n",
            "Iteration 60, loss = 76.46772569\n",
            "Iteration 61, loss = 75.48547915\n",
            "Iteration 62, loss = 74.54588466\n",
            "Iteration 63, loss = 73.67336717\n",
            "Iteration 64, loss = 72.86619288\n",
            "Iteration 65, loss = 72.09099605\n",
            "Iteration 66, loss = 71.40209224\n",
            "Iteration 67, loss = 70.71263135\n",
            "Iteration 68, loss = 70.10006613\n",
            "Iteration 69, loss = 69.52697251\n",
            "Iteration 70, loss = 68.95337602\n",
            "Iteration 71, loss = 68.46394042\n",
            "Iteration 72, loss = 67.97773227\n",
            "Iteration 73, loss = 67.53060848\n",
            "Iteration 74, loss = 67.10812003\n",
            "Iteration 75, loss = 66.72082009\n",
            "Iteration 76, loss = 66.36443437\n",
            "Iteration 77, loss = 66.00978849\n",
            "Iteration 78, loss = 65.68792845\n",
            "Iteration 79, loss = 65.39078152\n",
            "Iteration 80, loss = 65.10938717\n",
            "Iteration 81, loss = 64.83649955\n",
            "Iteration 82, loss = 64.61376326\n",
            "Iteration 83, loss = 64.37243884\n",
            "Iteration 84, loss = 64.15536455\n",
            "Iteration 85, loss = 63.95709810\n",
            "Iteration 86, loss = 63.77146586\n",
            "Iteration 87, loss = 63.60104218\n",
            "Iteration 88, loss = 63.42245666\n",
            "Iteration 89, loss = 63.27938088\n",
            "Iteration 90, loss = 63.13176953\n",
            "Iteration 91, loss = 62.99360172\n",
            "Iteration 92, loss = 62.86805219\n",
            "Iteration 93, loss = 62.75338714\n",
            "Iteration 94, loss = 62.64108759\n",
            "Iteration 95, loss = 62.53837739\n",
            "Iteration 96, loss = 62.44042331\n",
            "Iteration 97, loss = 62.35135352\n",
            "Iteration 98, loss = 62.25938549\n",
            "Iteration 99, loss = 62.18227851\n",
            "Iteration 100, loss = 62.11349991\n",
            "Iteration 101, loss = 62.03967479\n",
            "Iteration 102, loss = 61.97807067\n",
            "Iteration 103, loss = 61.91645102\n",
            "Iteration 104, loss = 61.85811037\n",
            "Iteration 105, loss = 61.80179926\n",
            "Iteration 106, loss = 61.75579373\n",
            "Iteration 107, loss = 61.70659280\n",
            "Iteration 108, loss = 61.66219637\n",
            "Iteration 109, loss = 61.62843800\n",
            "Iteration 110, loss = 61.59163266\n",
            "Iteration 111, loss = 61.54712319\n",
            "Iteration 112, loss = 61.51686739\n",
            "Iteration 113, loss = 61.48842957\n",
            "Iteration 114, loss = 61.45447196\n",
            "Iteration 115, loss = 61.42916249\n",
            "Iteration 116, loss = 61.40404827\n",
            "Iteration 117, loss = 61.38329973\n",
            "Iteration 118, loss = 61.35645030\n",
            "Iteration 119, loss = 61.34397948\n",
            "Iteration 120, loss = 61.31420713\n",
            "Iteration 121, loss = 61.29879864\n",
            "Iteration 122, loss = 61.28090946\n",
            "Iteration 123, loss = 61.26459140\n",
            "Iteration 124, loss = 61.25191607\n",
            "Iteration 125, loss = 61.23400317\n",
            "Iteration 126, loss = 61.22215193\n",
            "Iteration 127, loss = 61.20931053\n",
            "Iteration 128, loss = 61.19955140\n",
            "Iteration 129, loss = 61.18818184\n",
            "Iteration 130, loss = 61.17549931\n",
            "Iteration 131, loss = 61.16756879\n",
            "Iteration 132, loss = 61.15847871\n",
            "Iteration 133, loss = 61.15035165\n",
            "Iteration 134, loss = 61.14200049\n",
            "Iteration 135, loss = 61.13537420\n",
            "Iteration 136, loss = 61.12892814\n",
            "Iteration 137, loss = 61.12008675\n",
            "Iteration 138, loss = 61.11689052\n",
            "Iteration 139, loss = 61.11143611\n",
            "Iteration 140, loss = 61.10593820\n",
            "Iteration 141, loss = 61.09918480\n",
            "Iteration 142, loss = 61.09466592\n",
            "Iteration 143, loss = 61.09179032\n",
            "Iteration 144, loss = 61.08620569\n",
            "Iteration 145, loss = 61.08425738\n",
            "Iteration 146, loss = 61.08004658\n",
            "Iteration 147, loss = 61.07600920\n",
            "Iteration 148, loss = 61.07295134\n",
            "Iteration 149, loss = 61.07120584\n",
            "Iteration 150, loss = 61.06762262\n",
            "Iteration 151, loss = 61.06525707\n",
            "Iteration 152, loss = 61.06355584\n",
            "Iteration 153, loss = 61.06002186\n",
            "Iteration 154, loss = 61.05787225\n",
            "Iteration 155, loss = 61.05633443\n",
            "Iteration 156, loss = 61.05508059\n",
            "Iteration 157, loss = 61.05316725\n",
            "Iteration 158, loss = 61.05107444\n",
            "Iteration 159, loss = 61.04973437\n",
            "Iteration 160, loss = 61.04934478\n",
            "Iteration 161, loss = 61.04701233\n",
            "Iteration 162, loss = 61.04658214\n",
            "Iteration 163, loss = 61.04518306\n",
            "Iteration 164, loss = 61.04384860\n",
            "Iteration 165, loss = 61.04262021\n",
            "Iteration 166, loss = 61.04202877\n",
            "Iteration 167, loss = 61.04113160\n",
            "Iteration 168, loss = 61.04033613\n",
            "Iteration 169, loss = 61.04010363\n",
            "Iteration 170, loss = 61.03884639\n",
            "Iteration 171, loss = 61.03823096\n",
            "Iteration 172, loss = 61.03825772\n",
            "Iteration 173, loss = 61.03721605\n",
            "Iteration 174, loss = 61.03734629\n",
            "Iteration 175, loss = 61.03598224\n",
            "Iteration 176, loss = 61.03604397\n",
            "Iteration 177, loss = 61.03524161\n",
            "Iteration 178, loss = 61.03512352\n",
            "Iteration 179, loss = 61.03453269\n",
            "Iteration 180, loss = 61.03510003\n",
            "Iteration 181, loss = 61.03416639\n",
            "Iteration 182, loss = 61.03349141\n",
            "Iteration 183, loss = 61.03392509\n",
            "Iteration 184, loss = 61.03301422\n",
            "Iteration 185, loss = 61.03305717\n",
            "Iteration 186, loss = 61.03248451\n",
            "Iteration 187, loss = 61.03218734\n",
            "Iteration 188, loss = 61.03229003\n",
            "Iteration 189, loss = 61.03258052\n",
            "Iteration 190, loss = 61.03167275\n",
            "Iteration 191, loss = 61.03145783\n",
            "Iteration 192, loss = 61.03129183\n",
            "Iteration 193, loss = 61.03130401\n",
            "Iteration 194, loss = 61.03089543\n",
            "Iteration 195, loss = 61.03087756\n",
            "Iteration 196, loss = 61.03058528\n",
            "Iteration 197, loss = 61.03105172\n",
            "Iteration 198, loss = 61.03068556\n",
            "Iteration 199, loss = 61.03037085\n",
            "Iteration 200, loss = 61.03029658\n",
            "Iteration 201, loss = 61.03017661\n",
            "Iteration 202, loss = 61.03045397\n",
            "Iteration 203, loss = 61.03010830\n",
            "Iteration 204, loss = 61.02981883\n",
            "Iteration 205, loss = 61.02973916\n",
            "Iteration 206, loss = 61.03017164\n",
            "Iteration 207, loss = 61.02959491\n",
            "Iteration 208, loss = 61.02978314\n",
            "Iteration 209, loss = 61.02980832\n",
            "Iteration 210, loss = 61.02955821\n",
            "Iteration 211, loss = 61.03001049\n",
            "Iteration 212, loss = 61.03045815\n",
            "Iteration 213, loss = 61.02979852\n",
            "Iteration 214, loss = 61.02993686\n",
            "Iteration 215, loss = 61.02953916\n",
            "Iteration 216, loss = 61.02956343\n",
            "Iteration 217, loss = 61.02945975\n",
            "Iteration 218, loss = 61.02915482\n",
            "Iteration 219, loss = 61.02990812\n",
            "Iteration 220, loss = 61.02985648\n",
            "Iteration 221, loss = 61.03018968\n",
            "Iteration 222, loss = 61.02902668\n",
            "Iteration 223, loss = 61.02915522\n",
            "Iteration 224, loss = 61.02981764\n",
            "Iteration 225, loss = 61.02928436\n",
            "Iteration 226, loss = 61.02944593\n",
            "Iteration 227, loss = 61.02918978\n",
            "Iteration 228, loss = 61.02967968\n",
            "Iteration 229, loss = 61.03016623\n",
            "Iteration 230, loss = 61.02906166\n",
            "Iteration 231, loss = 61.02916913\n",
            "Iteration 232, loss = 61.02903400\n",
            "Iteration 233, loss = 61.02921523\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 88 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 717.19919739\n",
            "Iteration 2, loss = 654.91930870\n",
            "Iteration 3, loss = 892879.78261190\n",
            "Iteration 4, loss = 2830.70222738\n",
            "Iteration 5, loss = 4627.52252509\n",
            "Iteration 6, loss = 6277.62498576\n",
            "Iteration 7, loss = 7650.33999579\n",
            "Iteration 8, loss = 8731.60691563\n",
            "Iteration 9, loss = 9553.35120420\n",
            "Iteration 10, loss = 10161.50590710\n",
            "Iteration 11, loss = 10601.73534958\n",
            "Iteration 12, loss = 10912.92293151\n",
            "Iteration 13, loss = 11127.60520128\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 89 ------ \n",
            "-----> Match Score: 0 <------\n",
            "Iteration 1, loss = 5664820.56279873\n",
            "Iteration 2, loss = 19623.68234162\n",
            "Iteration 3, loss = 42184.28093604\n",
            "Iteration 4, loss = 65160.96211882\n",
            "Iteration 5, loss = 85165.26328106\n",
            "Iteration 6, loss = 101634.75401245\n",
            "Iteration 7, loss = 114570.15520631\n",
            "Iteration 8, loss = 124499.98141560\n",
            "Iteration 9, loss = 132001.52328615\n",
            "Iteration 10, loss = 137609.45593006\n",
            "Iteration 11, loss = 141772.11813499\n",
            "Iteration 12, loss = 144846.38846187\n",
            "Iteration 13, loss = 147108.62532203\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 90 ------ \n",
            "[12, 24, 36, 48, 59, 14] [16 25 36 44 55 14] [36] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 36, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 36, 48, 59, 14] [19 31 35 50 67 14] [] [14] 6.0\n",
            "-----> Match Score: 39.0 <------\n",
            "Iteration 1, loss = 2325.54814789\n",
            "Iteration 2, loss = 395.26849405\n",
            "Iteration 3, loss = 325.68105129\n",
            "Iteration 4, loss = 562.61876843\n",
            "Iteration 5, loss = 663.32771964\n",
            "Iteration 6, loss = 630.62217956\n",
            "Iteration 7, loss = 552.01306846\n",
            "Iteration 8, loss = 332.50074927\n",
            "Iteration 9, loss = 87.74397252\n",
            "Iteration 10, loss = 139.74455631\n",
            "Iteration 11, loss = 72.59843499\n",
            "Iteration 12, loss = 67.59422193\n",
            "Iteration 13, loss = 68.69900659\n",
            "Iteration 14, loss = 61.97387597\n",
            "Iteration 15, loss = 62.83810198\n",
            "Iteration 16, loss = 61.94236342\n",
            "Iteration 17, loss = 61.51283943\n",
            "Iteration 18, loss = 61.71215954\n",
            "Iteration 19, loss = 61.47811934\n",
            "Iteration 20, loss = 61.49741363\n",
            "Iteration 21, loss = 61.48993002\n",
            "Iteration 22, loss = 61.47961835\n",
            "Iteration 23, loss = 61.43958714\n",
            "Iteration 24, loss = 61.42767846\n",
            "Iteration 25, loss = 61.49033211\n",
            "Iteration 26, loss = 61.46589700\n",
            "Iteration 27, loss = 61.45181592\n",
            "Iteration 28, loss = 61.48485934\n",
            "Iteration 29, loss = 61.47877590\n",
            "Iteration 30, loss = 61.47589733\n",
            "Iteration 31, loss = 61.48310366\n",
            "Iteration 32, loss = 61.47476570\n",
            "Iteration 33, loss = 61.44294632\n",
            "Iteration 34, loss = 61.44706452\n",
            "Iteration 35, loss = 61.42963274\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 91 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 4945.19398831\n",
            "Iteration 2, loss = 716.85030401\n",
            "Iteration 3, loss = 706.22208906\n",
            "Iteration 4, loss = 691.80239074\n",
            "Iteration 5, loss = 672.40758914\n",
            "Iteration 6, loss = 649.61560979\n",
            "Iteration 7, loss = 624.61611152\n",
            "Iteration 8, loss = 598.54140646\n",
            "Iteration 9, loss = 572.08600860\n",
            "Iteration 10, loss = 545.63207606\n",
            "Iteration 11, loss = 519.81345110\n",
            "Iteration 12, loss = 494.98675052\n",
            "Iteration 13, loss = 470.83306583\n",
            "Iteration 14, loss = 447.92493950\n",
            "Iteration 15, loss = 426.24220704\n",
            "Iteration 16, loss = 405.55243799\n",
            "Iteration 17, loss = 386.09500950\n",
            "Iteration 18, loss = 367.88225920\n",
            "Iteration 19, loss = 350.59988189\n",
            "Iteration 20, loss = 334.27837038\n",
            "Iteration 21, loss = 319.15543653\n",
            "Iteration 22, loss = 304.76044656\n",
            "Iteration 23, loss = 291.50783007\n",
            "Iteration 24, loss = 278.81056599\n",
            "Iteration 25, loss = 267.15285382\n",
            "Iteration 26, loss = 256.10524709\n",
            "Iteration 27, loss = 245.81602871\n",
            "Iteration 28, loss = 236.16924819\n",
            "Iteration 29, loss = 227.10732976\n",
            "Iteration 30, loss = 218.62794682\n",
            "Iteration 31, loss = 210.77505640\n",
            "Iteration 32, loss = 203.34885496\n",
            "Iteration 33, loss = 196.38621968\n",
            "Iteration 34, loss = 189.91289924\n",
            "Iteration 35, loss = 183.84723725\n",
            "Iteration 36, loss = 178.18388740\n",
            "Iteration 37, loss = 172.86313146\n",
            "Iteration 38, loss = 167.85539741\n",
            "Iteration 39, loss = 163.18826822\n",
            "Iteration 40, loss = 158.86197133\n",
            "Iteration 41, loss = 154.77237852\n",
            "Iteration 42, loss = 150.99102989\n",
            "Iteration 43, loss = 147.43449416\n",
            "Iteration 44, loss = 144.08676765\n",
            "Iteration 45, loss = 140.94699417\n",
            "Iteration 46, loss = 137.97438378\n",
            "Iteration 47, loss = 135.26311074\n",
            "Iteration 48, loss = 132.72803869\n",
            "Iteration 49, loss = 130.36890279\n",
            "Iteration 50, loss = 128.07467585\n",
            "Iteration 51, loss = 125.98117913\n",
            "Iteration 52, loss = 124.02646780\n",
            "Iteration 53, loss = 122.19497966\n",
            "Iteration 54, loss = 120.44928606\n",
            "Iteration 55, loss = 118.84876993\n",
            "Iteration 56, loss = 117.33429754\n",
            "Iteration 57, loss = 115.92879750\n",
            "Iteration 58, loss = 114.64455420\n",
            "Iteration 59, loss = 113.35842806\n",
            "Iteration 60, loss = 112.20967792\n",
            "Iteration 61, loss = 111.14923382\n",
            "Iteration 62, loss = 110.12938646\n",
            "Iteration 63, loss = 109.18806466\n",
            "Iteration 64, loss = 108.28892133\n",
            "Iteration 65, loss = 107.45740200\n",
            "Iteration 66, loss = 106.68688948\n",
            "Iteration 67, loss = 105.96928559\n",
            "Iteration 68, loss = 105.27431897\n",
            "Iteration 69, loss = 104.64769141\n",
            "Iteration 70, loss = 104.05769746\n",
            "Iteration 71, loss = 103.48719471\n",
            "Iteration 72, loss = 102.97511810\n",
            "Iteration 73, loss = 102.47709915\n",
            "Iteration 74, loss = 102.04775699\n",
            "Iteration 75, loss = 101.60986691\n",
            "Iteration 76, loss = 101.21903209\n",
            "Iteration 77, loss = 100.84339182\n",
            "Iteration 78, loss = 100.49666655\n",
            "Iteration 79, loss = 100.17400941\n",
            "Iteration 80, loss = 99.87065686\n",
            "Iteration 81, loss = 99.58302657\n",
            "Iteration 82, loss = 99.31388178\n",
            "Iteration 83, loss = 99.06268330\n",
            "Iteration 84, loss = 98.82258015\n",
            "Iteration 85, loss = 98.60827278\n",
            "Iteration 86, loss = 98.41679511\n",
            "Iteration 87, loss = 98.20775154\n",
            "Iteration 88, loss = 98.03615266\n",
            "Iteration 89, loss = 97.86365523\n",
            "Iteration 90, loss = 97.71522215\n",
            "Iteration 91, loss = 97.56419349\n",
            "Iteration 92, loss = 97.42401686\n",
            "Iteration 93, loss = 97.29292699\n",
            "Iteration 94, loss = 97.16872229\n",
            "Iteration 95, loss = 97.05987081\n",
            "Iteration 96, loss = 96.94994132\n",
            "Iteration 97, loss = 96.86210499\n",
            "Iteration 98, loss = 96.75892559\n",
            "Iteration 99, loss = 96.67263548\n",
            "Iteration 100, loss = 96.59226548\n",
            "Iteration 101, loss = 96.52724031\n",
            "Iteration 102, loss = 96.44217129\n",
            "Iteration 103, loss = 96.38274249\n",
            "Iteration 104, loss = 96.32180450\n",
            "Iteration 105, loss = 96.25722543\n",
            "Iteration 106, loss = 96.21078078\n",
            "Iteration 107, loss = 96.15664483\n",
            "Iteration 108, loss = 96.11140265\n",
            "Iteration 109, loss = 96.06074798\n",
            "Iteration 110, loss = 96.02531031\n",
            "Iteration 111, loss = 95.98462315\n",
            "Iteration 112, loss = 95.94991169\n",
            "Iteration 113, loss = 95.91779558\n",
            "Iteration 114, loss = 95.88548550\n",
            "Iteration 115, loss = 95.85255084\n",
            "Iteration 116, loss = 95.82801899\n",
            "Iteration 117, loss = 95.80212206\n",
            "Iteration 118, loss = 95.77220293\n",
            "Iteration 119, loss = 95.75169723\n",
            "Iteration 120, loss = 95.73159841\n",
            "Iteration 121, loss = 95.71196743\n",
            "Iteration 122, loss = 95.69445463\n",
            "Iteration 123, loss = 95.67469965\n",
            "Iteration 124, loss = 95.65911776\n",
            "Iteration 125, loss = 95.64038186\n",
            "Iteration 126, loss = 95.62797866\n",
            "Iteration 127, loss = 95.61439248\n",
            "Iteration 128, loss = 95.60203947\n",
            "Iteration 129, loss = 95.59296365\n",
            "Iteration 130, loss = 95.58002762\n",
            "Iteration 131, loss = 95.56875154\n",
            "Iteration 132, loss = 95.56075818\n",
            "Iteration 133, loss = 95.54875156\n",
            "Iteration 134, loss = 95.54358076\n",
            "Iteration 135, loss = 95.53525522\n",
            "Iteration 136, loss = 95.52827712\n",
            "Iteration 137, loss = 95.52097423\n",
            "Iteration 138, loss = 95.51370609\n",
            "Iteration 139, loss = 95.50923501\n",
            "Iteration 140, loss = 95.50250594\n",
            "Iteration 141, loss = 95.49652133\n",
            "Iteration 142, loss = 95.49289969\n",
            "Iteration 143, loss = 95.48974216\n",
            "Iteration 144, loss = 95.48366205\n",
            "Iteration 145, loss = 95.48047618\n",
            "Iteration 146, loss = 95.47634346\n",
            "Iteration 147, loss = 95.47227364\n",
            "Iteration 148, loss = 95.46995827\n",
            "Iteration 149, loss = 95.46748833\n",
            "Iteration 150, loss = 95.46326618\n",
            "Iteration 151, loss = 95.46110682\n",
            "Iteration 152, loss = 95.45840011\n",
            "Iteration 153, loss = 95.45753126\n",
            "Iteration 154, loss = 95.45523647\n",
            "Iteration 155, loss = 95.45171456\n",
            "Iteration 156, loss = 95.45051169\n",
            "Iteration 157, loss = 95.44811700\n",
            "Iteration 158, loss = 95.44641470\n",
            "Iteration 159, loss = 95.44611969\n",
            "Iteration 160, loss = 95.44302024\n",
            "Iteration 161, loss = 95.44177192\n",
            "Iteration 162, loss = 95.44156579\n",
            "Iteration 163, loss = 95.43890095\n",
            "Iteration 164, loss = 95.43762686\n",
            "Iteration 165, loss = 95.43647818\n",
            "Iteration 166, loss = 95.43558463\n",
            "Iteration 167, loss = 95.43479525\n",
            "Iteration 168, loss = 95.43347556\n",
            "Iteration 169, loss = 95.43301279\n",
            "Iteration 170, loss = 95.43189194\n",
            "Iteration 171, loss = 95.43121917\n",
            "Iteration 172, loss = 95.43106298\n",
            "Iteration 173, loss = 95.42960221\n",
            "Iteration 174, loss = 95.42939158\n",
            "Iteration 175, loss = 95.42879973\n",
            "Iteration 176, loss = 95.42787414\n",
            "Iteration 177, loss = 95.42754394\n",
            "Iteration 178, loss = 95.42686277\n",
            "Iteration 179, loss = 95.42668491\n",
            "Iteration 180, loss = 95.42670507\n",
            "Iteration 181, loss = 95.42603796\n",
            "Iteration 182, loss = 95.42623994\n",
            "Iteration 183, loss = 95.42538306\n",
            "Iteration 184, loss = 95.42547384\n",
            "Iteration 185, loss = 95.42449185\n",
            "Iteration 186, loss = 95.42430240\n",
            "Iteration 187, loss = 95.42474471\n",
            "Iteration 188, loss = 95.42387277\n",
            "Iteration 189, loss = 95.42375013\n",
            "Iteration 190, loss = 95.42457315\n",
            "Iteration 191, loss = 95.42409258\n",
            "Iteration 192, loss = 95.42303357\n",
            "Iteration 193, loss = 95.42311218\n",
            "Iteration 194, loss = 95.42307804\n",
            "Iteration 195, loss = 95.42307037\n",
            "Iteration 196, loss = 95.42256887\n",
            "Iteration 197, loss = 95.42252187\n",
            "Iteration 198, loss = 95.42235365\n",
            "Iteration 199, loss = 95.42257913\n",
            "Iteration 200, loss = 95.42259282\n",
            "Iteration 201, loss = 95.42253288\n",
            "Iteration 202, loss = 95.42196942\n",
            "Iteration 203, loss = 95.42219970\n",
            "Iteration 204, loss = 95.42165738\n",
            "Iteration 205, loss = 95.42342964\n",
            "Iteration 206, loss = 95.42174558\n",
            "Iteration 207, loss = 95.42152597\n",
            "Iteration 208, loss = 95.42161004\n",
            "Iteration 209, loss = 95.42162999\n",
            "Iteration 210, loss = 95.42137536\n",
            "Iteration 211, loss = 95.42185910\n",
            "Iteration 212, loss = 95.42120951\n",
            "Iteration 213, loss = 95.42134143\n",
            "Iteration 214, loss = 95.42112443\n",
            "Iteration 215, loss = 95.42136708\n",
            "Iteration 216, loss = 95.42129772\n",
            "Iteration 217, loss = 95.42139355\n",
            "Iteration 218, loss = 95.42105198\n",
            "Iteration 219, loss = 95.42145447\n",
            "Iteration 220, loss = 95.42094793\n",
            "Iteration 221, loss = 95.42085364\n",
            "Iteration 222, loss = 95.42107641\n",
            "Iteration 223, loss = 95.42087258\n",
            "Iteration 224, loss = 95.42130974\n",
            "Iteration 225, loss = 95.42080456\n",
            "Iteration 226, loss = 95.42156454\n",
            "Iteration 227, loss = 95.42075032\n",
            "Iteration 228, loss = 95.42072762\n",
            "Iteration 229, loss = 95.42085783\n",
            "Iteration 230, loss = 95.42068177\n",
            "Iteration 231, loss = 95.42070138\n",
            "Iteration 232, loss = 95.42052683\n",
            "Iteration 233, loss = 95.42115564\n",
            "Iteration 234, loss = 95.42079390\n",
            "Iteration 235, loss = 95.42054223\n",
            "Iteration 236, loss = 95.42061423\n",
            "Iteration 237, loss = 95.42066822\n",
            "Iteration 238, loss = 95.42060870\n",
            "Iteration 239, loss = 95.42035084\n",
            "Iteration 240, loss = 95.42107671\n",
            "Iteration 241, loss = 95.42058214\n",
            "Iteration 242, loss = 95.42055693\n",
            "Iteration 243, loss = 95.42047187\n",
            "Iteration 244, loss = 95.42040161\n",
            "Iteration 245, loss = 95.42044942\n",
            "Iteration 246, loss = 95.42063828\n",
            "Iteration 247, loss = 95.42045445\n",
            "Iteration 248, loss = 95.42074057\n",
            "Iteration 249, loss = 95.42062535\n",
            "Iteration 250, loss = 95.42071663\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 92 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 1034.71407819\n",
            "Iteration 2, loss = 382.25751887\n",
            "Iteration 3, loss = 2603.92393530\n",
            "Iteration 4, loss = 683.61469971\n",
            "Iteration 5, loss = 667.14243395\n",
            "Iteration 6, loss = 645.64600918\n",
            "Iteration 7, loss = 620.88815553\n",
            "Iteration 8, loss = 594.36238706\n",
            "Iteration 9, loss = 567.08962423\n",
            "Iteration 10, loss = 539.51414917\n",
            "Iteration 11, loss = 512.68128830\n",
            "Iteration 12, loss = 486.42968552\n",
            "Iteration 13, loss = 460.85315140\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 93 ------ \n",
            "[3, 5, 6, 12, 14, 5] [ 3  6 11 14 66 21] [3, 6, 14] [] 6.0\n",
            "[3, 5, 6, 12, 14, 5] [ 6  8 20 52 68  5] [6] [5] 7.0\n",
            "[3, 5, 6, 12, 14, 5] [20 40 47 55 63  5] [] [5] 6.0\n",
            "[3, 5, 6, 12, 14, 5] [ 2 12 32 50 65  5] [12] [5] 7.0\n",
            "-----> Match Score: 26.0 <------\n",
            "Iteration 1, loss = 1027958.83775805\n",
            "Iteration 2, loss = 2245.00622783\n",
            "Iteration 3, loss = 3965.83582164\n",
            "Iteration 4, loss = 5464.30231118\n",
            "Iteration 5, loss = 6160.35168179\n",
            "Iteration 6, loss = 7154.03583399\n",
            "Iteration 7, loss = 7900.65043001\n",
            "Iteration 8, loss = 8569.20077145\n",
            "Iteration 9, loss = 9068.21907870\n",
            "Iteration 10, loss = 9451.55965606\n",
            "Iteration 11, loss = 9733.66871468\n",
            "Iteration 12, loss = 9943.38342754\n",
            "Iteration 13, loss = 10097.60918244\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 94 ------ \n",
            "[12, 24, 35, 47, 59, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 35, 47, 59, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 916.45902284\n",
            "Iteration 2, loss = 699.05266915\n",
            "Iteration 3, loss = 679.49638721\n",
            "Iteration 4, loss = 655.65056881\n",
            "Iteration 5, loss = 629.03376455\n",
            "Iteration 6, loss = 601.00209704\n",
            "Iteration 7, loss = 572.57012129\n",
            "Iteration 8, loss = 544.40194385\n",
            "Iteration 9, loss = 516.63408824\n",
            "Iteration 10, loss = 489.77074469\n",
            "Iteration 11, loss = 464.01615158\n",
            "Iteration 12, loss = 439.46373294\n",
            "Iteration 13, loss = 416.20556329\n",
            "Iteration 14, loss = 393.94895180\n",
            "Iteration 15, loss = 372.95213756\n",
            "Iteration 16, loss = 353.36070965\n",
            "Iteration 17, loss = 334.90712953\n",
            "Iteration 18, loss = 317.53988707\n",
            "Iteration 19, loss = 301.19688494\n",
            "Iteration 20, loss = 285.82037737\n",
            "Iteration 21, loss = 271.58620510\n",
            "Iteration 22, loss = 258.01844362\n",
            "Iteration 23, loss = 245.41236675\n",
            "Iteration 24, loss = 233.61464525\n",
            "Iteration 25, loss = 222.47348801\n",
            "Iteration 26, loss = 212.21775501\n",
            "Iteration 27, loss = 202.55003453\n",
            "Iteration 28, loss = 193.40997374\n",
            "Iteration 29, loss = 184.84145852\n",
            "Iteration 30, loss = 177.01206858\n",
            "Iteration 31, loss = 169.51465408\n",
            "Iteration 32, loss = 162.56528620\n",
            "Iteration 33, loss = 155.97750208\n",
            "Iteration 34, loss = 149.90699993\n",
            "Iteration 35, loss = 144.19309226\n",
            "Iteration 36, loss = 138.80642522\n",
            "Iteration 37, loss = 133.85491849\n",
            "Iteration 38, loss = 129.18604849\n",
            "Iteration 39, loss = 124.80477315\n",
            "Iteration 40, loss = 120.70148366\n",
            "Iteration 41, loss = 116.81428167\n",
            "Iteration 42, loss = 113.30943805\n",
            "Iteration 43, loss = 109.90928166\n",
            "Iteration 44, loss = 106.74665371\n",
            "Iteration 45, loss = 103.79013713\n",
            "Iteration 46, loss = 101.03827182\n",
            "Iteration 47, loss = 98.53297130\n",
            "Iteration 48, loss = 96.07595417\n",
            "Iteration 49, loss = 93.76681458\n",
            "Iteration 50, loss = 91.72891722\n",
            "Iteration 51, loss = 89.72609072\n",
            "Iteration 52, loss = 87.85622321\n",
            "Iteration 53, loss = 86.13776743\n",
            "Iteration 54, loss = 84.52116076\n",
            "Iteration 55, loss = 83.00429108\n",
            "Iteration 56, loss = 81.61874352\n",
            "Iteration 57, loss = 80.26673864\n",
            "Iteration 58, loss = 79.02870529\n",
            "Iteration 59, loss = 77.88049617\n",
            "Iteration 60, loss = 76.77815971\n",
            "Iteration 61, loss = 75.74879575\n",
            "Iteration 62, loss = 74.82012015\n",
            "Iteration 63, loss = 73.92847946\n",
            "Iteration 64, loss = 73.08383534\n",
            "Iteration 65, loss = 72.32352557\n",
            "Iteration 66, loss = 71.60138964\n",
            "Iteration 67, loss = 70.91092794\n",
            "Iteration 68, loss = 70.26254861\n",
            "Iteration 69, loss = 69.65527503\n",
            "Iteration 70, loss = 69.09929725\n",
            "Iteration 71, loss = 68.59113518\n",
            "Iteration 72, loss = 68.09937498\n",
            "Iteration 73, loss = 67.65703963\n",
            "Iteration 74, loss = 67.21123768\n",
            "Iteration 75, loss = 66.80399987\n",
            "Iteration 76, loss = 66.44211976\n",
            "Iteration 77, loss = 66.08422689\n",
            "Iteration 78, loss = 65.76732439\n",
            "Iteration 79, loss = 65.44849258\n",
            "Iteration 80, loss = 65.15784223\n",
            "Iteration 81, loss = 64.90316251\n",
            "Iteration 82, loss = 64.65067463\n",
            "Iteration 83, loss = 64.40282878\n",
            "Iteration 84, loss = 64.18966579\n",
            "Iteration 85, loss = 63.97626648\n",
            "Iteration 86, loss = 63.79312859\n",
            "Iteration 87, loss = 63.61701947\n",
            "Iteration 88, loss = 63.43419154\n",
            "Iteration 89, loss = 63.27398832\n",
            "Iteration 90, loss = 63.13971358\n",
            "Iteration 91, loss = 62.98715791\n",
            "Iteration 92, loss = 62.86585107\n",
            "Iteration 93, loss = 62.74773111\n",
            "Iteration 94, loss = 62.62991632\n",
            "Iteration 95, loss = 62.52154056\n",
            "Iteration 96, loss = 62.42479627\n",
            "Iteration 97, loss = 62.33398159\n",
            "Iteration 98, loss = 62.25172867\n",
            "Iteration 99, loss = 62.16760781\n",
            "Iteration 100, loss = 62.09124960\n",
            "Iteration 101, loss = 62.01366659\n",
            "Iteration 102, loss = 61.95151502\n",
            "Iteration 103, loss = 61.89066392\n",
            "Iteration 104, loss = 61.83063390\n",
            "Iteration 105, loss = 61.77690444\n",
            "Iteration 106, loss = 61.73491064\n",
            "Iteration 107, loss = 61.67428383\n",
            "Iteration 108, loss = 61.63849592\n",
            "Iteration 109, loss = 61.59388892\n",
            "Iteration 110, loss = 61.55401703\n",
            "Iteration 111, loss = 61.51861439\n",
            "Iteration 112, loss = 61.48115075\n",
            "Iteration 113, loss = 61.45114928\n",
            "Iteration 114, loss = 61.42395297\n",
            "Iteration 115, loss = 61.39322724\n",
            "Iteration 116, loss = 61.36624398\n",
            "Iteration 117, loss = 61.34208772\n",
            "Iteration 118, loss = 61.31782887\n",
            "Iteration 119, loss = 61.29657127\n",
            "Iteration 120, loss = 61.27520265\n",
            "Iteration 121, loss = 61.25953363\n",
            "Iteration 122, loss = 61.23998472\n",
            "Iteration 123, loss = 61.22526313\n",
            "Iteration 124, loss = 61.20594380\n",
            "Iteration 125, loss = 61.19251845\n",
            "Iteration 126, loss = 61.18063499\n",
            "Iteration 127, loss = 61.16689778\n",
            "Iteration 128, loss = 61.15349190\n",
            "Iteration 129, loss = 61.14704197\n",
            "Iteration 130, loss = 61.13392864\n",
            "Iteration 131, loss = 61.12363321\n",
            "Iteration 132, loss = 61.11409537\n",
            "Iteration 133, loss = 61.10730105\n",
            "Iteration 134, loss = 61.09909197\n",
            "Iteration 135, loss = 61.09162151\n",
            "Iteration 136, loss = 61.08431826\n",
            "Iteration 137, loss = 61.07881812\n",
            "Iteration 138, loss = 61.07222821\n",
            "Iteration 139, loss = 61.06751744\n",
            "Iteration 140, loss = 61.06154366\n",
            "Iteration 141, loss = 61.05624850\n",
            "Iteration 142, loss = 61.05173302\n",
            "Iteration 143, loss = 61.04735703\n",
            "Iteration 144, loss = 61.04336140\n",
            "Iteration 145, loss = 61.04172016\n",
            "Iteration 146, loss = 61.03523114\n",
            "Iteration 147, loss = 61.03342390\n",
            "Iteration 148, loss = 61.03008494\n",
            "Iteration 149, loss = 61.02719975\n",
            "Iteration 150, loss = 61.02331885\n",
            "Iteration 151, loss = 61.02267061\n",
            "Iteration 152, loss = 61.01794298\n",
            "Iteration 153, loss = 61.01714723\n",
            "Iteration 154, loss = 61.01551399\n",
            "Iteration 155, loss = 61.01194492\n",
            "Iteration 156, loss = 61.01056526\n",
            "Iteration 157, loss = 61.00904039\n",
            "Iteration 158, loss = 61.00705992\n",
            "Iteration 159, loss = 61.00528850\n",
            "Iteration 160, loss = 61.00411852\n",
            "Iteration 161, loss = 61.00445907\n",
            "Iteration 162, loss = 61.00143873\n",
            "Iteration 163, loss = 61.00052628\n",
            "Iteration 164, loss = 60.99923495\n",
            "Iteration 165, loss = 60.99802144\n",
            "Iteration 166, loss = 60.99757508\n",
            "Iteration 167, loss = 60.99619173\n",
            "Iteration 168, loss = 60.99604094\n",
            "Iteration 169, loss = 60.99459770\n",
            "Iteration 170, loss = 60.99467879\n",
            "Iteration 171, loss = 60.99340022\n",
            "Iteration 172, loss = 60.99255626\n",
            "Iteration 173, loss = 60.99193577\n",
            "Iteration 174, loss = 60.99108115\n",
            "Iteration 175, loss = 60.99108697\n",
            "Iteration 176, loss = 60.98997514\n",
            "Iteration 177, loss = 60.98951893\n",
            "Iteration 178, loss = 60.99049323\n",
            "Iteration 179, loss = 60.98931143\n",
            "Iteration 180, loss = 60.98860401\n",
            "Iteration 181, loss = 60.98791386\n",
            "Iteration 182, loss = 60.98749503\n",
            "Iteration 183, loss = 60.98715892\n",
            "Iteration 184, loss = 60.98657732\n",
            "Iteration 185, loss = 60.98649749\n",
            "Iteration 186, loss = 60.98712270\n",
            "Iteration 187, loss = 60.98572127\n",
            "Iteration 188, loss = 60.98594523\n",
            "Iteration 189, loss = 60.98527936\n",
            "Iteration 190, loss = 60.98507387\n",
            "Iteration 191, loss = 60.98470725\n",
            "Iteration 192, loss = 60.98478216\n",
            "Iteration 193, loss = 60.98434070\n",
            "Iteration 194, loss = 60.98468916\n",
            "Iteration 195, loss = 60.98407722\n",
            "Iteration 196, loss = 60.98410559\n",
            "Iteration 197, loss = 60.98437931\n",
            "Iteration 198, loss = 60.98422709\n",
            "Iteration 199, loss = 60.98368338\n",
            "Iteration 200, loss = 60.98381968\n",
            "Iteration 201, loss = 60.98374912\n",
            "Iteration 202, loss = 60.98354648\n",
            "Iteration 203, loss = 60.98340124\n",
            "Iteration 204, loss = 60.98304702\n",
            "Iteration 205, loss = 60.98320535\n",
            "Iteration 206, loss = 60.98332686\n",
            "Iteration 207, loss = 60.98323698\n",
            "Iteration 208, loss = 60.98310032\n",
            "Iteration 209, loss = 60.98282432\n",
            "Iteration 210, loss = 60.98308780\n",
            "Iteration 211, loss = 60.98311386\n",
            "Iteration 212, loss = 60.98297669\n",
            "Iteration 213, loss = 60.98337926\n",
            "Iteration 214, loss = 60.98262661\n",
            "Iteration 215, loss = 60.98328031\n",
            "Iteration 216, loss = 60.98271617\n",
            "Iteration 217, loss = 60.98258354\n",
            "Iteration 218, loss = 60.98352178\n",
            "Iteration 219, loss = 60.98258330\n",
            "Iteration 220, loss = 60.98252744\n",
            "Iteration 221, loss = 60.98244370\n",
            "Iteration 222, loss = 60.98269135\n",
            "Iteration 223, loss = 60.98270800\n",
            "Iteration 224, loss = 60.98250413\n",
            "Iteration 225, loss = 60.98257230\n",
            "Iteration 226, loss = 60.98229058\n",
            "Iteration 227, loss = 60.98311209\n",
            "Iteration 228, loss = 60.98241135\n",
            "Iteration 229, loss = 60.98234644\n",
            "Iteration 230, loss = 60.98229663\n",
            "Iteration 231, loss = 60.98234928\n",
            "Iteration 232, loss = 60.98222076\n",
            "Iteration 233, loss = 60.98225759\n",
            "Iteration 234, loss = 60.98210072\n",
            "Iteration 235, loss = 60.98331115\n",
            "Iteration 236, loss = 60.98255428\n",
            "Iteration 237, loss = 60.98210364\n",
            "Iteration 238, loss = 60.98252111\n",
            "Iteration 239, loss = 60.98262502\n",
            "Iteration 240, loss = 60.98238134\n",
            "Iteration 241, loss = 60.98284767\n",
            "Iteration 242, loss = 60.98209784\n",
            "Iteration 243, loss = 60.98229313\n",
            "Iteration 244, loss = 60.98304688\n",
            "Iteration 245, loss = 60.98245543\n",
            "Iteration 246, loss = 60.98235422\n",
            "Iteration 247, loss = 60.98272845\n",
            "Iteration 248, loss = 60.98213439\n",
            "Iteration 249, loss = 60.98228363\n",
            "Iteration 250, loss = 60.98202117\n",
            "Iteration 251, loss = 60.98212224\n",
            "Iteration 252, loss = 60.98229653\n",
            "Iteration 253, loss = 60.98225753\n",
            "Iteration 254, loss = 60.98214230\n",
            "Iteration 255, loss = 60.98239949\n",
            "Iteration 256, loss = 60.98264393\n",
            "Iteration 257, loss = 60.98217337\n",
            "Iteration 258, loss = 60.98236373\n",
            "Iteration 259, loss = 60.98223577\n",
            "Iteration 260, loss = 60.98209843\n",
            "Iteration 261, loss = 60.98229619\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 95 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 715.34342345\n",
            "Iteration 2, loss = 685.55972514\n",
            "Iteration 3, loss = 602.42915372\n",
            "Iteration 4, loss = 347.59644123\n",
            "Iteration 5, loss = 96.11665474\n",
            "Iteration 6, loss = 142.51765821\n",
            "Iteration 7, loss = 69.57480494\n",
            "Iteration 8, loss = 68.77354963\n",
            "Iteration 9, loss = 65.84006750\n",
            "Iteration 10, loss = 61.34606302\n",
            "Iteration 11, loss = 61.86974347\n",
            "Iteration 12, loss = 61.35184948\n",
            "Iteration 13, loss = 61.05298973\n",
            "Iteration 14, loss = 61.09622418\n",
            "Iteration 15, loss = 61.05425459\n",
            "Iteration 16, loss = 61.02384603\n",
            "Iteration 17, loss = 60.99170332\n",
            "Iteration 18, loss = 61.05908429\n",
            "Iteration 19, loss = 61.04246900\n",
            "Iteration 20, loss = 61.02288222\n",
            "Iteration 21, loss = 60.99165751\n",
            "Iteration 22, loss = 61.01526834\n",
            "Iteration 23, loss = 61.06122487\n",
            "Iteration 24, loss = 61.05595398\n",
            "Iteration 25, loss = 61.06120120\n",
            "Iteration 26, loss = 61.04686385\n",
            "Iteration 27, loss = 61.03965053\n",
            "Iteration 28, loss = 61.08438502\n",
            "Iteration 29, loss = 61.02509345\n",
            "Iteration 30, loss = 61.01605008\n",
            "Iteration 31, loss = 61.00774937\n",
            "Iteration 32, loss = 61.01121115\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 96 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 736.85022822\n",
            "Iteration 2, loss = 692.44428438\n",
            "Iteration 3, loss = 616.54085504\n",
            "Iteration 4, loss = 367.91728894\n",
            "Iteration 5, loss = 92.59215250\n",
            "Iteration 6, loss = 149.36904530\n",
            "Iteration 7, loss = 68.16143625\n",
            "Iteration 8, loss = 69.09683499\n",
            "Iteration 9, loss = 67.27340484\n",
            "Iteration 10, loss = 61.54813240\n",
            "Iteration 11, loss = 62.24634900\n",
            "Iteration 12, loss = 61.28025660\n",
            "Iteration 13, loss = 61.16655800\n",
            "Iteration 14, loss = 61.06379649\n",
            "Iteration 15, loss = 61.01081813\n",
            "Iteration 16, loss = 61.26437957\n",
            "Iteration 17, loss = 60.97790232\n",
            "Iteration 18, loss = 61.02670773\n",
            "Iteration 19, loss = 61.03445473\n",
            "Iteration 20, loss = 60.99946252\n",
            "Iteration 21, loss = 61.00725951\n",
            "Iteration 22, loss = 61.02105983\n",
            "Iteration 23, loss = 61.02317985\n",
            "Iteration 24, loss = 61.00872978\n",
            "Iteration 25, loss = 61.01985993\n",
            "Iteration 26, loss = 61.08123781\n",
            "Iteration 27, loss = 61.08027367\n",
            "Iteration 28, loss = 60.99007919\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 97 ------ \n",
            "[12, 24, 35, 48, 59, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [ 8 40 49 58 63 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [19 25 43 46 48 14] [48] [14] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 48, 59, 14] [ 5  6 45 55 59 14] [59] [14] 7.0\n",
            "[12, 24, 35, 48, 59, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 39.0 <------\n",
            "Iteration 1, loss = 1005.15351059\n",
            "Iteration 2, loss = 700.53859958\n",
            "Iteration 3, loss = 680.11542149\n",
            "Iteration 4, loss = 655.61106552\n",
            "Iteration 5, loss = 628.61020533\n",
            "Iteration 6, loss = 600.39470001\n",
            "Iteration 7, loss = 571.61628542\n",
            "Iteration 8, loss = 543.27543529\n",
            "Iteration 9, loss = 515.58635368\n",
            "Iteration 10, loss = 488.77341747\n",
            "Iteration 11, loss = 462.88945342\n",
            "Iteration 12, loss = 438.37797967\n",
            "Iteration 13, loss = 414.97064023\n",
            "Iteration 14, loss = 392.92160474\n",
            "Iteration 15, loss = 372.10089104\n",
            "Iteration 16, loss = 352.42404210\n",
            "Iteration 17, loss = 334.07008409\n",
            "Iteration 18, loss = 316.65131601\n",
            "Iteration 19, loss = 300.33575419\n",
            "Iteration 20, loss = 285.15021941\n",
            "Iteration 21, loss = 270.71982203\n",
            "Iteration 22, loss = 257.33836547\n",
            "Iteration 23, loss = 244.76572488\n",
            "Iteration 24, loss = 233.01084801\n",
            "Iteration 25, loss = 222.03731157\n",
            "Iteration 26, loss = 211.61443097\n",
            "Iteration 27, loss = 201.96726595\n",
            "Iteration 28, loss = 192.92368289\n",
            "Iteration 29, loss = 184.49021107\n",
            "Iteration 30, loss = 176.54194817\n",
            "Iteration 31, loss = 169.10821177\n",
            "Iteration 32, loss = 162.16944459\n",
            "Iteration 33, loss = 155.63968439\n",
            "Iteration 34, loss = 149.60226479\n",
            "Iteration 35, loss = 143.87848371\n",
            "Iteration 36, loss = 138.59234045\n",
            "Iteration 37, loss = 133.57804773\n",
            "Iteration 38, loss = 128.91057449\n",
            "Iteration 39, loss = 124.54812957\n",
            "Iteration 40, loss = 120.51581167\n",
            "Iteration 41, loss = 116.64141920\n",
            "Iteration 42, loss = 113.05590470\n",
            "Iteration 43, loss = 109.72725379\n",
            "Iteration 44, loss = 106.60871709\n",
            "Iteration 45, loss = 103.66651139\n",
            "Iteration 46, loss = 100.93891614\n",
            "Iteration 47, loss = 98.36624917\n",
            "Iteration 48, loss = 95.96626969\n",
            "Iteration 49, loss = 93.69077105\n",
            "Iteration 50, loss = 91.62764981\n",
            "Iteration 51, loss = 89.63944386\n",
            "Iteration 52, loss = 87.80350147\n",
            "Iteration 53, loss = 86.11570076\n",
            "Iteration 54, loss = 84.46600309\n",
            "Iteration 55, loss = 82.98372813\n",
            "Iteration 56, loss = 81.55134032\n",
            "Iteration 57, loss = 80.25510893\n",
            "Iteration 58, loss = 78.98253019\n",
            "Iteration 59, loss = 77.82451119\n",
            "Iteration 60, loss = 76.77870721\n",
            "Iteration 61, loss = 75.75797038\n",
            "Iteration 62, loss = 74.82169574\n",
            "Iteration 63, loss = 73.93909766\n",
            "Iteration 64, loss = 73.09893757\n",
            "Iteration 65, loss = 72.32312687\n",
            "Iteration 66, loss = 71.59357401\n",
            "Iteration 67, loss = 70.90025452\n",
            "Iteration 68, loss = 70.29014487\n",
            "Iteration 69, loss = 69.65069500\n",
            "Iteration 70, loss = 69.12018008\n",
            "Iteration 71, loss = 68.59897824\n",
            "Iteration 72, loss = 68.11128235\n",
            "Iteration 73, loss = 67.64708380\n",
            "Iteration 74, loss = 67.21916796\n",
            "Iteration 75, loss = 66.81267258\n",
            "Iteration 76, loss = 66.45510448\n",
            "Iteration 77, loss = 66.09205772\n",
            "Iteration 78, loss = 65.76590590\n",
            "Iteration 79, loss = 65.44722395\n",
            "Iteration 80, loss = 65.17171196\n",
            "Iteration 81, loss = 64.89193856\n",
            "Iteration 82, loss = 64.64816915\n",
            "Iteration 83, loss = 64.41677885\n",
            "Iteration 84, loss = 64.18372041\n",
            "Iteration 85, loss = 63.98168026\n",
            "Iteration 86, loss = 63.80117786\n",
            "Iteration 87, loss = 63.61175801\n",
            "Iteration 88, loss = 63.43867465\n",
            "Iteration 89, loss = 63.27820114\n",
            "Iteration 90, loss = 63.14239159\n",
            "Iteration 91, loss = 62.99870034\n",
            "Iteration 92, loss = 62.87612038\n",
            "Iteration 93, loss = 62.75129048\n",
            "Iteration 94, loss = 62.63940955\n",
            "Iteration 95, loss = 62.53276919\n",
            "Iteration 96, loss = 62.43281069\n",
            "Iteration 97, loss = 62.34452424\n",
            "Iteration 98, loss = 62.25436988\n",
            "Iteration 99, loss = 62.17552501\n",
            "Iteration 100, loss = 62.09706797\n",
            "Iteration 101, loss = 62.02578389\n",
            "Iteration 102, loss = 61.96497890\n",
            "Iteration 103, loss = 61.90144757\n",
            "Iteration 104, loss = 61.83697544\n",
            "Iteration 105, loss = 61.78638238\n",
            "Iteration 106, loss = 61.73717876\n",
            "Iteration 107, loss = 61.68741218\n",
            "Iteration 108, loss = 61.64206635\n",
            "Iteration 109, loss = 61.60243515\n",
            "Iteration 110, loss = 61.56005361\n",
            "Iteration 111, loss = 61.52477731\n",
            "Iteration 112, loss = 61.49040983\n",
            "Iteration 113, loss = 61.46207164\n",
            "Iteration 114, loss = 61.42571731\n",
            "Iteration 115, loss = 61.39645964\n",
            "Iteration 116, loss = 61.37609090\n",
            "Iteration 117, loss = 61.35099987\n",
            "Iteration 118, loss = 61.32813294\n",
            "Iteration 119, loss = 61.30209752\n",
            "Iteration 120, loss = 61.28483393\n",
            "Iteration 121, loss = 61.26519884\n",
            "Iteration 122, loss = 61.24614121\n",
            "Iteration 123, loss = 61.23032189\n",
            "Iteration 124, loss = 61.21780205\n",
            "Iteration 125, loss = 61.19965019\n",
            "Iteration 126, loss = 61.18631484\n",
            "Iteration 127, loss = 61.17448161\n",
            "Iteration 128, loss = 61.16319167\n",
            "Iteration 129, loss = 61.15292214\n",
            "Iteration 130, loss = 61.14243471\n",
            "Iteration 131, loss = 61.12976426\n",
            "Iteration 132, loss = 61.12143851\n",
            "Iteration 133, loss = 61.11383380\n",
            "Iteration 134, loss = 61.10616822\n",
            "Iteration 135, loss = 61.09716489\n",
            "Iteration 136, loss = 61.08972764\n",
            "Iteration 137, loss = 61.08395033\n",
            "Iteration 138, loss = 61.07691626\n",
            "Iteration 139, loss = 61.07184799\n",
            "Iteration 140, loss = 61.06545182\n",
            "Iteration 141, loss = 61.06112334\n",
            "Iteration 142, loss = 61.05563627\n",
            "Iteration 143, loss = 61.05180988\n",
            "Iteration 144, loss = 61.04747775\n",
            "Iteration 145, loss = 61.04446805\n",
            "Iteration 146, loss = 61.04111278\n",
            "Iteration 147, loss = 61.03616426\n",
            "Iteration 148, loss = 61.03491658\n",
            "Iteration 149, loss = 61.03401417\n",
            "Iteration 150, loss = 61.02807334\n",
            "Iteration 151, loss = 61.02575073\n",
            "Iteration 152, loss = 61.02420618\n",
            "Iteration 153, loss = 61.02211905\n",
            "Iteration 154, loss = 61.02017639\n",
            "Iteration 155, loss = 61.01763214\n",
            "Iteration 156, loss = 61.01549808\n",
            "Iteration 157, loss = 61.01519747\n",
            "Iteration 158, loss = 61.01272320\n",
            "Iteration 159, loss = 61.01086667\n",
            "Iteration 160, loss = 61.00979704\n",
            "Iteration 161, loss = 61.00929416\n",
            "Iteration 162, loss = 61.00800908\n",
            "Iteration 163, loss = 61.00712361\n",
            "Iteration 164, loss = 61.00510555\n",
            "Iteration 165, loss = 61.00425532\n",
            "Iteration 166, loss = 61.00468445\n",
            "Iteration 167, loss = 61.00273785\n",
            "Iteration 168, loss = 61.00193477\n",
            "Iteration 169, loss = 61.00165599\n",
            "Iteration 170, loss = 61.00081501\n",
            "Iteration 171, loss = 61.00029531\n",
            "Iteration 172, loss = 60.99951370\n",
            "Iteration 173, loss = 60.99872515\n",
            "Iteration 174, loss = 60.99847473\n",
            "Iteration 175, loss = 60.99985380\n",
            "Iteration 176, loss = 60.99763499\n",
            "Iteration 177, loss = 60.99692518\n",
            "Iteration 178, loss = 60.99638365\n",
            "Iteration 179, loss = 60.99611687\n",
            "Iteration 180, loss = 60.99566319\n",
            "Iteration 181, loss = 60.99529622\n",
            "Iteration 182, loss = 60.99549516\n",
            "Iteration 183, loss = 60.99449623\n",
            "Iteration 184, loss = 60.99408984\n",
            "Iteration 185, loss = 60.99412436\n",
            "Iteration 186, loss = 60.99337129\n",
            "Iteration 187, loss = 60.99323233\n",
            "Iteration 188, loss = 60.99401674\n",
            "Iteration 189, loss = 60.99301622\n",
            "Iteration 190, loss = 60.99250572\n",
            "Iteration 191, loss = 60.99246645\n",
            "Iteration 192, loss = 60.99207604\n",
            "Iteration 193, loss = 60.99210675\n",
            "Iteration 194, loss = 60.99233069\n",
            "Iteration 195, loss = 60.99186254\n",
            "Iteration 196, loss = 60.99164220\n",
            "Iteration 197, loss = 60.99162677\n",
            "Iteration 198, loss = 60.99138158\n",
            "Iteration 199, loss = 60.99133399\n",
            "Iteration 200, loss = 60.99134345\n",
            "Iteration 201, loss = 60.99138720\n",
            "Iteration 202, loss = 60.99113277\n",
            "Iteration 203, loss = 60.99094515\n",
            "Iteration 204, loss = 60.99106669\n",
            "Iteration 205, loss = 60.99114246\n",
            "Iteration 206, loss = 60.99137863\n",
            "Iteration 207, loss = 60.99124073\n",
            "Iteration 208, loss = 60.99231479\n",
            "Iteration 209, loss = 60.99099074\n",
            "Iteration 210, loss = 60.99095120\n",
            "Iteration 211, loss = 60.99113415\n",
            "Iteration 212, loss = 60.99080799\n",
            "Iteration 213, loss = 60.99077886\n",
            "Iteration 214, loss = 60.99046961\n",
            "Iteration 215, loss = 60.99076325\n",
            "Iteration 216, loss = 60.99093706\n",
            "Iteration 217, loss = 60.99035179\n",
            "Iteration 218, loss = 60.99038622\n",
            "Iteration 219, loss = 60.99058093\n",
            "Iteration 220, loss = 60.99017445\n",
            "Iteration 221, loss = 60.99017976\n",
            "Iteration 222, loss = 60.99042643\n",
            "Iteration 223, loss = 60.99029111\n",
            "Iteration 224, loss = 60.99017601\n",
            "Iteration 225, loss = 60.99036086\n",
            "Iteration 226, loss = 60.99011011\n",
            "Iteration 227, loss = 60.99013069\n",
            "Iteration 228, loss = 60.99013578\n",
            "Iteration 229, loss = 60.99030393\n",
            "Iteration 230, loss = 60.99004115\n",
            "Iteration 231, loss = 60.99016740\n",
            "Iteration 232, loss = 60.99023788\n",
            "Iteration 233, loss = 60.99072075\n",
            "Iteration 234, loss = 60.99004687\n",
            "Iteration 235, loss = 60.99023710\n",
            "Iteration 236, loss = 60.99019286\n",
            "Iteration 237, loss = 60.99014932\n",
            "Iteration 238, loss = 60.99017470\n",
            "Iteration 239, loss = 60.99023437\n",
            "Iteration 240, loss = 60.99078748\n",
            "Iteration 241, loss = 60.98991471\n",
            "Iteration 242, loss = 60.98991046\n",
            "Iteration 243, loss = 60.99038316\n",
            "Iteration 244, loss = 60.99003365\n",
            "Iteration 245, loss = 60.98997374\n",
            "Iteration 246, loss = 60.99005203\n",
            "Iteration 247, loss = 60.99014441\n",
            "Iteration 248, loss = 60.99040434\n",
            "Iteration 249, loss = 60.99054060\n",
            "Iteration 250, loss = 60.99051264\n",
            "Iteration 251, loss = 60.99048094\n",
            "Iteration 252, loss = 60.99056270\n",
            "Iteration 253, loss = 60.99006483\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 98 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 713.23841133\n",
            "Iteration 2, loss = 685.77764321\n",
            "Iteration 3, loss = 666.47293323\n",
            "Iteration 4, loss = 643.00216024\n",
            "Iteration 5, loss = 26690865.86262476\n",
            "Iteration 6, loss = 29962566024235202926679687168.00000000\n",
            "Iteration 7, loss = 3972282003179003879409332518912.00000000\n",
            "Iteration 8, loss = 11498279636538786806494763417600.00000000\n",
            "Iteration 9, loss = 19596366765852818098093073367040.00000000\n",
            "Iteration 10, loss = 26887801881421696039528718925824.00000000\n",
            "Iteration 11, loss = 32940860512657288940649596321792.00000000\n",
            "Iteration 12, loss = 37745532158153584373476089659392.00000000\n",
            "Iteration 13, loss = 41456458083358064177914736279552.00000000\n",
            "Iteration 14, loss = 44272432756123835441232710991872.00000000\n",
            "Iteration 15, loss = 46384113681216530022560792838144.00000000\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 99 ------ \n",
            "-----> Match Score: 0 <------\n",
            "Iteration 1, loss = 656.21294438\n",
            "Iteration 2, loss = 584.09567667\n",
            "Iteration 3, loss = 530.88565398\n",
            "Iteration 4, loss = 451.99290755\n",
            "Iteration 5, loss = 386.88438604\n",
            "Iteration 6, loss = 326.33770167\n",
            "Iteration 7, loss = 271.00882120\n",
            "Iteration 8, loss = 222.46076122\n",
            "Iteration 9, loss = 183.61472044\n",
            "Iteration 10, loss = 159.95709032\n",
            "Iteration 11, loss = 145.31104511\n",
            "Iteration 12, loss = 139.83537621\n",
            "Iteration 13, loss = 190.16261737\n",
            "Iteration 14, loss = 473.73072501\n",
            "Iteration 15, loss = 524.82044782\n",
            "Iteration 16, loss = 510.45247632\n",
            "Iteration 17, loss = 492.92883600\n",
            "Iteration 18, loss = 473.68094064\n",
            "Iteration 19, loss = 453.30186299\n",
            "Iteration 20, loss = 432.70674249\n",
            "Iteration 21, loss = 412.10672347\n",
            "Iteration 22, loss = 391.88783797\n",
            "Iteration 23, loss = 372.49351109\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 100 ------ \n",
            "[-1, 12, 17, 14, 16, 8] [18 22 29 54 57  8] [] [8] 6.0\n",
            "[-1, 12, 17, 14, 16, 8] [ 1 16 48 49 65  8] [16] [8] 7.0\n",
            "[-1, 12, 17, 14, 16, 8] [11 33 44 59 67  8] [] [8] 6.0\n",
            "[-1, 12, 17, 14, 16, 8] [15 27 44 59 63  8] [] [8] 6.0\n",
            "[-1, 12, 17, 14, 16, 8] [21 31 50 51 69  8] [] [8] 6.0\n",
            "-----> Match Score: 31.0 <------\n",
            "Iteration 1, loss = 53102455.11117836\n",
            "Iteration 2, loss = 1341724.34141145\n",
            "Iteration 3, loss = 3044186.36790429\n",
            "Iteration 4, loss = 4737114.93235974\n",
            "Iteration 5, loss = 6211250.23575273\n",
            "Iteration 6, loss = 7413300.12496938\n",
            "Iteration 7, loss = 8357169.85872093\n",
            "Iteration 8, loss = 9081037.36359751\n",
            "Iteration 9, loss = 9627635.70870109\n",
            "Iteration 10, loss = 10036036.72944984\n",
            "Iteration 11, loss = 10338932.96527849\n",
            "Iteration 12, loss = 10562393.93732505\n",
            "Iteration 13, loss = 10726611.69639072\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 101 ------ \n",
            "-----> Match Score: 0 <------\n",
            "Iteration 1, loss = 725.12417728\n",
            "Iteration 2, loss = 704.96217897\n",
            "Iteration 3, loss = 677.48736124\n",
            "Iteration 4, loss = 613.05134769\n",
            "Iteration 5, loss = 419.94965115\n",
            "Iteration 6, loss = 105.93598480\n",
            "Iteration 7, loss = 142.00733150\n",
            "Iteration 8, loss = 86.34213256\n",
            "Iteration 9, loss = 65.43142705\n",
            "Iteration 10, loss = 68.62455103\n",
            "Iteration 11, loss = 62.39029724\n",
            "Iteration 12, loss = 61.89067069\n",
            "Iteration 13, loss = 61.62715927\n",
            "Iteration 14, loss = 61.01216152\n",
            "Iteration 15, loss = 61.03098040\n",
            "Iteration 16, loss = 61.05880997\n",
            "Iteration 17, loss = 61.04950594\n",
            "Iteration 18, loss = 61.00008054\n",
            "Iteration 19, loss = 61.03051746\n",
            "Iteration 20, loss = 60.98162716\n",
            "Iteration 21, loss = 61.02547510\n",
            "Iteration 22, loss = 61.01364548\n",
            "Iteration 23, loss = 61.01170834\n",
            "Iteration 24, loss = 61.01798403\n",
            "Iteration 25, loss = 61.01629524\n",
            "Iteration 26, loss = 61.08596560\n",
            "Iteration 27, loss = 60.99917034\n",
            "Iteration 28, loss = 61.00592158\n",
            "Iteration 29, loss = 61.02980856\n",
            "Iteration 30, loss = 61.00864039\n",
            "Iteration 31, loss = 60.99846203\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 102 ------ \n",
            "[12, 24, 35, 47, 58, 13] [ 6 15 50 59 60 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [12 33 54 57 60 13] [12] [13] 7.0\n",
            "[12, 24, 35, 47, 58, 13] [27 32 34 43 52 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 8 23 37 52 63 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 2 23 40 59 69 13] [] [13] 6.0\n",
            "[12, 24, 35, 47, 58, 13] [ 1  7 45 47 69 13] [47] [13] 7.0\n",
            "-----> Match Score: 38.0 <------\n",
            "Iteration 1, loss = 1234672.52507266\n",
            "Iteration 2, loss = 272943.08192834\n",
            "Iteration 3, loss = 788423.80426853\n",
            "Iteration 4, loss = 1343005.55969447\n",
            "Iteration 5, loss = 1842302.11142478\n",
            "Iteration 6, loss = 2256766.07586849\n",
            "Iteration 7, loss = 2585723.79770362\n",
            "Iteration 8, loss = 2839771.98267662\n",
            "Iteration 9, loss = 3032528.75537471\n",
            "Iteration 10, loss = 3177053.51927480\n",
            "Iteration 11, loss = 3284531.06397814\n",
            "Iteration 12, loss = 3363998.93153875\n",
            "Iteration 13, loss = 3422516.45082431\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 103 ------ \n",
            "[1, -12, -7, -21, -21, 5] [ 6  8 20 52 68  5] [] [5] 6.0\n",
            "[1, -12, -7, -21, -21, 5] [20 40 47 55 63  5] [] [5] 6.0\n",
            "[1, -12, -7, -21, -21, 5] [ 2 12 32 50 65  5] [] [5] 6.0\n",
            "-----> Match Score: 18.0 <------\n",
            "Iteration 1, loss = 703.48676533\n",
            "Iteration 2, loss = 690.73242639\n",
            "Iteration 3, loss = 671.35593067\n",
            "Iteration 4, loss = 647.73232160\n",
            "Iteration 5, loss = 621.52142893\n",
            "Iteration 6, loss = 593.90795224\n",
            "Iteration 7, loss = 565.81909504\n",
            "Iteration 8, loss = 537.97607174\n",
            "Iteration 9, loss = 510.72519890\n",
            "Iteration 10, loss = 484.12969055\n",
            "Iteration 11, loss = 458.77318510\n",
            "Iteration 12, loss = 434.52501646\n",
            "Iteration 13, loss = 411.41101575\n",
            "Iteration 14, loss = 389.52100200\n",
            "Iteration 15, loss = 368.99091115\n",
            "Iteration 16, loss = 349.56047587\n",
            "Iteration 17, loss = 331.35635684\n",
            "Iteration 18, loss = 314.19132809\n",
            "Iteration 19, loss = 297.98673390\n",
            "Iteration 20, loss = 282.80186511\n",
            "Iteration 21, loss = 268.75170585\n",
            "Iteration 22, loss = 255.41011610\n",
            "Iteration 23, loss = 242.95746845\n",
            "Iteration 24, loss = 231.34763739\n",
            "Iteration 25, loss = 220.43472702\n",
            "Iteration 26, loss = 210.12103430\n",
            "Iteration 27, loss = 200.56296789\n",
            "Iteration 28, loss = 191.60685473\n",
            "Iteration 29, loss = 183.24109274\n",
            "Iteration 30, loss = 175.42222158\n",
            "Iteration 31, loss = 167.97819254\n",
            "Iteration 32, loss = 161.16716105\n",
            "Iteration 33, loss = 154.68949883\n",
            "Iteration 34, loss = 148.71950115\n",
            "Iteration 35, loss = 143.08839223\n",
            "Iteration 36, loss = 137.73892138\n",
            "Iteration 37, loss = 132.83981815\n",
            "Iteration 38, loss = 128.21003716\n",
            "Iteration 39, loss = 123.92270231\n",
            "Iteration 40, loss = 119.85028729\n",
            "Iteration 41, loss = 116.05768421\n",
            "Iteration 42, loss = 112.52760021\n",
            "Iteration 43, loss = 109.18559023\n",
            "Iteration 44, loss = 106.13156113\n",
            "Iteration 45, loss = 103.21565266\n",
            "Iteration 46, loss = 100.49879465\n",
            "Iteration 47, loss = 97.94363537\n",
            "Iteration 48, loss = 95.55312470\n",
            "Iteration 49, loss = 93.37428582\n",
            "Iteration 50, loss = 91.27732924\n",
            "Iteration 51, loss = 89.30072647\n",
            "Iteration 52, loss = 87.51595461\n",
            "Iteration 53, loss = 85.79510694\n",
            "Iteration 54, loss = 84.22773290\n",
            "Iteration 55, loss = 82.71877426\n",
            "Iteration 56, loss = 81.31159063\n",
            "Iteration 57, loss = 80.01138973\n",
            "Iteration 58, loss = 78.79092775\n",
            "Iteration 59, loss = 77.65745699\n",
            "Iteration 60, loss = 76.55517945\n",
            "Iteration 61, loss = 75.56262337\n",
            "Iteration 62, loss = 74.61538419\n",
            "Iteration 63, loss = 73.75617259\n",
            "Iteration 64, loss = 72.93693604\n",
            "Iteration 65, loss = 72.18364384\n",
            "Iteration 66, loss = 71.44057694\n",
            "Iteration 67, loss = 70.79397335\n",
            "Iteration 68, loss = 70.14941425\n",
            "Iteration 69, loss = 69.54720224\n",
            "Iteration 70, loss = 68.98111979\n",
            "Iteration 71, loss = 68.49863828\n",
            "Iteration 72, loss = 68.01475794\n",
            "Iteration 73, loss = 67.55128977\n",
            "Iteration 74, loss = 67.13643747\n",
            "Iteration 75, loss = 66.72668265\n",
            "Iteration 76, loss = 66.36402070\n",
            "Iteration 77, loss = 66.02156019\n",
            "Iteration 78, loss = 65.70132345\n",
            "Iteration 79, loss = 65.38877631\n",
            "Iteration 80, loss = 65.10448935\n",
            "Iteration 81, loss = 64.85747572\n",
            "Iteration 82, loss = 64.59342422\n",
            "Iteration 83, loss = 64.36328666\n",
            "Iteration 84, loss = 64.14644143\n",
            "Iteration 85, loss = 63.93528048\n",
            "Iteration 86, loss = 63.74788532\n",
            "Iteration 87, loss = 63.57063596\n",
            "Iteration 88, loss = 63.41635008\n",
            "Iteration 89, loss = 63.25762866\n",
            "Iteration 90, loss = 63.10229832\n",
            "Iteration 91, loss = 62.97152056\n",
            "Iteration 92, loss = 62.83561208\n",
            "Iteration 93, loss = 62.71999990\n",
            "Iteration 94, loss = 62.61090253\n",
            "Iteration 95, loss = 62.50824997\n",
            "Iteration 96, loss = 62.41134137\n",
            "Iteration 97, loss = 62.30754807\n",
            "Iteration 98, loss = 62.22456856\n",
            "Iteration 99, loss = 62.15633649\n",
            "Iteration 100, loss = 62.07213544\n",
            "Iteration 101, loss = 62.00407792\n",
            "Iteration 102, loss = 61.93683977\n",
            "Iteration 103, loss = 61.87105898\n",
            "Iteration 104, loss = 61.81199108\n",
            "Iteration 105, loss = 61.76706456\n",
            "Iteration 106, loss = 61.71652165\n",
            "Iteration 107, loss = 61.66334541\n",
            "Iteration 108, loss = 61.61930456\n",
            "Iteration 109, loss = 61.58433276\n",
            "Iteration 110, loss = 61.53690930\n",
            "Iteration 111, loss = 61.50504410\n",
            "Iteration 112, loss = 61.46985716\n",
            "Iteration 113, loss = 61.43815239\n",
            "Iteration 114, loss = 61.40934384\n",
            "Iteration 115, loss = 61.37892889\n",
            "Iteration 116, loss = 61.35389749\n",
            "Iteration 117, loss = 61.33052105\n",
            "Iteration 118, loss = 61.30617708\n",
            "Iteration 119, loss = 61.28370929\n",
            "Iteration 120, loss = 61.26366191\n",
            "Iteration 121, loss = 61.24562047\n",
            "Iteration 122, loss = 61.22876997\n",
            "Iteration 123, loss = 61.20866397\n",
            "Iteration 124, loss = 61.20091674\n",
            "Iteration 125, loss = 61.18078834\n",
            "Iteration 126, loss = 61.16677903\n",
            "Iteration 127, loss = 61.15380933\n",
            "Iteration 128, loss = 61.14134137\n",
            "Iteration 129, loss = 61.13174497\n",
            "Iteration 130, loss = 61.11944932\n",
            "Iteration 131, loss = 61.11145078\n",
            "Iteration 132, loss = 61.10248245\n",
            "Iteration 133, loss = 61.09298734\n",
            "Iteration 134, loss = 61.08543021\n",
            "Iteration 135, loss = 61.07734582\n",
            "Iteration 136, loss = 61.07044740\n",
            "Iteration 137, loss = 61.06320395\n",
            "Iteration 138, loss = 61.05907592\n",
            "Iteration 139, loss = 61.05195429\n",
            "Iteration 140, loss = 61.04823044\n",
            "Iteration 141, loss = 61.04138379\n",
            "Iteration 142, loss = 61.03877489\n",
            "Iteration 143, loss = 61.03416939\n",
            "Iteration 144, loss = 61.02964593\n",
            "Iteration 145, loss = 61.02755842\n",
            "Iteration 146, loss = 61.02367268\n",
            "Iteration 147, loss = 61.01977651\n",
            "Iteration 148, loss = 61.01638669\n",
            "Iteration 149, loss = 61.01511328\n",
            "Iteration 150, loss = 61.01100893\n",
            "Iteration 151, loss = 61.01005880\n",
            "Iteration 152, loss = 61.00680311\n",
            "Iteration 153, loss = 61.00463623\n",
            "Iteration 154, loss = 61.00250962\n",
            "Iteration 155, loss = 61.00086759\n",
            "Iteration 156, loss = 60.99903351\n",
            "Iteration 157, loss = 60.99858167\n",
            "Iteration 158, loss = 60.99501364\n",
            "Iteration 159, loss = 60.99427319\n",
            "Iteration 160, loss = 60.99275279\n",
            "Iteration 161, loss = 60.99093117\n",
            "Iteration 162, loss = 60.99007780\n",
            "Iteration 163, loss = 60.98869721\n",
            "Iteration 164, loss = 60.98731056\n",
            "Iteration 165, loss = 60.98646806\n",
            "Iteration 166, loss = 60.98564950\n",
            "Iteration 167, loss = 60.98552261\n",
            "Iteration 168, loss = 60.98368269\n",
            "Iteration 169, loss = 60.98343158\n",
            "Iteration 170, loss = 60.98250727\n",
            "Iteration 171, loss = 60.98335253\n",
            "Iteration 172, loss = 60.98129440\n",
            "Iteration 173, loss = 60.98054673\n",
            "Iteration 174, loss = 60.98022958\n",
            "Iteration 175, loss = 60.98121683\n",
            "Iteration 176, loss = 60.97928009\n",
            "Iteration 177, loss = 60.97928733\n",
            "Iteration 178, loss = 60.97833303\n",
            "Iteration 179, loss = 60.97897565\n",
            "Iteration 180, loss = 60.98047130\n",
            "Iteration 181, loss = 60.97743698\n",
            "Iteration 182, loss = 60.97713776\n",
            "Iteration 183, loss = 60.97716033\n",
            "Iteration 184, loss = 60.97664451\n",
            "Iteration 185, loss = 60.97641993\n",
            "Iteration 186, loss = 60.97579997\n",
            "Iteration 187, loss = 60.97593661\n",
            "Iteration 188, loss = 60.97612353\n",
            "Iteration 189, loss = 60.97533908\n",
            "Iteration 190, loss = 60.97524501\n",
            "Iteration 191, loss = 60.97506594\n",
            "Iteration 192, loss = 60.97500345\n",
            "Iteration 193, loss = 60.97481102\n",
            "Iteration 194, loss = 60.97446305\n",
            "Iteration 195, loss = 60.97417136\n",
            "Iteration 196, loss = 60.97459541\n",
            "Iteration 197, loss = 60.97435586\n",
            "Iteration 198, loss = 60.97407485\n",
            "Iteration 199, loss = 60.97381802\n",
            "Iteration 200, loss = 60.97420345\n",
            "Iteration 201, loss = 60.97373564\n",
            "Iteration 202, loss = 60.97364098\n",
            "Iteration 203, loss = 60.97361637\n",
            "Iteration 204, loss = 60.97311933\n",
            "Iteration 205, loss = 60.97365175\n",
            "Iteration 206, loss = 60.97337406\n",
            "Iteration 207, loss = 60.97330843\n",
            "Iteration 208, loss = 60.97339082\n",
            "Iteration 209, loss = 60.97284766\n",
            "Iteration 210, loss = 60.97327819\n",
            "Iteration 211, loss = 60.97296373\n",
            "Iteration 212, loss = 60.97307387\n",
            "Iteration 213, loss = 60.97320282\n",
            "Iteration 214, loss = 60.97282775\n",
            "Iteration 215, loss = 60.97281906\n",
            "Iteration 216, loss = 60.97274895\n",
            "Iteration 217, loss = 60.97273349\n",
            "Iteration 218, loss = 60.97299947\n",
            "Iteration 219, loss = 60.97276354\n",
            "Iteration 220, loss = 60.97299605\n",
            "Iteration 221, loss = 60.97259623\n",
            "Iteration 222, loss = 60.97264441\n",
            "Iteration 223, loss = 60.97232622\n",
            "Iteration 224, loss = 60.97277991\n",
            "Iteration 225, loss = 60.97259705\n",
            "Iteration 226, loss = 60.97254331\n",
            "Iteration 227, loss = 60.97250052\n",
            "Iteration 228, loss = 60.97274257\n",
            "Iteration 229, loss = 60.97234304\n",
            "Iteration 230, loss = 60.97255702\n",
            "Iteration 231, loss = 60.97310835\n",
            "Iteration 232, loss = 60.97267471\n",
            "Iteration 233, loss = 60.97219845\n",
            "Iteration 234, loss = 60.97227634\n",
            "Iteration 235, loss = 60.97226160\n",
            "Iteration 236, loss = 60.97242761\n",
            "Iteration 237, loss = 60.97197233\n",
            "Iteration 238, loss = 60.97249803\n",
            "Iteration 239, loss = 60.97200319\n",
            "Iteration 240, loss = 60.97205999\n",
            "Iteration 241, loss = 60.97241848\n",
            "Iteration 242, loss = 60.97196012\n",
            "Iteration 243, loss = 60.97205072\n",
            "Iteration 244, loss = 60.97196472\n",
            "Iteration 245, loss = 60.97224811\n",
            "Iteration 246, loss = 60.97226362\n",
            "Iteration 247, loss = 60.97190174\n",
            "Iteration 248, loss = 60.97284107\n",
            "Iteration 249, loss = 60.97218868\n",
            "Iteration 250, loss = 60.97199013\n",
            "Iteration 251, loss = 60.97206374\n",
            "Iteration 252, loss = 60.97225761\n",
            "Iteration 253, loss = 60.97185803\n",
            "Iteration 254, loss = 60.97219334\n",
            "Iteration 255, loss = 60.97198014\n",
            "Iteration 256, loss = 60.97247242\n",
            "Iteration 257, loss = 60.97218801\n",
            "Iteration 258, loss = 60.97200582\n",
            "Iteration 259, loss = 60.97194245\n",
            "Iteration 260, loss = 60.97180883\n",
            "Iteration 261, loss = 60.97208228\n",
            "Iteration 262, loss = 60.97222180\n",
            "Iteration 263, loss = 60.97184387\n",
            "Iteration 264, loss = 60.97248676\n",
            "Iteration 265, loss = 60.97181170\n",
            "Iteration 266, loss = 60.97288393\n",
            "Iteration 267, loss = 60.97224250\n",
            "Iteration 268, loss = 60.97183639\n",
            "Iteration 269, loss = 60.97192252\n",
            "Iteration 270, loss = 60.97225257\n",
            "Iteration 271, loss = 60.97207269\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "----- 104 ------ \n",
            "[12, 24, 35, 47, 58, 14] [16 25 36 44 55 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 8 40 49 58 63 14] [58] [14] 7.0\n",
            "[12, 24, 35, 47, 58, 14] [19 25 43 46 48 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  8 17 27 28 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [ 5  6 45 55 59 14] [] [14] 6.0\n",
            "[12, 24, 35, 47, 58, 14] [19 31 35 50 67 14] [35] [14] 7.0\n",
            "-----> Match Score: 38.0 <------\n"
          ]
        }
      ],
      "source": [
        "winningScore = 0\n",
        "winningState = 0\n",
        "\n",
        "in_randoms = 1\n",
        "while in_randoms <= 104:\n",
        "    # Fitting MLPC\n",
        "    MLPCSolver = \"sgd\" # solver{\"lbfgs\", \"sgd\", \"adam\"}, default=adam\n",
        "    MLPclf = MLPRegressor(hidden_layer_sizes=(4,4), max_iter=1536, alpha=0.0001,  verbose=10,\n",
        "                           solver=MLPCSolver, random_state=in_randoms, tol=0.000000001)\n",
        "    MLPclf.fit(X_train, y_train)\n",
        "\n",
        "    # Predicting the Test set results\n",
        "    y_r_pred = MLPclf.predict(X_test)\n",
        "\n",
        "    totalMatchScore = 0\n",
        "    print('----- ' + str(in_randoms) + ' ------ ')\n",
        "    for index, pred in enumerate(y_r_pred):\n",
        "        pred = list(map(round, pred))\n",
        "        comparePOS = list(set(pred[:5]) & set(y_test[index][:5]))\n",
        "        comparePWB = list(set(pred[5:]) & set(y_test[index][5:]))\n",
        "        matchScore = predictionScore(pred[:5], y_test[index][:5]) + (predictionScore(pred[5:], y_test[index][5:])*6)\n",
        "        if matchScore >= 6:\n",
        "            totalMatchScore += matchScore\n",
        "            print(pred, y_test[index], comparePOS, comparePWB, matchScore)#, round(accuracy,3), X_test[index])\n",
        "        # Find the winner!\n",
        "        if totalMatchScore >= winningScore:\n",
        "            winningScore = totalMatchScore\n",
        "            winningState = in_randoms\n",
        "    print('-----> Match Score: ' + str(totalMatchScore) + ' <------')\n",
        "\n",
        "    in_randoms += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St3VdIkf_lOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce0a237-7c28-4c9a-9012-25cf4b5709ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----> Winner is 49 with 61 <------\n",
            "Iteration 1, loss = 131207282.61903372\n",
            "Iteration 2, loss = 10006928.36891563\n",
            "Iteration 3, loss = 20500615.01322863\n",
            "Iteration 4, loss = 29520859.18991382\n",
            "Iteration 5, loss = 36357677.02730908\n",
            "Iteration 6, loss = 41238277.94664849\n",
            "Iteration 7, loss = 44610463.22429676\n",
            "Iteration 8, loss = 46896188.62814995\n",
            "Iteration 9, loss = 48428078.20833450\n",
            "Iteration 10, loss = 49450446.27393344\n",
            "Iteration 11, loss = 50125747.83796978\n",
            "Iteration 12, loss = 50570592.48391920\n",
            "Iteration 13, loss = 50863641.06017731\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "[-57. -72. -37. -17. -85. -95.] [29.97, 74.8, 86.84, 81, 81.06, 2]\n"
          ]
        }
      ],
      "source": [
        "print('-----> Winner is ' + str(int(winningState)) + ' with ' + str(int(winningScore)) + ' <------')\n",
        "# Fitting RNC\n",
        "MLPclf = MLPRegressor(hidden_layer_sizes=(4,4), max_iter=1536, alpha=0.0001,  verbose=10,\n",
        "                           solver=MLPCSolver, random_state=int(winningState), tol=0.000000001)\n",
        "MLPclf.fit(X, y)\n",
        "\n",
        "# Predicting the next draw set results\n",
        "nextdraw_MLpred = MLPclf.predict([nextdraw_set])\n",
        "nextdraw_MLpred[0] = list(map(round, nextdraw_MLpred[0]))\n",
        "print(nextdraw_MLpred[0], nextdraw_set)\n",
        "\n",
        "nextDrawResults.append([{\"numbers\":list(map(round, nextdraw_MLpred[0]))},{\"score\":int(winningScore)},{\"class\":\"weather - MLPRegressor - S\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBjk3zKQwqqf"
      },
      "source": [
        "# Show the results\n",
        "Order the results by the best scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q-X2KdmxFwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a118b2-e610-43ef-dbe5-ecd929c1c680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PB 2022-08-24\n",
            "[3, 17, 49, 58, 68, 8] 80 weather - RandomForestClassifier - E\n",
            "[3, 25, 35, 58, 68, 10] 74 weather - RandomForestClassifier - G\n",
            "[12, 24, 36, 48, 60, 14] 62 weather - MLPRegressor - L\n",
            "[-57, -72, -37, -17, -85, -95] 61 weather - MLPRegressor - S\n",
            "[1, 28, 36, 59, 68, 11] 50 weather - KNeighborsClassifier - U\n",
            "[19, 23, 32, 35, 68, 21] 49 weather - KNeighborsClassifier - D\n"
          ]
        }
      ],
      "source": [
        "print(\"PB\", nextdraw_date.strftime(\"%Y-%m-%d\"))\n",
        "#for predictions in nextDrawResults:\n",
        "#    print(list(map(int, predictions[0]['numbers'])), predictions[1]['score'], predictions[2]['class'])\n",
        "nextDrawResultsSorted = sorted(nextDrawResults, key=lambda k: k[1]['score'], reverse=True)\n",
        "for predictions in nextDrawResultsSorted:\n",
        "    print(list(map(int, predictions[0]['numbers'])), predictions[1]['score'], predictions[2]['class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write Top Pick to Date"
      ],
      "metadata": {
        "id": "MFM1NB2pPgE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write the top pick numbers back to the date record for display\n",
        "#print(str(nextDrawResultsSorted[0][0]['numbers']))\n",
        "DBentry = LuckyWeatherNumbers.update_item(\n",
        "    Key = { \n",
        "        'draw_date': str(datetime.date(nextdraw_date)),\n",
        "        'night': str(datetime.date(nextdraw_date).weekday())\n",
        "    },\n",
        "    UpdateExpression = 'SET top_pick = :this_top_pick',\n",
        "    ExpressionAttributeValues = {\n",
        "        ':this_top_pick': str(nextDrawResultsSorted[0][0]['numbers'])\n",
        "    }\n",
        ") \n",
        "\n",
        "print(str(datetime.date(nextdraw_date)), nextDrawResultsSorted[0][0]['numbers'], DBentry['ResponseMetadata']['RequestId'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91iPG6fdPlSj",
        "outputId": "0ad34bb0-3e5f-4c2a-c855-ae30a4c06047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-24 [3, 17, 49, 58, 68, 8] 8HLS8KBF4KV9OLL9NKE4I9NENJVV4KQNSO5AEMVJF66Q9ASUAAJG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display results\n",
        "table = dynamodb.Table('LuckyWeatherNumbers')\n",
        "#print(table.creation_date_time)\n",
        "\n",
        "# grab all the records...\n",
        "response = table.scan(\n",
        "    FilterExpression=Attr('top_pick').exists(),\n",
        "    ProjectionExpression='draw_date, POS1, POS2, POS3, POS4, POS5, PWRB, night, top_pick'\n",
        ")\n",
        "# put them in a dataframe\n",
        "df_w = pd.DataFrame(response['Items'])\n",
        "\n",
        "# make everything numeric\n",
        "for column in df_w:\n",
        "    # set all to numeric\n",
        "    #print(column)\n",
        "    if column not in ['draw_date', 'top_pick']:\n",
        "      df_w[column] = pd.to_numeric(df_w[column], errors='coerce')\n",
        "\n",
        "\n",
        "# re-sort the columns\n",
        "df_w = df_w[['draw_date', 'top_pick', 'POS1', 'POS2', 'POS3', 'POS4', 'POS5', 'PWRB', 'night']]\n",
        "\n",
        "#print('Shape of the dataset: ' + str(df_w.shape))\n",
        "df_w.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "I-1wzSO0UhHx",
        "outputId": "d78426a3-efae-4922-8a58-2120fce93f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b8d59174e45b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# re-sort the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'draw_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top_pick'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POS1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POS2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POS3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POS4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POS5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PWRB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'night'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#print('Shape of the dataset: ' + str(df_w.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['POS1', 'POS2', 'POS3', 'POS4', 'POS5', 'PWRB'] not in index\""
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lottoPicker-scikit-PB-WeatherData.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}